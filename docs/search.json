[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"book provides overview skills needed reproducible open research using statistical programming language R tidyverse packages. covers reproducible workflows, data visualisation, data tidying wrangling, archiving, iteration functions, probability data simulations.book mainly focusses technical data skills, reproducible open research reason learning skills. following papers provide great overview concepts already familiar .Easing open science: guide graduate students advisors (Kathawalla et al., 2021)open science workflow credible, rigorous research (Corker, 2021)Seven easy steps open science (Crüwell et al., 2019)community-sourced glossary open scholarship terms (Parsons et al., 2022)","code":""},{"path":"index.html","id":"resources","chapter":"Overview","heading":"Resources","text":"Videos\nchapter several short video lectures main learning outcomes. videos captioned watching captioning useful way learn jargon computational reproducibility. access YouTube, videos available request. videos created 2020, aspects RStudio interface book text changed.Videos\nchapter several short video lectures main learning outcomes. videos captioned watching captioning useful way learn jargon computational reproducibility. access YouTube, videos available request. videos created 2020, aspects RStudio interface book text changed.reprores\ncustom R package course. can install code . download packages used book, along offline copy book, shiny apps used book, exercises.\n\ndevtools::install_github(\"psyteachr/reprores-v3\")reprores\ncustom R package course. can install code . download packages used book, along offline copy book, shiny apps used book, exercises.glossary\nCoding statistics lot specialist terms. Throughout book, jargon linked glossary. chapter end table glossary terms relevant chapter.glossary\nCoding statistics lot specialist terms. Throughout book, jargon linked glossary. chapter end table glossary terms relevant chapter.","code":"\ndevtools::install_github(\"psyteachr/reprores-v3\")"},{"path":"index.html","id":"how-to-learn-data-skills","chapter":"Overview","heading":"How to learn data skills","text":"Learning data skills kind like gym membership (HT Phil McAleer analogy). given state---art equipment use instructions use , data skills get stronger unless practice.Data skills require memorise lots code. introduced many different functions, main skill learn efficiently find information need. require getting used structure help files cheat sheets, learning Goggle problem choose helpful solution, learning read error messages.Learning code involves making lot mistakes. mistakes completely essential process, try feel frustrated. Many chapter exercises give broken code fix get experience seeing common errors look like. become experienced coder, might make fewer errors, recover much faster.","code":""},{"path":"index.html","id":"i-found-a-bug","chapter":"Overview","heading":"I found a bug!","text":"book work progress, might find errors. Please help fix ! best way open issue github describes error, can also email Lisa.","code":""},{"path":"index.html","id":"other-resources","chapter":"Overview","heading":"Other Resources","text":"RStudio Cheat SheetsImproving Pedagogy Registered ReportsLearning Statistics R NavarroR Data Science Grolemund WickhamImproving statistical inferences CourseraswirlR Reproducible Scientific Analysiscodeschool.comdatacampStyle guide R programming#rstats twitter highly recommended!","code":""},{"path":"intro.html","id":"intro","chapter":"1 Getting Started","heading":"1 Getting Started","text":"","code":""},{"path":"intro.html","id":"ilo-intro","chapter":"1 Getting Started","heading":"1.1 Learning Objectives","text":"Understand RStudio IDE (video)Type commands console (video)Understand coding terms function syntax (video)Install package (video)Know methods getting help","code":""},{"path":"intro.html","id":"setup-intro","chapter":"1 Getting Started","heading":"1.2 Setup","text":"Download RStudio IDE cheat sheet.","code":""},{"path":"intro.html","id":"r-and-rstudio","chapter":"1 Getting Started","heading":"1.3 R and RStudio","text":"R programming environment data processing statistical analysis. use R Psychology University Glasgow promote reproducible research. refers able document reproduce steps raw data results. R allows write scripts combine data files, clean data, run analyses. many ways , including writing SPSS syntax files, find R useful tool free, open source, commonly used research psychologists.See Appendix information install R associated programs.","code":""},{"path":"intro.html","id":"rconsole","chapter":"1 Getting Started","heading":"1.3.1 The Base R Console","text":"open application called R, see \"R Console\" window looks something like .\nFigure 1.1: R Console window.\ncan close R never open . working entirely RStudio class.ALWAYS REMEMBER: Launch R though RStudio IDELaunch  (RStudio.app),  (R.app).","code":""},{"path":"intro.html","id":"rstudio_ide","chapter":"1 Getting Started","heading":"1.3.2 RStudio","text":"RStudio Integrated Development Environment (IDE). program serves text editor, file manager, provides many functions help read write R code.\nFigure 1.2: RStudio IDE\nRStudio arranged four window panes. default, upper left pane source pane, view edit source code files. bottom left pane usually console pane, can type commands view output messages. right panes several different tabs show information code. can change location panes tabs shown Preferences > Pane Layout.","code":""},{"path":"intro.html","id":"configure-rstudio","chapter":"1 Getting Started","heading":"1.3.3 Configure RStudio","text":"class, learning reproducible research. involves writing scripts completely transparently perform analysis start finish way yields result different people using software different computers. Transparency key value science, embodied \"trust verify\" motto.things reproducibly, others can understand check work. benefits science, selfish reason, : important person benefit reproducible script future self. return analysis two weeks vacation, thank earlier self things transparent, reproducible way, can easily pick right left .two tweaks RStudio installation maximize reproducibility. Go Global Options... Tools menu (Cmd-,), uncheck box says Restore .RData workspace startup. keep things around workspace, things get messy, unexpected things happen. always start clear workspace. also means never want save workspace exit, set Never. thing want save scripts.\nFigure 1.3: Alter settings increased reproducibility.\nsettings :Restore .RData workspace startup: CheckedNot CheckedSave workspace .RData exit: AlwaysNeverAsk","code":""},{"path":"intro.html","id":"console","chapter":"1 Getting Started","heading":"1.4 Console commands","text":"first going learn interact console. general, developing R scripts R Markdown files, rather working directly console window. However, can consider console kind \"sandbox\" can try lines code adapt get want. can copy back script editor.Mostly, however, typing script editor window (either R script R Markdown file) sending commands console placing cursor line holding Ctrl key press Enter. Ctrl+Enter key sequence sends command script console.One simple way learn R console use calculator. Enter lines code see results match. prepared make lots typos (first).R console remembers history commands typed past. Use arrow keys keyboard scroll backwards forwards history. lot faster re-typing.can break mathematical expressions multiple lines; R waits complete expression processing .Text inside quotes called string.can break text multiple lines; R waits close quote processing . want include double quote inside quoted string, escape backslash.","code":"\n1 + 1## [1] 2\n1 + 1 + 3## [1] 5\n## here comes a long expression\n## let's break it over multiple lines\n1 + 2 + 3 + 4 + 5 + 6 +\n    7 + 8 + 9 +\n    10## [1] 55\n\"Good afternoon\"## [1] \"Good afternoon\"\nafrica <- \"I hear the drums echoing tonight  \nBut she hears only whispers of some quiet conversation  \nShe's coming in, 12:30 flight  \nThe moonlit wings reflect the stars that guide me towards salvation  \nI stopped an old man along the way  \nHoping to find some old forgotten words or ancient melodies  \nHe turned to me as if to say, \\\"Hurry boy, it's waiting there for you\\\"\n\n- Toto\"\n\ncat(africa) # cat() prints the string## I hear the drums echoing tonight  \n## But she hears only whispers of some quiet conversation  \n## She's coming in, 12:30 flight  \n## The moonlit wings reflect the stars that guide me towards salvation  \n## I stopped an old man along the way  \n## Hoping to find some old forgotten words or ancient melodies  \n## He turned to me as if to say, \"Hurry boy, it's waiting there for you\"\n## \n## - Toto"},{"path":"intro.html","id":"coding-terms","chapter":"1 Getting Started","heading":"1.5 Coding Terms","text":"","code":""},{"path":"intro.html","id":"vars","chapter":"1 Getting Started","heading":"1.5.1 Objects","text":"Often want store result computation later use. can store object (also sometimes called variable). object R:contains letters, numbers, full stops, underscoresstarts letter full stop letterdistinguishes uppercase lowercase letters (rickastley RickAstley)following valid different objects:songdataSongDatasong_datasong.data.song.datanever_gonna_give_you_up_never_gonna_let_you_downThe following valid objects:_song_data1song.1songsong datasong-dataUse assignment operator<-` assign value right object named left.Now set x value, can something :Note print result back stored. view result, just type object name blank line.object assigned value, value change unless reassign object, even objects used calculate change. Predict code test :code run:this_year = 4344197620192020my_birth_year = 4344197620192020my_age = 4344197620192020","code":"\n## use the assignment operator '<-'\n## R stores the number in the object\nx <- 5\nx * 2\n\n## R evaluates the expression and stores the result in the object boring_calculation\nboring_calculation <- 2 + 2## [1] 10\nboring_calculation## [1] 4\nthis_year <- 2019\nmy_birth_year <- 1976\nmy_age <- this_year - my_birth_year\nthis_year <- 2020"},{"path":"intro.html","id":"the-environment","chapter":"1 Getting Started","heading":"1.5.2 The environment","text":"time assign something new object, R creates new entry global environment. Objects global environment exist end session; disappear forever (unless save ).Look Environment tab upper right pane. lists objects created. Click broom icon clear objects start fresh. can also use following functions console view objects, remove one object, remove objects.upper right corner Environment tab, change List Grid. Now can see type, length, size objects, reorder list attributes.","code":"\nls()            # print the objects in the global environment\nrm(\"x\")         # remove the object named x from the global environment\nrm(list = ls()) # clear out the global environment"},{"path":"intro.html","id":"whitespace","chapter":"1 Getting Started","heading":"1.5.3 Whitespace","text":"R mostly ignores whitespace: spaces, tabs, line breaks. means can use whitespace help organise code.see > beginning line, means R waiting start new command. However, see + instead > start line, means R waiting finish command started previous line. want cancel whatever command started, just press Esc key console window get back > command prompt.often useful break long functions onto several lines.","code":"\n# a and b are identical\na <- list(ctl = \"Control Condition\", exp1 = \"Experimental Condition 1\", exp2 = \"Experimental Condition 2\")\n\n# but b is much easier to read\nb <- list(ctl  = \"Control Condition\", \n          exp1 = \"Experimental Condition 1\", \n          exp2 = \"Experimental Condition 2\")\n# R waits until next line for evaluation\n(3 + 2) *\n     5## [1] 25\ncat(\"3, 6, 9, the goose drank wine\",\n    \"The monkey chewed tobacco on the streetcar line\",\n    \"The line broke, the monkey got choked\",\n    \"And they all went to heaven in a little rowboat\",\n    sep = \"  \\n\")## 3, 6, 9, the goose drank wine  \n## The monkey chewed tobacco on the streetcar line  \n## The line broke, the monkey got choked  \n## And they all went to heaven in a little rowboat"},{"path":"intro.html","id":"function_syx","chapter":"1 Getting Started","heading":"1.5.4 Function syntax","text":"lot R involves calling function storing results. function named section code can reused.example, sd function returns standard deviation vector numbers provide input argument. Functions set like :arguments parentheses can named (e.g., argument1 = 10) can skip names put exact order defined function. can check typing ?sd (whatever function name looking ) console Help pane show default order Usage. can skip arguments default value specified.functions return value, may also produce side effects like printing console.illustrate, function rnorm() generates random numbers standard normal distribution. help page rnorm() (accessed typing ?rnorm console) shows syntaxwhere n number randomly generated numbers want, mean mean distribution, sd standard deviation. default mean 0, default standard deviation 1. default n, means get error specify :want 10 random numbers normal distribution mean 0 standard deviation, can just use defaults.want 10 numbers normal distribution mean 100:equivalent less efficient way calling function:need name arguments R recognize intended fill first second arguments position function call. However, want change default argument coming later list, need name . instance, wanted keep default mean = 0 change standard deviation 100, way:functions give list options argument; means default value first option. usage entry power.t.test() function looks like :default value sd? NULLtwo.sample10.05What default value type? NULLtwo.sampleone.samplepairedWhich equivalent power.t.test(100, 0.5)?\n\npower.t.test(n = 100)power.t.test()power.t.test(delta = 0.5, n = 100)power.t.test(100, 0.5, sig.level = 1, sd = 0.05)\n","code":"\nfunction_name(argument1, argument2 = \"value\")\nrnorm(n, mean = 0, sd = 1)\nrnorm()## Error in rnorm(): argument \"n\" is missing, with no default\nrnorm(10)##  [1] -0.3904910 -0.1381635 -0.7593314 -0.4045687 -0.4013214  2.0054098\n##  [7] -0.1142254  0.5915578  0.6943761 -1.9953083\nrnorm(10, 100)##  [1]  98.48829  98.96984 100.44520 100.29931 101.11297 100.08531  99.12447\n##  [8] 100.90521 100.38799 100.78756\nrnorm(n = 10, mean = 100)##  [1] 100.38078 101.73240 100.54867  99.95692 100.60686 100.39064 100.74864\n##  [8] 100.76760 100.38174 100.30323\nrnorm(10, sd = 100)##  [1]  128.684153   21.997591   77.442757   53.775709   -1.323737  -76.934590\n##  [7] -253.666227  -43.574221 -175.716691 -119.241014\npower.t.test(n = NULL, delta = NULL, sd = 1, sig.level = 0.05,\n             power = NULL,\n             type = c(\"two.sample\", \"one.sample\", \"paired\"),\n             alternative = c(\"two.sided\", \"one.sided\"),\n             strict = FALSE, tol = .Machine$double.eps^0.25)"},{"path":"intro.html","id":"install-package","chapter":"1 Getting Started","heading":"1.6 Add-on packages","text":"One great things R user extensible: anyone can create new add-software package extends functionality. currently thousands add-packages R users created solve many different kinds problems, just simply fun. packages data visualisation, machine learning, neuroimaging, eyetracking, web scraping, playing games Sudoku.Add-packages distributed base R, downloaded installed archive, way , instance, download install PokemonGo smartphone.main repository packages reside called CRAN, Comprehensive R Archive Network. package pass strict tests devised R core team allowed part CRAN archive. can install CRAN archive R using install.packages() function.important distinction installing package loading package.","code":""},{"path":"intro.html","id":"installing-a-package","chapter":"1 Getting Started","heading":"1.6.1 Installing a package","text":"done using install.packages(). like installing app phone: app remain installed remove . instance, want use PokemonGo phone, install App Store Play Store, re-install time want use . launch app, run background close restart phone. Likewise, install package, package available (loaded) every time open R.may able permanently install packages using R system; may able public workstations lack appropriate privileges.Install beepr package system. package plays sounds, can set long script play sound notify done.already packages like audio installed, also install r glossary(\"dependency\", \"dependencies\", )` . get error message end, installation successful.Never install package inside script. console pane.","code":"\n# type this in the console pane\ninstall.packages(\"beepr\")"},{"path":"intro.html","id":"loading-a-package","chapter":"1 Getting Started","heading":"1.6.2 Loading a package","text":"done using library(packagename). like launching app phone: functionality app launched remains close app restart. Likewise, run library(packagename) within session, functionality package referred packagename made available R session. next time start R, need run library() function want access functionality.can load functions beepr current R session follows:might get red text load package, normal. usually warning package functions name packages already loaded.Now can run function beepr::beep().can use convention package::function() indicate add-package function resides. instance, see readr::read_csv(), refers function read_csv() readr add-package.","code":"\nlibrary(beepr)\nbeepr::beep() # default sound\nbeepr::beep(sound = \"mario\") # change the sound argument"},{"path":"intro.html","id":"tidyverse","chapter":"1 Getting Started","heading":"1.6.3 Tidyverse","text":"tidyverseis meta-package loads several packages using almost every script:ggplot2, data visualisation (Chapter 3)readr, data import (Chapter 4)tibble, tables (Chapter 4)tidyr, data tidying (Chapter 6)dplyr, data manipulation (Chapter 7)purrr, repeating things (Chapter 8)stringr, stringsforcats, factors","code":""},{"path":"intro.html","id":"install-from-github","chapter":"1 Getting Started","heading":"1.6.4 Install from GitHub","text":"Many R packages yet CRAN still development. Increasingly, datasets code papers available packages can download github. need install devtools package able install packages github. Check package installed trying load (e.g., devtools installed, library(devtools) display error message) searching packages tab lower right pane. listed packages installed; checked packages currently loaded.\nFigure 1.4: Check installed loaded packages packages tab lower right pane.\ninstall reprores package, load using library() function. can try functions .many different ways can find discover functions available reprores package?reprores contains datasets using future lessons. getdata() creates directory called data class datasets.","code":"\n# install devtools if you get\n# Error in loadNamespace(name) : there is no package called ‘devtools’\n# install.packages(\"devtools\")\ndevtools::install_github(\"psyteachr/reprores-v3\")\nlibrary(reprores)\n\n# opens a local copy of this book in your web browser\nbook()\n\n# opens a shiny app that lets you see how simulated data would look in different plot styles\napp(\"plotdemo\")\n\n# creates and opens a file containing the exercises for this chapter\nexercise(1)\n# loads the disgust dataset\ndata(\"disgust\")\n\n# shows the documentation for the built-in dataset `disgust`\n?disgust\n\n# saves datasets into a \"data\" folder in your working directory\ngetdata(\"data\")"},{"path":"intro.html","id":"help","chapter":"1 Getting Started","heading":"1.7 Getting help","text":"feel like need lot help starting learn. really go away, supposed . Experienced coders also constantly looking things ; impossible memorise everything. goal learn enough structure R can look things quickly. much specialised jargon coding; easier google \"concatenating vectors R\" \"putting together groups things kind data R\".","code":""},{"path":"intro.html","id":"function-help","chapter":"1 Getting Started","heading":"1.7.1 Function Help","text":"Start help browser using function help.start().function base R loaded package, can use help(\"function_name\") function ?function_name shortcut access help file. package loaded, specify package name second argument help function.package loaded sure package function , use shortcut ??function_name.first argument mean function? trimna.rmmeanxWhat package read_excel ? readrreadxlbasestats","code":"\n# these methods are all equivalent ways of getting help\nhelp(\"rnorm\")\n?rnorm\nhelp(\"rnorm\", package=\"stats\") "},{"path":"intro.html","id":"googling","chapter":"1 Getting Started","heading":"1.7.2 Googling","text":"function help help, even sure function need, try Googling question. take practice able use right jargon search terms get want. helps put \"R\" \"rstats\", \"tidyverse\" search text, name relevant package, like ggplot2.","code":""},{"path":"intro.html","id":"vignettes","chapter":"1 Getting Started","heading":"1.7.3 Vignettes","text":"Many packages, especially tidyverse ones, helpful websites vignettes explaining use functions. vignettes also available inside R.","code":"\n# opens a list of available vignettes\nvignette(package = \"ggplot2\")\n\n# opens a specific vignette in the Help pane\nvignette(\"ggplot2-specs\", package = \"ggplot2\")"},{"path":"intro.html","id":"asking-for-help","chapter":"1 Getting Started","heading":"1.7.4 Asking for Help","text":"else fails, can ask help. See Appendix B advice share code asking help class Teams channel web-based forums. also section make reprex make easier others understand reproduce problem (often solve process) .TL;DR: copy paste code giving trouble, please send screenshots definitely photos screen.","code":""},{"path":"intro.html","id":"glossaryintro","chapter":"1 Getting Started","heading":"1.8 Glossary","text":"chapter ends glossary table defining jargon introduced chapter. links take glossary book, can also download offline use.","code":"\n# install the glossary package (only once)\ndevtools::install_github(\"psyteachr/glossary\")\n\n# open the glossary offline \nglossary::book()"},{"path":"intro.html","id":"resources-intro","chapter":"1 Getting Started","heading":"1.9 Further Resources","text":"Chapter 1: Introduction R Data ScienceRStudio IDE CheatsheetRStudio Cloud","code":""},{"path":"repro.html","id":"repro","chapter":"2 Reproducible Workflows","heading":"2 Reproducible Workflows","text":"","code":""},{"path":"repro.html","id":"ilo-repro","chapter":"2 Reproducible Workflows","heading":"2.1 Learning Objectives","text":"Organise project (video)Create compile Rmarkdown document (video)Edit YAML header add table contents optionsInclude tableInclude figureReport output analysis using inline RAdd bibliography citations","code":""},{"path":"repro.html","id":"setup-repro","chapter":"2 Reproducible Workflows","heading":"2.2 Setup","text":"given instructions Section 2.4.4 set new project keep class notes. Section 2.5 gives instructions set R Markdown script chapter.reference, packages use chapter.Download R Markdown Cheat Sheet.","code":"\n# packages needed for this chapter\nlibrary(tidyverse)  # various data manipulation functions\nlibrary(knitr)      # for table and image display\nlibrary(kableExtra) # for styling tables\nlibrary(papaja)     # for APA-style tables\nlibrary(gt)         # for fancy tables\nlibrary(DT)         # for interactive tables"},{"path":"repro.html","id":"why-learn-reproducible-reports","chapter":"2 Reproducible Workflows","heading":"2.3 Why learn reproducible reports?","text":"ever worked report, creating summary table demographics, making beautiful plots, getting analysis just right, copying relevant numbers manuscript, find forgot exclude test run redo everything?Areproducible report fixes problem. Although requires bit extra effort start, pay back allowing update entire report push button whenever anything changes.Studies also show many, , papers scientific literature reporting errors. example, half 250,000 psychology papers published 1985 2013 least one value statistically incompatible (e.g., p-value possible given t-value degrees freedom) (Nuijten et al., 2016). Reproducible reports help avoid transcription rounding errors.make reproducible reports following principles literate programming. basic idea text report together single document along code needed perform analyses generate tables. report \"compiled\" original format , portable format, HTML PDF. different traditional cutting pasting approaches , instance, create graph Microsoft Excel statistics program like SPSS paste Microsoft Word.","code":""},{"path":"repro.html","id":"projects","chapter":"2 Reproducible Workflows","heading":"2.4 Organising a project","text":"First, need get organised. Projects RStudio way group files need one project. projects include scripts, data files, output files like PDF report created script images.","code":""},{"path":"repro.html","id":"file-system","chapter":"2 Reproducible Workflows","heading":"2.4.1 File System","text":"Modern computers tend hide file system users, need understand little bit files stored computer order get script find data. computer's file system like big box (directory) contains files smaller boxes, \"subdirectories\". can specify location file name names directories inside.example, Lisa looking file called report.Rmdon Desktop, can specify full file path like : /Users/lisad/Desktop/report.Rmd, Desktop directory inside lisad directory, inside Users directory, located base whole file system. file desktop, probably different path unless user directory also called lisad. can also use ~ shortcut represent user directory person currently logged , like : ~/Desktop/report.Rmd.","code":""},{"path":"repro.html","id":"working-directory","chapter":"2 Reproducible Workflows","heading":"2.4.2 Working Directory","text":"put files? usually want scripts data files single project inside one folder computer, working directory project. can organise files subdirectories inside main project directory, putting raw data files directory called data saving image files directory called images.script reference files three locations, using appropriate format.Never set change working directory script.R Markdown files automatically use directory .Rmd file working directory.script needs file subdirectory working directory, , data/5factor.xlsx, load using relative path accessible move working directory another location computer:load using absolute path:Also note convention using forward slashes, unlike Windows-specific convention using backward slashes. make references files work everyone, regardless operating system.","code":"\ndat <- read_csv(\"data/5factor.xlsx\")  # correct\ndat <- read_csv(\"C:/My Files/2020-2021/data/5factor.xlsx\")   # wrong"},{"path":"repro.html","id":"naming-things","chapter":"2 Reproducible Workflows","heading":"2.4.3 Naming Things","text":"Name files people computers can easily find things. important principles:file directory names contain letters, numbers, dashes, underscores, full stop (.) file name extension (means spaces!)consistent capitalisation (set rule make easy remember, like always use lowercase)use underscores (_) separate parts file name, dashes (-) separate words sectionname files pattern alphabetises sensible order makes easy find file looking forprefix filename underscore move top list, prefix files numbers control orderFor example, file names mess:report.docreport final.docData (Participants) 11-15.xlsParticipants Data Nov 12.xlsfinal report2.docproject notes.txtQuestionnaire Data November 15.xlsHere one way structure similar files structure easy human scan list use code find relevant files. See can figure last one ._project-notes.txtreport_v1.docreport_v2.docreport_v3.docdata_participants_2021-11-12.xlsdata_participants_2021-11-15.xlsquestionnaire-data_2021-11-15.xlsdata-questionnaire-2021_11_15.xlsdata_questionnaire_2021-11-15.xlsdata_2021-11-15_questionnaire.xlsThink ways name files . Look project files see can improve.","code":""},{"path":"repro.html","id":"new-project","chapter":"2 Reproducible Workflows","heading":"2.4.4 Start a Project","text":"Now understand file system work name things make easier scripts access , ready make class project.First, make new directory keep materials class (called mine reprores-2022). can set directory default working directory General tab Global Options. means files saved default working project.can sometimes cause problems directory OneDrive full file path special characters 260 characters Windows machines.Next, choose New Project... File menu create new project called reprores-class-notes. Make sure save inside directory just made. RStudio restart open new project directory working directory.\nFigure 2.1: Starting new project.\n\nFigure 2.2: Starting new project.\n\nFigure 2.3: Starting new project.\nClick Files tab lower right pane see contents project directory. see file called reprores-class-notes.Rproj, file contains project information.can double-click open project.Depending settings, may also see directory called .Rproj.user, contains specific user settings. can ignore \"invisible\" files start full stop.","code":"\ninclude_graphics(c(\"images/repro/new_proj_1.png\",\n                   \"images/repro/new_proj_2.png\",\n                   \"images/repro/new_proj_3.png\"))"},{"path":"repro.html","id":"r-markdown","chapter":"2 Reproducible Workflows","heading":"2.5 R Markdown","text":"lesson, learn make R Markdown document table contents, appropriate headers, code chunks, tables, images, inline R, bibliography.new type reproducible report format called quarto similar R Markdown. using quarto class small differences get confusing learning quarto R Markdown time, able pick quarto easily learned R Markdown.use R Markdown create reproducible reports, enables mixing text code. reproducible script contain sections code code blocks. code block starts ends three backtick symbols row, information code curly brackets, {r chunk-name, echo=FALSE} (runs code, show text code block compiled document). text outside code blocks written markdown, way specify formatting, headers, paragraphs, lists, bolding, links.\nFigure 2.4: reproducible script.\nopen new R Markdown file template, see example document several code blocks . create HTML PDF report R Markdown (Rmd) document, compile . Compiling document called knitting RStudio. button looks like ball yarn needles click compile file report.Create new R Markdown file File > New File > R Markdown... menu. Change title author, save file 02-repro.Rmd, click knit button create html file.","code":""},{"path":"repro.html","id":"yaml","chapter":"2 Reproducible Workflows","heading":"2.5.1 YAML Header","text":"YAML header can set several options.Try changing values false true see options .df_print: kable option prints data frames using knitr::kable. learn customise tables.built-bootswatch themes : default, cerulean, cosmo, darkly, flatly, journal, lumen, paper, readable, sandstone, simplex, spacelab, united, yeti. can view download themes.\nFigure 2.5: Light themes versions 3 4.\n","code":"---\ntitle: \"My Demo Document\"\nauthor: \"Me\"\noutput:\n  html_document:\n    toc: true\n    toc_float:\n      collapsed: false\n      smooth_scroll: false\n    number_sections: false\nbibliography: refs.bib\ncsl: apa.csl\n---"},{"path":"repro.html","id":"setup","chapter":"2 Reproducible Workflows","heading":"2.5.2 Setup","text":"create new R Markdown file RStudio using default template, setup chunk automatically created.can set default options code chunks . See knitr options documentation explanations possible options.code sets following options:fig.width  = 8 : default figure width 8 inches (can change individual figures)fig.height = 5 : default figure height 5 inchesfig.path   = 'images/' : figures saved directory \"images\"echo       = FALSE : show code chunks rendered documentwarning    = FALSE : show function warningsmessage    = FALSE : show function messagescache      = FALSE : run code create images objects time knit (set TRUE time-consuming code)Find list current chunk options typing str(knitr::opts_chunk$get()) console.can also add packages need chunk using library(). Often working script, realize need load another add-package. bury call library(package_I_need) way script. Put top, user overview packages needed.using function package tidyverse, load setup chunk.","code":"```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)``````{r setup, include=FALSE}\nknitr::opts_chunk$set(\n  fig.width  = 8, \n  fig.height = 5, \n  fig.path   = 'images/',\n  echo       = FALSE, \n  warning    = TRUE, \n  message    = FALSE,\n  cache      = FALSE\n)```"},{"path":"repro.html","id":"structure","chapter":"2 Reproducible Workflows","heading":"2.5.3 Structure","text":"include table contents (toc), created document headers. Headers markdown created prefacing header title one hashes (#).Use following structure developing analysis scripts:load add-packages need usedefine custom functionsload simulate data working withwork datasave anything need saveDelete default text add structure document creating headers subheaders. going load data, create summary table, plot data, analyse .","code":""},{"path":"repro.html","id":"code-chunks","chapter":"2 Reproducible Workflows","heading":"2.5.4 Code Chunks","text":"can include code chunks create display images, tables, computations include text. start loading data.First, create code chunk document. code loads data web.can add comments inside R chunks hash symbol (#). R interpreter ignore characters hash end line.usually good practice start code chunk comment explains , especially code explained text report.name objects clearly, often need add clarifying comments. example, named three objects total_pet_n, mean_score sd_score, omit comments.bit art comment code well. best way develop skill read lot people's code others review code.","code":"\npets <- read_csv(\"https://psyteachr.github.io/reprores/data/pets.csv\",\n                 show_col_types = FALSE)\n# simulating new data\n\nn <- nrow(pets) # the total number of pet\nmu <- mean(pets$score) # the mean score for all pets\nsd <- sd(pets$score) # the SD for score for all pets\n\nsimulated_scores <- rnorm(n, mu, sd)"},{"path":"repro.html","id":"repro-tables","chapter":"2 Reproducible Workflows","heading":"2.5.5 Tables","text":"Next, create code chunk want display table descriptives (e.g., Participants section Methods). use tidyverse functions learn data wrangling lectures create summary statistics group.table print tibble format interactive view, use format df_print setting YAML header knit.table OK, reader-friendly changing column labels, rounding means, adding caption. can use knitr::kable() , specialised functions packages format tables.knitr\nkableExtra\npapaja\ngt\nDT\nTable 2.1: Summary statistics pets dataset.\nkableExtra package gives lot flexibility table display.\nTable 2.2: Summary statistics pets dataset.\npapaja helps create APA-formatted manuscripts, including tables.\nTable 2.3: \ngt package allows even customisation.Table 2.4: Summary statistics pets dataset.DT lets make interactive data tables. Chapter 10.3.3 goes details type table.","code":"\nsummary_table <- pets %>%\n  group_by(pet) %>%\n  summarise(\n    n = n(),\n    mean_weight = mean(weight),\n    mean_score = mean(score)\n  )\n\n# print\nsummary_table\nnewnames <- c(\"Pet Type\", \"N\", \"Mean Weight\", \"Mean Score\")\n\nknitr::kable(summary_table, \n             digits = 2, \n             col.names = newnames,\n             caption = \"Summary statistics for the pets dataset.\")\nlibrary(kableExtra)\n\nkable(summary_table, \n      digits = 2, \n      col.names = c(\"Pet Type\", \"N\", \"Weight\", \"Score\"),\n      caption = \"Summary statistics for the pets dataset.\") |>\n  kable_classic() |>\n  kable_styling(full_width = FALSE, font_size = 20) |>\n  add_header_above(c(\" \" = 2, \"Means\" = 2)) |>\n  kableExtra::row_spec(2, bold = TRUE, background = \"lightyellow\")\npapaja::apa_table(summary_table, \n                  col.names = c(\"Pet Type\", \"N\", \"Weight\", \"Score\"),\n                  caption = \"Summary statistics for the pets dataset.\",\n                  col_spanners = list(\"Means\" = c(3, 4)))\nlibrary(gt)\n\ngt(summary_table, caption = \"Summary statistics for the pets dataset.\") |>\n  fmt_number(columns = c(mean_weight, mean_score),\n            decimals = 2) |>\n  cols_label(pet = \"Pet Type\", \n             n = \"N\", \n             mean_weight = \"Weight\", \n             mean_score = \"Score\") |>\n  tab_spanner(label = \"Means\",\n              columns = c(mean_weight, mean_score)) |>\n opt_stylize(style = 6, color = \"blue\")\nDT::datatable(summary_table, \n              caption = \"Summary statistics for the pets dataset.\",\n              colnames = c(\"Pet Type\", \"N\", \"Weight\", \"Score\")) |>\n  DT::formatRound(c(\"mean_weight\", \"mean_score\"),\n                  digits = 2)"},{"path":"repro.html","id":"repro-figures","chapter":"2 Reproducible Workflows","heading":"2.5.6 Images","text":"Next, create code chunk want display image document. put Results section. use code learn data visualisation lecture show violin-boxplots groups.Notice figure caption formatted chunk options.\nFigure 2.6: Figure 1. Scores pet type country.\nlast line changes default text size font, can useful generating figures meet journal's requirements.can also include images create R using typical markdown syntax images:Things Hyperbole Half","code":"\n```r\nggplot(pets, aes(pet, score, fill = country)) +\n  geom_violin(alpha = 0.5) +\n  geom_boxplot(width = 0.25, \n               position = position_dodge(width = 0.9),\n               show.legend = FALSE) +\n  scale_fill_manual(values = c(\"orange\", \"dodgerblue\")) +\n  xlab(\"\") +\n  ylab(\"Score\") +\n  theme(text = element_text(size = 20, family = \"Times\"))\n```\n\n<div class=\"figure\" style=\"text-align: center\">\n<img src=\"02-repro_files/figure-html/unnamed-chunk-5-1.png\" alt=\"Figure 1. Scores by pet type and country.\" width=\"100%\" />\n<p class=\"caption\">(\\#fig:unnamed-chunk-5)Figure 1. Scores by pet type and country.<\/p>\n<\/div>![All the Things by [Hyperbole and a Half](http://hyperboleandahalf.blogspot.com/)](images/memes/x-all-the-things.png){style=\"width: 50%\"}"},{"path":"repro.html","id":"inline-r","chapter":"2 Reproducible Workflows","heading":"2.5.7 In-line R","text":"Now analyse pets data see cats heavier ferrets. First run analysis code. save numbers might want use manuscript variables round appropriately. Finally, use glue::glue() format results string.can insert results paragraph inline R code looks like :Rendered text:\nCats significantly heavier ferrets (t = 18.42, df = 180.4, p < 0.001).","code":"\n# analysis\ncat_weight <- filter(pets, pet == \"cat\") %>% pull(weight)\nferret_weight <- filter(pets, pet == \"ferret\") %>% pull(weight)\nweight_test <- t.test(cat_weight, ferret_weight)\n\n# round individual values you want to report\nt <- weight_test$statistic %>% round(2)\ndf <- weight_test$parameter %>% round(1)\np <- weight_test$p.value %>% round(3)\n# handle p-values < .001\np_symbol <- ifelse(p < .001, \"<\", \"=\")\nif (p < .001) p <- .001\n\n# format the results string\nweight_result <- glue::glue(\"t = {t}, df = {df}, p {p_symbol} {p}\")Cats were significantly heavier than ferrets (`r weight_result`)."},{"path":"repro.html","id":"bibliography","chapter":"2 Reproducible Workflows","heading":"2.5.8 Bibliography","text":"several ways -text references automatically generate bibliography R Markdown. Markdown files need link BibTex file (plain text file references specific format) contains references need cite. specify name file YAML header, like bibliography: refs.bib cite references text using symbol shortname, like [@tidyverse]. can also include \"csl\" style file format references , example, APA style.","code":"---\ntitle: \"My Paper\"\nauthor: \"Me\"\noutput: \n  html_document:\n    toc: true\nbibliography: refs.bib\ncsl: apa.csl"},{"path":"repro.html","id":"converting-from-reference-software","chapter":"2 Reproducible Workflows","heading":"2.5.8.1 Converting from reference software","text":"reference software like EndNote, Zotero Mendeley exporting options can export BibTeX format. just need check shortnames resulting file.","code":""},{"path":"repro.html","id":"creating-a-bibtex-file","chapter":"2 Reproducible Workflows","heading":"2.5.8.2 Creating a BibTeX File","text":"reference software like EndNote, Zotero Mendeley exporting options can export BibTeX format. just need check shortnames resulting file.can also make BibTeX file add references manually. RStudio, go File > New File... > Text File save file \"bibliography.bib\".Next, add line bibliography: bibliography.bib YAML header.","code":""},{"path":"repro.html","id":"citations","chapter":"2 Reproducible Workflows","heading":"2.5.8.3 Adding references","text":"can add references journal article following format:See complete guide BibTeX format instructions citing books, technical reports, .can get reference R package using functions citation() toBibtex(). can paste bibtex entry bibliography.bib file. Make sure add short name (e.g., \"ggplot2\") first comma refer reference.Google Scholar entries BibTeX citation option. usually easiest way get relevant values, although add DOI . can keep suggested shortname change something makes sense .journal websites also let download citations bibtex format. example, go publisher's page Equivalence Testing Psychological Research: Tutorial, click Cite button (sidebar bottom Explore menu), choose BibTeX format, download citation. can open file text editor copy text. look like :Paste reference bibliography.bib file. Change doi:10.1177/2515245918770963 first line reference shortname use cite reference manuscript. use TOSTtutorial.","code":"@article{shortname,\n  author = {Author One and Author Two and Author Three},\n  title = {Paper Title},\n  journal = {Journal Title},\n  volume = {vol},\n  number = {issue},\n  pages = {startpage--endpage},\n  year = {year},\n  doi = {doi}\n}\ncitation(package=\"ggplot2\") %>% toBibtex()## @Book{,\n##   author = {Hadley Wickham},\n##   title = {ggplot2: Elegant Graphics for Data Analysis},\n##   publisher = {Springer-Verlag New York},\n##   year = {2016},\n##   isbn = {978-3-319-24277-4},\n##   url = {https://ggplot2.tidyverse.org},\n## }@article{doi:10.1177/2515245918770963,\nauthor = {Daniël Lakens and Anne M. Scheel and Peder M. Isager},\ntitle ={Equivalence Testing for Psychological Research: A Tutorial},\njournal = {Advances in Methods and Practices in Psychological Science},\nvolume = {1},\nnumber = {2},\npages = {259-269},\nyear = {2018},\ndoi = {10.1177/2515245918770963},\n\nURL = { \n        https://doi.org/10.1177/2515245918770963\n    \n},\neprint = { \n        https://doi.org/10.1177/2515245918770963\n    \n}\n,\n    abstract = { Psychologists must be able to test both for the presence of an effect and for the absence of an effect. In addition to testing against zero, researchers can use the two one-sided tests (TOST) procedure to test for equivalence and reject the presence of a smallest effect size of interest (SESOI). The TOST procedure can be used to determine if an observed effect is surprisingly small, given that a true effect at least as extreme as the SESOI exists. We explain a range of approaches to determine the SESOI in psychological science and provide detailed examples of how equivalence tests should be performed and reported. Equivalence tests are an important extension of the statistical tools psychologists currently use and enable researchers to falsify predictions about the presence, and declare the absence, of meaningful effects. }\n}"},{"path":"repro.html","id":"references","chapter":"2 Reproducible Workflows","heading":"2.5.8.4 Citing references","text":"can cite references text like :tutorial uses several R packages (Allaire et al., 2018; Wickham, 2017).Put minus front @ just want year:Lakens, Scheel Isengar (2018) wrote tutorial explaining test absence effect.","code":"This tutorial uses several R packages [@tidyverse;@rmarkdown].Lakens, Scheel and Isengar [-@TOSTtutorial] wrote a tutorial explaining how to test for the absence of an effect."},{"path":"repro.html","id":"uncited-references","chapter":"2 Reproducible Workflows","heading":"2.5.8.5 Uncited references","text":"want add item reference section without citing, , add YAML header like :add items .bib file like :","code":"nocite: |\n  @ref1, @ref2, @ref3nocite: '@*'"},{"path":"repro.html","id":"citation-styles","chapter":"2 Reproducible Workflows","heading":"2.5.8.6 Citation Styles","text":"can search list style files various journals download file format bibliography specific journal's style. need add line csl: filename.csl YAML header.Add citations bibliography.bib file, reference text, render manuscript see automatically generated reference section. Try different citation style files.","code":""},{"path":"repro.html","id":"reference-section","chapter":"2 Reproducible Workflows","heading":"2.5.8.7 Reference Section","text":"default, reference section added end document. want change position (e.g., add figures tables references), include <div id=\"refs\"><\/div> want references.Add -text citations reference list report.","code":""},{"path":"repro.html","id":"custom-templates","chapter":"2 Reproducible Workflows","heading":"2.5.9 Custom Templates","text":"packages provide custom R Markdown templates. reprores Report template shows possible options YAML header, bibliography style files, explains set linked figures tables. contains multiple files, RStudio ask create new folder keep files .\nFigure 2.7: custom R markdown temlate reprores.\nStart report Report template knit . Try changing deleting options.","code":""},{"path":"repro.html","id":"glossary-repro","chapter":"2 Reproducible Workflows","heading":"2.6 Glossary","text":"","code":""},{"path":"repro.html","id":"resources-repro","chapter":"2 Reproducible Workflows","heading":"2.7 Further Resources","text":"Chapter 27: R Markdown R Data ScienceR Markdown Cheat SheetR Markdown reference GuideR Markdown TutorialR Markdown: Definitive Guide Yihui Xie, J. J. Allaire, & Garrett GrolemundProject Structure Danielle NavarroHow name files Jenny BryanPapaja Reproducible APA ManuscriptsThe Turing Way","code":""},{"path":"ggplot.html","id":"ggplot","chapter":"3 Data Visualisation","heading":"3 Data Visualisation","text":"","code":""},{"path":"ggplot.html","id":"ilo-ggplot","chapter":"3 Data Visualisation","heading":"3.1 Learning Objectives","text":"","code":""},{"path":"ggplot.html","id":"basic","chapter":"3 Data Visualisation","heading":"Basic","text":"Understand types graphs best different types data (video)\n1 discrete\n1 continuous\n2 discrete\n2 continuous\n1 discrete, 1 continuous\n3 continuous\n1 discrete1 continuous2 discrete2 continuous1 discrete, 1 continuous3 continuousCreate common types graphs ggplot2 (video)\ngeom_bar()\ngeom_density()\ngeom_freqpoly()\ngeom_histogram()\ngeom_col()\ngeom_boxplot()\ngeom_violin()\nVertical Intervals\ngeom_crossbar()\ngeom_errorbar()\ngeom_linerange()\ngeom_pointrange()\n\ngeom_point()\ngeom_smooth()\ngeom_bar()geom_density()geom_freqpoly()geom_histogram()geom_col()geom_boxplot()geom_violin()Vertical Intervals\ngeom_crossbar()\ngeom_errorbar()\ngeom_linerange()\ngeom_pointrange()\ngeom_crossbar()geom_errorbar()geom_linerange()geom_pointrange()geom_point()geom_smooth()Set custom size,\nlabels,\ncolours, \nthemes (video)Combine plots plot, facets, grid using patchwork (video)Save plots image file (video)","code":""},{"path":"ggplot.html","id":"intermediate","chapter":"3 Data Visualisation","heading":"Intermediate","text":"Add lines graphsDeal overlapping dataCreate less common types graphs\ngeom_tile()\ngeom_density2d()\ngeom_bin2d()\ngeom_hex()\ngeom_count()\ngeom_tile()geom_density2d()geom_bin2d()geom_hex()geom_count()Adjust axes (e.g., flip coordinates, set axis limits)","code":""},{"path":"ggplot.html","id":"setup-ggplot","chapter":"3 Data Visualisation","heading":"3.2 Setup","text":"Open reprores-class-notes projectCreate new R Markdown file called 03-ggplot.RmdUpdate YAML headerReplace setup chunk one :Download ggplot2 cheat sheet.","code":"```{r setup, include = FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n\n# packages needed for this chapter\nlibrary(tidyverse)   # loads ggplot2 for plots\nlibrary(patchwork)   # multi-part plots\nlibrary(plotly)      # interactive plots\nlibrary(ggwordcloud) # word clouds\nlibrary(reprores)    # class-specific datasets\n\nset.seed(30250) # makes sure random numbers are reproducible```"},{"path":"ggplot.html","id":"vartypes","chapter":"3 Data Visualisation","heading":"3.3 Common Variable Combinations","text":"Continuous variables properties can measure, like height. Discrete variables things can count, like number pets . Categorical variables can nominal, categories really order, like cats, dogs ferrets (even though ferrets obviously best). can also ordinal, clear order, distance categories something exactly equate, like points Likert rating scale.Different types visualisations good different types variables.Load pets dataset explore glimpse(pets) View(pets). simulated dataset one random factor (id), two categorical factors (pet, country) three continuous variables (score, age, weight).read ahead, come example type variable combination sketch types graphs best display data.1 categorical1 continuous2 categorical2 continuous1 categorical, 1 continuous3 continuous","code":"\ndata(\"pets\", package = \"reprores\")\n# if you don't have the reprores package, use:\n# pets <- read_csv(\"https://psyteachr.github.io/reprores/data/pets.csv\", col_types = \"cffiid\")\nglimpse(pets)## Rows: 800\n## Columns: 6\n## $ id      <chr> \"S001\", \"S002\", \"S003\", \"S004\", \"S005\", \"S006\", \"S007\", \"S008\"…\n## $ pet     <fct> dog, dog, dog, dog, dog, dog, dog, dog, dog, dog, dog, dog, do…\n## $ country <fct> UK, UK, UK, UK, UK, UK, UK, UK, UK, UK, UK, UK, UK, UK, UK, UK…\n## $ score   <int> 90, 107, 94, 120, 111, 110, 100, 107, 106, 109, 85, 110, 102, …\n## $ age     <int> 6, 8, 2, 10, 4, 8, 9, 8, 6, 11, 5, 9, 1, 10, 7, 8, 1, 8, 5, 13…\n## $ weight  <dbl> 19.78932, 20.01422, 19.14863, 19.56953, 21.39259, 21.31880, 19…"},{"path":"ggplot.html","id":"basic-plots","chapter":"3 Data Visualisation","heading":"3.4 Basic Plots","text":"R basic plotting functions, difficult use aesthetically nice. can useful quick look data working script, though. function plot() usually defaults sensible type plot, depending whether arguments x y categorical, continuous, missing.\nFigure 3.1: plot() categorical x\n\nFigure 3.2: plot() categorical x continuous y\n\nFigure 3.3: plot() continuous x y\nfunction hist() creates quick histogram can see distribution data. can adjust many columns plotted argument breaks.\nFigure 3.4: hist()\n","code":"\nplot(x = pets$pet)\nplot(x = pets$pet, y = pets$score)\nplot(x = pets$age, y = pets$weight)\nhist(pets$score, breaks = 20)"},{"path":"ggplot.html","id":"ggplots","chapter":"3 Data Visualisation","heading":"3.5 GGplots","text":"functions nice quick visualisations, hard make pretty, publication-ready plots. package ggplot2 (loaded tidyverse) one common packages creating beautiful visualisations.ggplot2 creates plots using \"grammar graphics\" add geoms layers. can complex understand, powerful mental model works.start totally empty plot layer created ggplot() function arguments.\nFigure 3.5: plot base created ggplot()\nfirst argument ggplot() data table want plot. use pets data loaded . second argument mapping columns data table correspond properties plot, x-axis, y-axis, line colour linetype, point shape, object fill. mappings specified aes() function. Just adding ggplot function creates labels ranges x y axes. usually sensible default values, given data, learn change later.\nFigure 3.6: Empty ggplot x y labels\nPeople usually omit argument names just put aes() function directly second argument ggplot. also usually omit x y argument names aes() (name properties).Next can add \"geoms\", plot styles. literally add + symbol. can also add plot attributes, labels, change theme base font size.\nFigure 3.7: Violin plot country represented colour.\n","code":"\nggplot()\nmapping <- aes(x = pet, \n               y = score, \n               colour = country, \n               fill = country)\nggplot(data = pets, mapping = mapping)\nggplot(pets, aes(pet, score, colour = country, fill = country)) +\n  geom_violin(alpha = 0.5) +\n  labs(x = \"Pet type\",\n       y = \"Score on an Important Test\",\n       colour = \"Country of Origin\",\n       fill = \"Country of Origin\",\n       title = \"My first plot!\") +\n  theme_bw(base_size = 15)"},{"path":"ggplot.html","id":"common-plot-types","chapter":"3 Data Visualisation","heading":"3.6 Common Plot Types","text":"many geoms, can take different arguments customise appearance. learn common .","code":""},{"path":"ggplot.html","id":"geom_bar","chapter":"3 Data Visualisation","heading":"3.6.1 Bar plot","text":"Bar plots good categorical data want represent count.\nFigure 3.8: Bar plot\n","code":"\nggplot(pets, aes(pet)) +\n  geom_bar()"},{"path":"ggplot.html","id":"geom_density","chapter":"3 Data Visualisation","heading":"3.6.2 Density plot","text":"Density plots good one continuous variable, fairly large number observations.\nFigure 3.9: Density plot\ncan represent subsets variable assigning category variable argument group, fill, color.\nFigure 3.10: Grouped density plot\nTry changing alpha argument figure .","code":"\nggplot(pets, aes(score)) +\n  geom_density()\nggplot(pets, aes(score, fill = pet)) +\n  geom_density(alpha = 0.5)"},{"path":"ggplot.html","id":"geom_freqpoly","chapter":"3 Data Visualisation","heading":"3.6.3 Frequency polygons","text":"want y-axis represent count rather density, try geom_freqpoly().\nFigure 3.11: Frequency ploygon plot\nTry changing binwidth argument 10 1. figure right value?","code":"\nggplot(pets, aes(score, color = pet)) +\n  geom_freqpoly(binwidth = 5)"},{"path":"ggplot.html","id":"geom_histogram","chapter":"3 Data Visualisation","heading":"3.6.4 Histogram","text":"Histograms also good one continuous variable, work well many observations. Set binwidth control wide bar .\nFigure 3.12: Histogram\nHistograms ggplot look pretty bad unless set fill color.show grouped histograms, also probably want change default position argument.\nFigure 3.13: Grouped Histogram\nTry changing position argument \"identity\", \"fill\", \"dodge\", \"stack\".","code":"\nggplot(pets, aes(score)) +\n  geom_histogram(binwidth = 5, fill = \"white\", color = \"black\")\nggplot(pets, aes(score, fill=pet)) +\n  geom_histogram(binwidth = 5, alpha = 0.5, \n                 position = \"dodge\")"},{"path":"ggplot.html","id":"geom_col","chapter":"3 Data Visualisation","heading":"3.6.5 Column plot","text":"Column plots worst way represent grouped continuous data, also one common. data already aggregated (e.g., rows group columns mean standard error), can use geom_bar geom_col geom_errorbar directly. , can use function stat_summary calculate mean standard error send numbers appropriate geom plotting.\nFigure 3.14: Column plot\nTry changing values coord_cartesian. ?","code":"\nggplot(pets, aes(pet, score, fill=pet)) +\n  stat_summary(fun = mean, geom = \"col\", alpha = 0.5) + \n  stat_summary(fun.data = mean_se, geom = \"errorbar\",\n               width = 0.25) +\n  coord_cartesian(ylim = c(80, 120))"},{"path":"ggplot.html","id":"geom_boxplot","chapter":"3 Data Visualisation","heading":"3.6.6 Boxplot","text":"Boxplots great representing distribution grouped continuous variables. fix problems using bar/column plots continuous data.\nFigure 3.15: Box plot\n","code":"\nggplot(pets, aes(pet, score, fill=pet)) +\n  geom_boxplot(alpha = 0.5)"},{"path":"ggplot.html","id":"geom_violin","chapter":"3 Data Visualisation","heading":"3.6.7 Violin plot","text":"Violin pots like sideways, mirrored density plots. give even information boxplot distribution especially useful non-normal distributions.\nFigure 3.16: Violin plot\nTry changing quantile argument. Set vector numbers 0.1 0.9 steps 0.1.","code":"\nggplot(pets, aes(pet, score, fill=pet)) +\n  geom_violin(draw_quantiles = .5,\n              trim = FALSE, alpha = 0.5,)"},{"path":"ggplot.html","id":"vertical_intervals","chapter":"3 Data Visualisation","heading":"3.6.8 Vertical intervals","text":"Boxplots violin plots always map well onto inferential stats use mean. can represent mean standard error value can calculate., create table means standard errors two groups. learn calculate raw data chapter data wrangling. also create new object called gg sets base plot.trick can useful want represent data different ways. can add different geoms base plot without re-type base plot code.\nFigure 3.17: geom_crossbar()\n\nFigure 3.18: geom_errorbar()\n\nFigure 3.19: geom_linerange()\n\nFigure 3.20: geom_pointrange()\ncan also use function stats_summary calculate mean, standard error, value data display using geom.\nFigure 3.21: Vertical intervals stats_summary()\n","code":"\ndat <- tibble(\n  group = c(\"A\", \"B\"),\n  mean = c(10, 20),\n  se = c(2, 3)\n)\ngg <- ggplot(dat, aes(group, mean, \n                      ymin = mean-se, \n                      ymax = mean+se))\ngg + geom_crossbar()\ngg + geom_errorbar()\ngg + geom_linerange()\ngg + geom_pointrange()\nggplot(pets, aes(pet, score, color=pet)) +\n  stat_summary(fun.data = mean_se, geom = \"crossbar\") +\n  stat_summary(fun.min = function(x) mean(x) - sd(x),\n               fun.max = function(x) mean(x) + sd(x),\n               geom = \"errorbar\", width = 0) +\n  theme(legend.position = \"none\") # gets rid of the legend"},{"path":"ggplot.html","id":"geom_point","chapter":"3 Data Visualisation","heading":"3.6.9 Scatter plot","text":"Scatter plots good way represent relationship two continuous variables.\nFigure 3.22: Scatter plot using geom_point()\n","code":"\nggplot(pets, aes(age, score, color = pet)) +\n  geom_point()"},{"path":"ggplot.html","id":"geom_smooth","chapter":"3 Data Visualisation","heading":"3.6.10 Line graph","text":"often want represent relationship single line.\nFigure 3.23: Line plot using geom_smooth()\noptions method argument geom_smooth? might want use ?can plot functions linear y ~ x. code creates data table x 101 values -10 10. y x squared plus 3*x plus 1. probably recognise algebra quadratic equation. can set formula argument geom_smooth quadratic formula (y ~ x + (x^2)) fit quadratic function data.\nFigure 3.24: Fitting quadratic functions\n","code":"\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y ~ x, method=\"lm\")\nquad <- tibble(\n  x = seq(-10, 10, length.out = 101),\n  y = x^2 + 3*x + 1\n)\n\nggplot(quad, aes(x, y)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x + I(x^2), \n              method=\"lm\")"},{"path":"ggplot.html","id":"customisation","chapter":"3 Data Visualisation","heading":"3.7 Customisation","text":"","code":""},{"path":"ggplot.html","id":"custom-size","chapter":"3 Data Visualisation","heading":"3.7.1 Size and Position","text":"can change size, aspect ratio position plots R Markdown document setup chunk.can change defaults single image using chunk options.\nFigure 3.25: 10x3 inches 100% width centre aligned.\n\nFigure 3.26: 5x3 inches 50% width aligned left.\n","code":"\nknitr::opts_chunk$set(\n  fig.width  = 8, # figures default to 8 inches wide\n  fig.height = 5, # figures default to 5 inches tall\n  fig.path   = 'images/', # figures saved in images directory\n  out.width = \"90%\", # images take up 90% of page width\n  fig.align = 'center' # centre images\n)```{r fig-pet1, fig.width=10, fig.height=3, out.width=\"100%\", fig.align=\"center\", fig.cap=\"10x3 inches at 100% width centre aligned.\"}\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y~x, method = lm)``````{r fig-pet2, fig.width=5, fig.height=3, out.width=\"50%\", fig.align=\"left\", fig.cap=\"5x3 inches at 50% width aligned left.\"}\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y~x, method = lm)```"},{"path":"ggplot.html","id":"custom-labels","chapter":"3 Data Visualisation","heading":"3.7.2 Labels","text":"can set custom titles axis labels different ways.\nFigure 3.27: Set custom labels labs()\n\nFigure 3.28: Set custom labels individual functions\nfunctions labs(), xlab(), ylab() convenient just want change label name, scale_{aesthetic}_{type} functions worth learning let customise many things aesthetic property (e.g., x, y, colour, fill, shape, linetype), long choose correct type (usually continuous discrete, also special scale functions data types like dates).\nFigure 3.29: Set custom labels scale functions\nUse help scale functions learn possible arguments. See happens change arguments .","code":"\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y ~ x, method=\"lm\") +\n  labs(title = \"Pet Score with Age\",\n       x = \"Age (in Years)\",\n       y = \"Pet Score\",\n       color = \"Pet Type\")\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y ~ x, method=\"lm\") +\n  ggtitle(\"Pet Score with Age\") +\n  xlab(\"Age (in Years)\") +\n  ylab(\"Pet Score\")\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y ~ x, method=\"lm\") +\n  ggtitle(\"Pet Score with Age\") +\n  scale_x_continuous(name = \"Age (in Years)\", \n                     breaks = 0:16,\n                     minor_breaks = NULL, \n                     trans = \"reverse\",\n                     position = \"top\") +\n  scale_y_continuous(name = \"Pet Score\", \n                     n.breaks = 16, \n                     limits = c(0, 150)) +\n  scale_color_discrete(name = \"Pet Type\", \n                       labels = c(\"Dogs\", \"Cats\", \"Ferrets\"), \n                       type = c(\"purple\", \"green\", \"orange\"))"},{"path":"ggplot.html","id":"custom-colours","chapter":"3 Data Visualisation","heading":"3.7.3 Colours","text":"can set custom values colour fill using scale_{aesthetic}_{type} functions like scale_colour_manual() scale_fill_manual().\nFigure 3.30: Set custom colour\nColours chapter Cookbook R many ways customise colour.","code":"\nggplot(pets, aes(pet, score, colour = pet, fill = pet)) +\n  geom_violin() +\n  scale_color_manual(values = c(\"darkgreen\", \"dodgerblue\", \"orange\")) +\n  scale_fill_manual(values = c(\"#CCFFCC\", \"#BBDDFF\", \"#FFCC66\"))"},{"path":"ggplot.html","id":"themes","chapter":"3 Data Visualisation","heading":"3.7.4 Themes","text":"GGplot comes several additional themes ability fully customise theme. Type ?theme console see full list. packages cowplot also custom themes. can add custom theme end ggplot object specify new base_size make default fonts lines larger smaller.\nFigure 3.31: Minimal theme 18-point base font size\ncomplicated, can fully customise theme theme(). can save object add end plots make style consistent. Alternatively, can set theme top script theme_set() apply subsequent ggplot plots.\nFigure 3.32: Custom theme\n","code":"\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y ~ x, method=\"lm\") +\n  theme_minimal(base_size = 18)\n# always start with a base theme that is closest to your desired theme\nvampire_theme <- theme_dark() +\n  theme(\n    rect = element_rect(fill = \"black\"),\n    panel.background = element_rect(fill = \"black\"),\n    text = element_text(size = 20, colour = \"white\"),\n    axis.text = element_text(size = 16, colour = \"grey70\"),\n    line = element_line(colour = \"white\", size = 2),\n    panel.grid = element_blank(),\n    axis.line = element_line(colour = \"white\"),\n    axis.ticks = element_blank(),\n    legend.position = \"top\"\n  )\n\ntheme_set(vampire_theme)\n\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y ~ x, method=\"lm\")"},{"path":"ggplot.html","id":"ggsave","chapter":"3 Data Visualisation","heading":"3.7.5 Save as file","text":"can save ggplot using ggsave(). saves last ggplot made, default, can specify plot want save assigned plot variable.can set width height plot. default units inches, can change units argument \"\", \"cm\", \"mm\".file type set filename suffix, \nspecifying argument device, can take following values:\n\"eps\", \"ps\", \"tex\", \"pdf\", \"jpeg\", \"tiff\", \"png\", \"bmp\", \"svg\" \"wmf\".","code":"\nbox <- ggplot(pets, aes(pet, score, fill=pet)) +\n  geom_boxplot(alpha = 0.5)\n\nviolin <- ggplot(pets, aes(pet, score, fill=pet)) +\n  geom_violin(alpha = 0.5)\n\nggsave(\"demog_violin_plot.png\", width = 5, height = 7)\n\nggsave(\"demog_box_plot.jpg\", plot = box, width = 5, height = 7)"},{"path":"ggplot.html","id":"combo_plots","chapter":"3 Data Visualisation","heading":"3.8 Combination Plots","text":"","code":""},{"path":"ggplot.html","id":"violinbox-plot","chapter":"3 Data Visualisation","heading":"3.8.1 Violinbox plot","text":"combination violin plot show shape distribution boxplot show median interquartile ranges can useful visualisation.\nFigure 3.33: Violin-box plot\nSet show.legend argument FALSE hide legend. x-axis already labels pet types.","code":"\nggplot(pets, aes(pet, score, fill = pet)) +\n  geom_violin(show.legend = FALSE) + \n  geom_boxplot(width = 0.2, fill = \"white\", \n               show.legend = FALSE)"},{"path":"ggplot.html","id":"violin-point-range-plot","chapter":"3 Data Visualisation","heading":"3.8.2 Violin-point-range plot","text":"can use stat_summary() superimpose point-range plot showing mean ± 1 SD. learn write functions lesson Iteration Functions.\nFigure 3.34: Point-range plot using stat_summary()\n","code":"\nggplot(pets, aes(pet, score, fill=pet)) +\n  geom_violin(trim = FALSE, alpha = 0.5) +\n  stat_summary(\n    fun = mean,\n    fun.max = function(x) {mean(x) + sd(x)},\n    fun.min = function(x) {mean(x) - sd(x)},\n    geom=\"pointrange\"\n  )"},{"path":"ggplot.html","id":"violin-jitter-plot","chapter":"3 Data Visualisation","heading":"3.8.3 Violin-jitter plot","text":"lot data points, good represent individually. can use geom_jitter .\nFigure 3.35: Violin-jitter plot\n","code":"\n# sample_n chooses 50 random observations from the dataset\nggplot(sample_n(pets, 50), aes(pet, score, fill=pet)) +\n  geom_violin(\n    trim = FALSE,\n    draw_quantiles = c(0.25, 0.5, 0.75), \n    alpha = 0.5\n  ) + \n  geom_jitter(\n    width = 0.15, # points spread out over 15% of available width\n    height = 0, # do not move position on the y-axis\n    alpha = 0.5, \n    size = 3\n  )"},{"path":"ggplot.html","id":"scatter-line-graph","chapter":"3 Data Visualisation","heading":"3.8.4 Scatter-line graph","text":"graph complicated, good also show individual data points behind line.\nFigure 3.36: Scatter-line plot\n","code":"\nggplot(sample_n(pets, 50), aes(age, weight, colour = pet)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method=\"lm\")"},{"path":"ggplot.html","id":"plot_grid","chapter":"3 Data Visualisation","heading":"3.8.5 Grid of plots","text":"can use patchwork package easily make grids different graphs. First, assign plot name.add plots together.\nFigure 3.37: Default grid plots\ncan use +, |, /, parentheses customise layout.\nFigure 3.38: Custom plot layout.\ncan alter plot layout control number widths plots per row column, add annotation.\nFigure 3.39: Plot annotation.\nCheck help plot_layout() plot_annotation()` see else can .","code":"\ngg <- ggplot(pets, aes(pet, score, colour = pet))\nnolegend <- theme(legend.position = 0)\n\nvp <- gg + geom_violin(alpha = 0.5) + nolegend +\n  ggtitle(\"Violin Plot\")\nbp <- gg + geom_boxplot(alpha = 0.5) + nolegend +\n  ggtitle(\"Box Plot\")\ncp <- gg + stat_summary(fun = mean, geom = \"col\", fill = \"white\") + nolegend +\n  ggtitle(\"Column Plot\")\ndp <- ggplot(pets, aes(score, colour = pet)) + \n  geom_density() + nolegend +\n  ggtitle(\"Density Plot\")\nvp + bp + cp + dp\n(vp | bp | cp) / dp\nvp + bp + cp + \n  plot_layout(nrow = 1, width = c(1,2,1)) +\n  plot_annotation(title = \"Pet Scores\",\n                  subtitle = \"Three plots visualising the same data\",\n                  tag_levels = \"a\")"},{"path":"ggplot.html","id":"overlap","chapter":"3 Data Visualisation","heading":"3.9 Overlapping Discrete Data","text":"","code":""},{"path":"ggplot.html","id":"reducing-opacity","chapter":"3 Data Visualisation","heading":"3.9.1 Reducing Opacity","text":"can deal overlapping data points (common using Likert scales) reducing opacity points. need use trial error adjust look right.\nFigure 3.40: Deal overlapping data using transparency\n","code":"\nggplot(pets, aes(age, score, colour = pet)) +\n  geom_point(alpha = 0.25) +\n  geom_smooth(formula = y ~ x, method=\"lm\")"},{"path":"ggplot.html","id":"geom_count","chapter":"3 Data Visualisation","heading":"3.9.2 Proportional Dot Plots","text":"can set size dot proportional number overlapping observations using geom_count().\nFigure 3.41: Deal overlapping data using geom_count()\nAlternatively, can transform data (learn data wrangling chapter) create count column use count set dot colour.\nFigure 3.42: Deal overlapping data using dot colour\nviridis package changes colour themes easier read people colourblindness print better greyscale. Viridis built ggplot2 since v3.0.0. uses scale_colour_viridis_c() scale_fill_viridis_c() continuous variables scale_colour_viridis_d() scale_fill_viridis_d() discrete variables.","code":"\nggplot(pets, aes(age, score, colour = pet)) +\n  geom_count()\npets %>%\n  group_by(age, score) %>%\n  summarise(count = n(), .groups = \"drop\") %>%\n  ggplot(aes(age, score, color=count)) +\n  geom_point(size = 2) +\n  scale_color_viridis_c()"},{"path":"ggplot.html","id":"overlapping-continuous-data","chapter":"3 Data Visualisation","heading":"3.10 Overlapping Continuous Data","text":"Even variables continuous, overplotting might obscure relationships lots data.\nFigure 3.43: Overplotted data\n","code":"\nggplot(pets, aes(age, score)) +\n  geom_point()"},{"path":"ggplot.html","id":"geom_density2d","chapter":"3 Data Visualisation","heading":"3.10.1 2D Density Plot","text":"Use geom_density2d() create contour map.\nFigure 3.44: Contour map geom_density2d()\ncan use geom_density2d_filled() create heatmap-style density plot.\nFigure 3.45: Heatmap-density plot\nTry geom_density2d_filled(n = 5, h = 10) instead. Play different values n h try guess .","code":"\nggplot(pets, aes(age, score)) +\n  geom_density2d()\nggplot(pets, aes(age, score)) +\n  geom_density2d_filled(n = 5, h = 10)"},{"path":"ggplot.html","id":"geom_bin2d","chapter":"3 Data Visualisation","heading":"3.10.2 2D Histogram","text":"Use geom_bin2d() create rectangular heatmap bin counts. Set binwidth x y dimensions capture box.\nFigure 3.46: Heatmap bin counts\n","code":"\nggplot(pets, aes(age, score)) +\n  geom_bin2d(binwidth = c(1, 5))"},{"path":"ggplot.html","id":"geom_hex","chapter":"3 Data Visualisation","heading":"3.10.3 Hexagonal Heatmap","text":"Use geomhex() create hexagonal heatmap bin counts. Adjust binwidth, xlim(), ylim() /figure dimensions make hexagons less stretched.\nFigure 3.47: Hexagonal heatmap bin counts\n","code":"\nggplot(pets, aes(age, score)) +\n  geom_hex(binwidth = c(1, 5))## Warning: Computation failed in `stat_binhex()`:"},{"path":"ggplot.html","id":"geom_tile","chapter":"3 Data Visualisation","heading":"3.10.4 Correlation Heatmap","text":"included code creating correlation matrix table variables, need understand done yet. cover mutate() gather() functions dplyr tidyr lessons.correlation matrix correct (long) format, easy make heatmap using geom_tile().\nFigure 3.48: Heatmap using geom_tile()\n","code":"\nheatmap <- pets %>%\n  select_if(is.numeric) %>% # get just the numeric columns\n  cor() %>% # create the correlation matrix\n  as_tibble(rownames = \"V1\") %>% # make it a tibble\n  gather(\"V2\", \"r\", 2:ncol(.)) # wide to long (V2)\nggplot(heatmap, aes(V1, V2, fill=r)) +\n  geom_tile() +\n  scale_fill_viridis_c()"},{"path":"ggplot.html","id":"glossary-ggplot","chapter":"3 Data Visualisation","heading":"3.11 Glossary","text":"","code":""},{"path":"ggplot.html","id":"resources-ggplot","chapter":"3 Data Visualisation","heading":"3.12 Further Resources","text":"Data visualisation using R, researchers use RChapter 3: Data Visualisation R Data Scienceggplot2 cheat sheetggplot2 FAQsChapter 28: Graphics communication R Data ScienceLook Data Data Vizualization Social ScienceHack Data Beautiful workshop University Glasgow postgraduate studentsGraphs Cookbook Rggplot2 documentationThe R Graph Gallery (really useful)Top 50 ggplot2 VisualizationsR Graphics Cookbook Winston Changggplot extensionsplotly creating interactive graphs","code":""},{"path":"data.html","id":"data","chapter":"4 Working with Data","heading":"4 Working with Data","text":"","code":""},{"path":"data.html","id":"ilo-data","chapter":"4 Working with Data","heading":"4.1 Learning Objectives","text":"able structure data scriptingLoad built-datasets (video)Import data CSV Excel files (video)Create data table (video)Understand use basic data types (video)Understand use basic container types (list, vector) (video)Use vectorized operations (video)able troubleshoot common data import problems (video)chapter lot jargon. Becoming familiar terms can help ask questions clearly search answers online. Keywords shown purple; can view short definition hovering access detailed definition clicking . defined words glossary end chapter.","code":""},{"path":"data.html","id":"setup-data","chapter":"4 Working with Data","heading":"4.2 Setup","text":"Open reprores-class-notes projectCreate new R Markdown file called 04-data.RmdUpdate YAML headerReplace setup chunk one :Download Data import cheatsheet.","code":"```{r setup, include = FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n\n# packages needed for this chapter\nlibrary(tidyverse)     # loads readr for importing data\n                       #   and tibble for creating tables\nlibrary(readxl)        # importing excel files\nlibrary(googlesheets4) # importing google sheets\nlibrary(haven)         # importing SPSS files\nlibrary(jsonlite)      # importing JSON files\nlibrary(rio)           # importing and exporting many types of files\nlibrary(skimr)         # summarising datasets\nlibrary(reprores)      # class-specific datasets```"},{"path":"data.html","id":"data-structure","chapter":"4 Working with Data","heading":"4.3 Data structure","text":"probably familiar data recorded Excel spreadsheets. fine data entry, prone error used calculations analysis (see horror stories). Broman & Woo (2018) recommend following several guidelines less error-prone use spreadsheets. paper well worth reading, summarise important guidelines .","code":""},{"path":"data.html","id":"be-consistent","chapter":"4 Working with Data","heading":"4.3.1 Be consistent","text":"Use names columns different data files, exact format categorical values. Capitalisation spaces also matter. example, record group \"\", \"\", \"\" different places (column); treated computational script three different values.column names items might want group later, questionnaire items belonging one three subscales, use consistent naming convention. make easier reshape data create subscale scores, cover Chapter 6.4. example, use column names like O_1, E_2, O_3, C_4 rather q1, q2, q3, q4. (Alternatively, can include separate table column question number corresponding column subscale join reformatted questionnaire data, learn Chapter 5.)","code":""},{"path":"data.html","id":"choose-good-names-for-things","chapter":"4 Working with Data","heading":"4.3.2 Choose good names for things","text":"covered Chapter 2.4.3 file names. also important use names variables values make easy work R. example, use column names letters, numbers, full stops underscores quote . Using camel case OK, just use consistent naming scheme keep looking whether named column SleepTime, sleepTime, sleep_time sleep.time.Choose best consistent column names single data file:subject.idsubject IDsidsubject_idAge (months)ageage_monthsageMonthsbybirth_yearBirth Yearbirth-year","code":""},{"path":"data.html","id":"write-dates-as-yyyy-mm-dd","chapter":"4 Working with Data","heading":"4.3.3 Write dates as YYYY-MM-DD","text":"format nearly impossible misinterpret (unlike formats like \"01/02/03\") sorts sensible order (unlike \"January 2, 2003\" \"2-1-03\").","code":""},{"path":"data.html","id":"no-empty-cells","chapter":"4 Working with Data","heading":"4.3.4 No empty cells","text":"strict one, think missing values either empty cells (\"\") NA consistent across data sets. use values, requires extra steps data import (see Section 4.4.2.3 ).","code":""},{"path":"data.html","id":"put-just-one-thing-in-a-cell","chapter":"4 Working with Data","heading":"4.3.5 Put just one thing in a cell","text":"put two pieces information cell. example, rather column called id-group containing subject ID experimental group (e.g., \"001A\"), record info two columns, id group. learn tidy data Chapter 6.","code":""},{"path":"data.html","id":"make-it-a-rectangle","chapter":"4 Working with Data","heading":"4.3.6 Make it a rectangle","text":"merging cells putting extra info cells spreadsheet can look nice, nightmare data import.\nFigure 4.1: Data multiple headers merged cells can take many extra steps import.\nlearn data formats better represent data like Chapter 6. See blog post solutions deal data like .","code":""},{"path":"data.html","id":"create-a-data-dictionary","chapter":"4 Working with Data","heading":"4.3.7 Create a data dictionary","text":"may think column names factor labels intuitive, researchers future thank creating data dictionary.can create data dictionary manually, use R package help make data imported R. Crystal Lewis reviews , like codebookr.","code":""},{"path":"data.html","id":"no-calculations-in-the-raw-data-files","chapter":"4 Working with Data","heading":"4.3.8 No calculations in the raw data files","text":"learning R !","code":""},{"path":"data.html","id":"do-not-use-font-colour-or-highlighting","chapter":"4 Working with Data","heading":"4.3.9 Do not use font colour or highlighting","text":"ways extract computationally, complex annoying deal . tempted use colour highlight something like outliers, add column TRUE/FALSE text values instead.Find paper Psychological Science another journal encourages data sharing. Find paper interested shares data (usually badge ) download data (usually listed \"Open Practices\" section end). Access data assess well follow guidelines .","code":""},{"path":"data.html","id":"data-tables","chapter":"4 Working with Data","heading":"4.4 Data tables","text":"","code":""},{"path":"data.html","id":"builtin","chapter":"4 Working with Data","heading":"4.4.1 Built-in data","text":"R comes built-datasets. packages, like tidyr reprores, also contain data. data() function lists datasets available package.Type name dataset console see data. Type ?smalldata console see dataset description.can also use data() function load dataset global environment.Always, always, always, look data created loaded table. Also look step transforms table. three main ways look tibble: print(), glimpse(), View().print() method can run explicitly, commonly called just typing variable name blank line. default print entire table, just first 10 rows. rare print data script; something usually sanity check, just console.look smalldata table made .function glimpse() gives sideways version tibble. useful table wide see columns. also tells data type column angled brackets column name. learn data types .way look table graphical spreadsheet-like version given View() (capital 'V'). can useful console, ever put one script create annoying pop-window user runs .\nNow can click smalldata environment pane open viewer looks bit like Excel.can get quick summary dataset summary() function.can even things like calculate difference means two columns.","code":"\n# lists datasets in reprores\ndata(package = \"reprores\")\nsmalldata\n# loads smalldata into the environment\ndata(\"smalldata\")\nsmalldata\nglimpse(smalldata)## Rows: 10\n## Columns: 4\n## $ id    <chr> \"S01\", \"S02\", \"S03\", \"S04\", \"S05\", \"S06\", \"S07\", \"S08\", \"S09\", \"…\n## $ group <chr> \"control\", \"control\", \"control\", \"control\", \"control\", \"exp\", \"e…\n## $ pre   <dbl> 98.46606, 104.39774, 105.13377, 92.42574, 123.53268, 97.48676, 8…\n## $ post  <dbl> 106.70508, 89.09030, 123.67230, 70.70178, 124.95526, 101.61697, …\nsummary(smalldata)##       id               group                pre              post       \n##  Length:10          Length:10          Min.   : 77.15   Min.   : 70.70  \n##  Class :character   Class :character   1st Qu.: 93.57   1st Qu.: 92.22  \n##  Mode  :character   Mode  :character   Median : 97.98   Median :107.76  \n##                                        Mean   : 98.57   Mean   :103.79  \n##                                        3rd Qu.:103.88   3rd Qu.:121.19  \n##                                        Max.   :123.53   Max.   :126.30\npre_mean <- mean(smalldata$pre)\npost_mean <- mean(smalldata$post)\npost_mean - pre_mean## [1] 5.223055"},{"path":"data.html","id":"import_data","chapter":"4 Working with Data","heading":"4.4.2 Importing data","text":"Built-data nice examples, probably interested data. many different types files might work data analysis. different file types usually distinguished three letter extension following period end file name. examples different types files functions use read write .double colon means function right comes package left, readr::read_csv() refers read_csv() function readr package, readxl::read_excel() refers function read_excel() readxl package. function rio::import() rio package read almost type data file, including SPSS Matlab. Check help ?rio::import see full list.can get directory data files used class tutorials exercises following code, create directory called \"data\" project directory. Alternatively, can download zip file datasets.","code":"\nreprores::getdata()"},{"path":"data.html","id":"csv-files","chapter":"4 Working with Data","heading":"4.4.2.1 CSV Files","text":"common file type encounter class .csv (comma-separated values). name suggests, CSV file distinguishes values go variable separating commas, text values sometimes enclosed double quotes. first line file usually provides names variables.example, small CSV containing demo data:five variables dataset, names given first line file: character, integer, double ,`logical, date. can see values variables given order, separated commas, subsequent line file.Use readr::read_csv() read data assign object called demo_csv.function give information data just read can check column names data types. makes mistake, reading \"date\" column character, can manually set column data types. Just copy \"Column specification\" printed first imported data, make changes need.dates, might need set format. See ?strptime list codes used represent different date formats. , \"%d-%b-%y\" means dates formatted like {day number}-{month abbreviation}-{2-digit year}.learn fix data import problems troubleshooting section .","code":"```\ncharacter,integer,double,logical,date\nA,1,1.5,TRUE,05-Sep-21\nB,2,2.5,TRUE,04-Sep-21\nC,3,3.5,FALSE,03-Sep-21\nD,4,4.5,FALSE,02-Sep-21\nE,5,5.5,,01-Sep-21\nF,6,6.5,TRUE,31-Aug-21\n```\ndemo_csv  <- readr::read_csv(\"data/demo.csv\")## Rows: 6 Columns: 5\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (2): character, date\n## dbl (2): integer, double\n## lgl (1): logical\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nct <- cols(\n  character = col_character(),\n  integer = col_double(),\n  double = col_double(),\n  logical = col_logical(),\n  date = col_date(format = \"%d-%b-%y\")\n)\n\ndemo  <- readr::read_csv(\"data/demo.csv\", col_types = ct)"},{"path":"data.html","id":"other-file-types","chapter":"4 Working with Data","heading":"4.4.2.2 Other File Types","text":"Use functions read file types.can access Google Sheets directly R using googlesheets4.Try loading five 5factor datasets data directory.","code":"\ndemo_tsv  <- readr::read_tsv(\"data/demo.tsv\")\ndemo_xls  <- readxl::read_excel(\"data/demo.xlsx\")\ndemo_sav  <- haven::read_sav(\"data/demo.sav\")\ndemo_json <- jsonlite::read_json(\"data/demo.json\")\ngooglesheets4::gs4_deauth() # skip authorisation for public data\n\nurl <- \"https://docs.google.com/spreadsheets/d/16dkq0YL0J7fyAwT1pdgj1bNNrheckAU_2-DKuuM6aGI/\"\n\ndemo_goo  <- googlesheets4::read_sheet(url)\nocean_csv  <- readr::read_csv(\"data/5factor.csv\")\nocean_tsv  <- readr::read_tsv(\"data/5factor.txt\")\nocean_xls  <- readxl::read_excel(\"data/5factor.xls\")\nocean_xlsx <- readxl::read_excel(\"data/5factor.xlsx\")\nocean_sav  <- haven::read_sav(\"data/5factor.sav\")"},{"path":"data.html","id":"missing-values","chapter":"4 Working with Data","heading":"4.4.2.3 Missing Values","text":"represent missing values anything blank cell \"NA\", need specify . Set argument na vector values used represent missing data. default set c(\"\", \"NA\"), also need change valid values really word \"NA\", 2-letter ISO country code Nigeria.","code":"\n# make a short CSV string with two types of missing values\ncsv_text <- \"id, country\n              1, UK\n              2, missing\n              3, \n              4, NA\"\n\nreadr::read_csv(csv_text, na = c(\"\", \"missing\"),\n                show_col_types = FALSE)"},{"path":"data.html","id":"inspecting-data","chapter":"4 Working with Data","heading":"4.4.3 Inspecting data","text":"Now loaded data, look upper right hand window RStudio, Environment tab. see objects listed, along number observations (rows) variables (columns). first check everything went OK.Always, always, always, inspect data created loaded table step transforms table. quickest basic way look table using View() print(). can also use functions like tibble::glimpse(), summary() skimr::skim() summarise data. Finally, best way really understand data plot using skills learned Chapter 3.","code":""},{"path":"data.html","id":"viewing-data","chapter":"4 Working with Data","heading":"4.4.3.1 Viewing data","text":"familiar way look table given View() (uppercase 'V'). command can useful console, ever put one script create annoying pop-window user runs . can click objects environment pane open viewer looks bit like Excel. can close tab done looking ; remove object.print() method can run explicitly, commonly called just typing variable name blank line. default print entire table, just first 10 rows.look demo_tsv table loaded . Depending wide screen , might need click arrow right table see last column.Remember way tables displayed can look different interactive interface knit version, depending df_print set.","code":"\ndemo_tsv"},{"path":"data.html","id":"summarising-data","chapter":"4 Working with Data","heading":"4.4.3.2 Summarising data","text":"function tibble::glimpse() gives sideways version table. useful table wide see columns. also tells data type column angled brackets column name.can get quick summary dataset summary() function.packages can give detailed summary, skimr.\nTable 4.1: Data summary\nVariable type: characterVariable type: DateVariable type: logicalVariable type: numeric","code":"\nglimpse(demo_xls)## Rows: 6\n## Columns: 5\n## $ character <chr> \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n## $ integer   <dbl> 1, 2, 3, 4, 5, 6\n## $ double    <dbl> 1.5, 2.5, 3.5, 4.5, 5.5, 6.5\n## $ logical   <lgl> TRUE, TRUE, FALSE, FALSE, NA, TRUE\n## $ date      <chr> \"05-Sep-21\", \"04-Sep-21\", \"03-Sep-21\", \"02-Sep-21\", \"01-Sep-…\nsummary(demo_sav)##   character            integer         double        logical   \n##  Length:6           Min.   :1.00   Min.   :1.50   Min.   :0.0  \n##  Class :character   1st Qu.:2.25   1st Qu.:2.75   1st Qu.:0.0  \n##  Mode  :character   Median :3.50   Median :4.00   Median :1.0  \n##                     Mean   :3.50   Mean   :4.00   Mean   :0.6  \n##                     3rd Qu.:4.75   3rd Qu.:5.25   3rd Qu.:1.0  \n##                     Max.   :6.00   Max.   :6.50   Max.   :1.0  \n##                                                   NA's   :1    \n##      date          \n##  Length:6          \n##  Class :character  \n##  Mode  :character  \n##                    \n##                    \n##                    \n## \nskimr::skim(demo)"},{"path":"data.html","id":"creating-data","chapter":"4 Working with Data","heading":"4.4.4 Creating data","text":"creating data table scratch, can use tibble::tibble() function, type data right . tibble package part tidyverse package loaded start chapter.create small table names three Avatar characters bending type. tibble() function takes arguments names want columns . values vectors list column values order.know value one cells, can enter NA, Sokka bending ability. values column , can just enter one value copied row.","code":"\navatar <- tibble(\n  name = c(\"Katara\", \"Toph\", \"Sokka\"),\n  bends = c(\"water\", \"earth\", NA),\n  friendly = TRUE\n)\n\n# print it\navatar"},{"path":"data.html","id":"writing-data","chapter":"4 Working with Data","heading":"4.4.5 Writing Data","text":"data want save CSV file, use readr::write_csv(), follows.save data CSV format working directory.Writing Google Sheets little trickier. Even Google Sheet publicly editable, add data without authorising account.can authorise interactively using following code (email), prompt authorise \"Tidyverse API Packages\" first time .Create new table called family first name, last name, age family members.Save CSV file called family.csv.Clear object environment restarting R code remove(family).Load data back view .working tabular data lot class, tabular data made vectors, group together data basic data type. following sections explain terminology help understand functions learning process analyse data.","code":"\nwrite_csv(avatar, \"avatar.csv\")\ngs4_auth(email = \"debruine@gmail.com\")\nsheet_id <- gs4_create(\"demo-file\", sheets = demo)\n\nnew_data <- tibble(\n  character = \"Z\",\n  integer = 0L,\n  double = 0.5,\n  logical = FALSE,\n  date = \"01-Jan-00\"\n)\n\nsheet_append(sheet_id, new_data)\ndemo <- read_sheet(sheet_id)\n# create the table\nfamily <- tribble(\n  ~first_name, ~last_name, ~age,\n  \"Lisa\", \"DeBruine\", 45,\n  \"Robbie\", \"Jones\", 14\n)\n\n# save the data to CSV\nexport(family, \"data/family.csv\")\n\n# remove the object from the environment\nremove(family)\n\n# load the data\nfamily <- import(\"data/family.csv\")"},{"path":"data.html","id":"data_types","chapter":"4 Working with Data","heading":"4.5 Basic data types","text":"Data can numbers, words, true/false values combinations . basic data types R : numeric, character, logical, well special classes factor date/times.\nFigure 4.2: Data types like categories format cells Excel.\n","code":""},{"path":"data.html","id":"numeric-data","chapter":"4 Working with Data","heading":"4.5.1 Numeric data","text":"real numbers numeric data types (imaginary numbers \"complex\"). two types numeric data, integer double. Integers whole numbers, like -1, 0 1. Doubles numbers can fractional amounts. just type plain number 10, stored double, even decimal point. want exact integer, use L suffix (10L).ever want know data type something, use typeof() function.want know something numeric (double integer), can use function .numeric() tell numeric (TRUE) (FALSE).","code":"\ntypeof(10)   # double\ntypeof(10.0) # double\ntypeof(10L)  # integer\ntypeof(10i)  # complex## [1] \"double\"\n## [1] \"double\"\n## [1] \"integer\"\n## [1] \"complex\"\nis.numeric(10L)\nis.numeric(10.0)\nis.numeric(\"Not a number\")## [1] TRUE\n## [1] TRUE\n## [1] FALSE"},{"path":"data.html","id":"character-data","chapter":"4 Working with Data","heading":"4.5.2 Character data","text":"Characters (also called \"strings\") text quotation marks.can include quotes, escape using backslash signal quote meant end string.","code":"\ntypeof(\"This is a character string\")\ntypeof('You can use double or single quotes')## [1] \"character\"\n## [1] \"character\"\nmy_string <- \"The instructor said, \\\"R is cool,\\\" and the class agreed.\"\ncat(my_string) # cat() prints the arguments## The instructor said, \"R is cool,\" and the class agreed."},{"path":"data.html","id":"logical-data","chapter":"4 Working with Data","heading":"4.5.3 Logical Data","text":"Logical data (also sometimes called \"boolean\" values) one two values: true false. R, always write uppercase: TRUE FALSE.might also see logical values abbreviated T F, 0 1. can cause problems road, always spell whole thing.R Markdown headers use YAML format, R, logical values lowercase true false without quotes.compare two values operator, checking see 10 greater 5, resulting value logical.","code":"\nclass(TRUE)\nclass(FALSE)## [1] \"logical\"\n## [1] \"logical\"\nis.logical(10 > 5)## [1] TRUE"},{"path":"data.html","id":"factors","chapter":"4 Working with Data","heading":"4.5.4 Factors","text":"factor specific type integer lets specify categories order. useful data tables make plots display categories correct order.Factors type integer, can tell factors checking class().","code":"\nmyfactor <- factor(\"B\", levels = c(\"A\", \"B\",\"C\"))\nmyfactor## [1] B\n## Levels: A B C\ntypeof(myfactor)\nclass(myfactor)## [1] \"integer\"\n## [1] \"factor\""},{"path":"data.html","id":"dates-and-times","chapter":"4 Working with Data","heading":"4.5.5 Dates and Times","text":"Dates times represented doubles special classes. Although typeof() tell double, can tell dates checking class(). Datetimes can one classes start POSIX.See Appendix H use lubridate work dates times.data types :100 integerdoublecharacterlogicalfactor100L integerdoublecharacterlogicalfactor\"100\" integerdoublecharacterlogicalfactor100.0 integerdoublecharacterlogicalfactor-100L integerdoublecharacterlogicalfactorfactor(100) integerdoublecharacterlogicalfactorTRUE integerdoublecharacterlogicalfactor\"TRUE\" integerdoublecharacterlogicalfactorFALSE integerdoublecharacterlogicalfactor1 == 2 integerdoublecharacterlogicalfactor","code":"\ndate <- as.Date(\"2022-01-24\")\ndatetime <- ISOdatetime(2022, 1, 24, 10, 35, 00, \"GMT\")\ntypeof(date)\ntypeof(datetime)\nclass(date)\nclass(datetime)## [1] \"double\"\n## [1] \"double\"\n## [1] \"Date\"\n## [1] \"POSIXct\" \"POSIXt\""},{"path":"data.html","id":"containers","chapter":"4 Working with Data","heading":"4.6 Basic container types","text":"Individual data values can grouped together containers. main types containers work vectors, lists, data tables.","code":""},{"path":"data.html","id":"vectors","chapter":"4 Working with Data","heading":"4.6.1 Vectors","text":"vector R like vector mathematics: set ordered elements. elements vector must data type (numeric, character, logical). can create vector enclosing elements function c().happens mix types? class variable mixed?mix data types vector; elements vector must data type. mix , R \"coerce\" . mix doubles integers, integers changed doubles. mix characters numeric types, numbers coerced characters, 10 turn \"10\".","code":"\n## put information into a vector using c(...)\nc(1, 2, 3, 4)\nc(\"this\", \"is\", \"cool\")\n1:6 # shortcut to make a vector of all integers x:y## [1] 1 2 3 4\n## [1] \"this\" \"is\"   \"cool\"\n## [1] 1 2 3 4 5 6\nmixed <- c(2, \"good\", 2L, \"b\", TRUE)\ntypeof(mixed)## [1] \"character\""},{"path":"data.html","id":"selecting-values-from-a-vector","chapter":"4 Working with Data","heading":"4.6.1.1 Selecting values from a vector","text":"wanted pick specific values vector position, can use square brackets (extract operator, []) vector.can select one value vector putting vector numbers inside square brackets. example, can select 18th, 19th, 20th, 21st, 4th, 9th 15th letter built-vector LETTERS (gives uppercase letters Latin alphabet).Can decode secret message?can also create 'named' vectors, element name. example:can access elements name using character vector within square brackets. can put order want, can repeat elements:can get vector names using names() function, can set change using something like names(vec2) <- c(\"n1\", \"n2\", \"n3\").Another way access elements using logical vector within square brackets. pull elements vector corresponding element logical vector TRUE. logical vector length original, repeat. can find long vector using length() function.","code":"\nvalues <- c(10, 20, 30, 40, 50)\nvalues[2] # selects the second value## [1] 20\nword <- c(18, 19, 20, 21, 4, 9, 15)\nLETTERS[word]## [1] \"R\" \"S\" \"T\" \"U\" \"D\" \"I\" \"O\"\nsecret <- c(14, 5, 22, 5, 18, 7, 15, 14, 14, 1, 7, 9, 22, 5, 25, 15, 21, 21, 16)\nvec <- c(first = 77.9, second = -13.2, third = 100.1)\nvec##  first second  third \n##   77.9  -13.2  100.1\nvec[c(\"third\", \"second\", \"second\")]##  third second second \n##  100.1  -13.2  -13.2\nlength(LETTERS)\nLETTERS[c(TRUE, FALSE)]## [1] 26\n##  [1] \"A\" \"C\" \"E\" \"G\" \"I\" \"K\" \"M\" \"O\" \"Q\" \"S\" \"U\" \"W\" \"Y\""},{"path":"data.html","id":"rep_seq","chapter":"4 Working with Data","heading":"4.6.1.2 Repeating Sequences","text":"useful tricks save typing creating vectors.command x:y : operator give sequence number starting x, going y increments 1.want create sequence something integer steps? can use seq() function. Look examples work arguments .want repeat vector many times? either type (painful) use rep() function, can repeat vectors different ways.rep() function useful create vector logical values (TRUE/FALSE 1/0) select values another vector.","code":"\n1:10\n15.3:20.5\n0:-10##  [1]  1  2  3  4  5  6  7  8  9 10\n## [1] 15.3 16.3 17.3 18.3 19.3 20.3\n##  [1]   0  -1  -2  -3  -4  -5  -6  -7  -8  -9 -10\nseq(from = -1, to = 1, by = 0.2)\nseq(0, 100, length.out = 11)\nseq(0, 10, along.with = LETTERS)##  [1] -1.0 -0.8 -0.6 -0.4 -0.2  0.0  0.2  0.4  0.6  0.8  1.0\n##  [1]   0  10  20  30  40  50  60  70  80  90 100\n##  [1]  0.0  0.4  0.8  1.2  1.6  2.0  2.4  2.8  3.2  3.6  4.0  4.4  4.8  5.2  5.6\n## [16]  6.0  6.4  6.8  7.2  7.6  8.0  8.4  8.8  9.2  9.6 10.0\nrep(0, 10)                      # ten zeroes\nrep(c(1L, 3L), times = 7)       # alternating 1 and 3, 7 times\nrep(c(\"A\", \"B\", \"C\"), each = 2) # A to C, 2 times each##  [1] 0 0 0 0 0 0 0 0 0 0\n##  [1] 1 3 1 3 1 3 1 3 1 3 1 3 1 3\n## [1] \"A\" \"A\" \"B\" \"B\" \"C\" \"C\"\n# Get subject IDs in the pattern Y Y N N ...\nsubject_ids <- 1:40\nyynn <- rep(c(TRUE, FALSE), each = 2, \n            length.out = length(subject_ids))\nsubject_ids[yynn]##  [1]  1  2  5  6  9 10 13 14 17 18 21 22 25 26 29 30 33 34 37 38"},{"path":"data.html","id":"vectorized_ops","chapter":"4 Working with Data","heading":"4.6.1.3 Vectorized Operations","text":"R performs calculations vectors special way. look example using \\(z\\)-scores. \\(z\\)-score deviation score divided standard deviation. say set four IQ scores.want subtract mean four scores, just use following code:subtracts 100 element vector. R automatically assumes wanted ; called vectorized operation makes possible express operations efficiently.calculate \\(z\\)-scores use formula:\\(z = \\frac{X - \\mu}{\\sigma}\\)X scores, \\(\\mu\\) mean, \\(\\sigma\\) standard deviation. can expression formula R follows:can see computed four \\(z\\)-scores single line code. later chapters, use vectorised operations process data, reverse-scoring questionnaire items.","code":"\n## example IQ scores: mu = 100, sigma = 15\niq <- c(86, 101, 127, 99)\niq - 100## [1] -14   1  27  -1\n## z-scores\n(iq - 100) / 15## [1] -0.93333333  0.06666667  1.80000000 -0.06666667"},{"path":"data.html","id":"lists","chapter":"4 Working with Data","heading":"4.6.2 Lists","text":"Recall vectors can contain data one type. want store collection data different data types? purpose use list. Define list using list() function.can refer elements list using square brackets like vector, can also use dollar sign notation ($) list items names.Explore 5 ways shown extract value list. data type object? difference single double brackets? one dollar sign?single brackets (bracket1 name1) return list subset items inside brackets. case, just one item, can (try data_types[1:2]). items keep names , returned value list(double = 10).double brackets (bracket2 name2 return single item vector. select one item; data_types[[1:2]] give \"subscript bounds\" error.dollar-sign notation double-brackets. name spaces characters letters, numbers, underscores, full stops, need surround name backticks (e.g., sales$`Customer ID`).","code":"\ndata_types <- list(\n  double = 10.0,\n  integer = 10L,\n  character = \"10\",\n  logical = TRUE\n)\n\nstr(data_types) # str() prints lists in a condensed format## List of 4\n##  $ double   : num 10\n##  $ integer  : int 10\n##  $ character: chr \"10\"\n##  $ logical  : logi TRUE\ndata_types$logical## [1] TRUE\nbracket1 <- data_types[1]\nbracket2 <- data_types[[1]]\nname1    <- data_types[\"double\"]\nname2    <- data_types[[\"double\"]]\ndollar   <- data_types$double"},{"path":"data.html","id":"tables-data","chapter":"4 Working with Data","heading":"4.6.3 Tables","text":"built-, imported, created data tabular data, data arranged form table.Tabular data structures allow collection data different types (characters, integers, logical, etc.) subject constraint \"column\" table (element list) must number elements. base R version table called data.frame, 'tidyverse' version called tibble. Tibbles far easier work , using . learn differences two data structures, see vignette(\"tibble\").Tabular data becomes especially important talk tidy data chapter 4, consists set simple principles structuring data.","code":""},{"path":"data.html","id":"creating-a-table","chapter":"4 Working with Data","heading":"4.6.3.1 Creating a table","text":"learned create table importing CSV Excel file, creating table scratch using tibble() function. can also use tibble::tribble() function create table row, rather column. start listing column names, preceded tilde (~), list values column, row row, separated commas (forget comma end row). method can easier data, let use shortcuts, like setting values column value repeating sequence.","code":"\n# construct a table by column with tibble\navatar <- tibble(\n  name = c(\"Katara\", \"Toph\", \"Sokka\"),\n  bends = c(\"water\", \"earth\", NA),\n  friendly = TRUE\n)\n\n# or by row with tribble\navatar <- tribble(\n  ~name,    ~bends,  ~friendly,\n  \"Katara\", \"water\", TRUE,\n  \"Toph\",   \"earth\", TRUE,\n  \"Sokka\",  NA,      TRUE\n)\n# export the data to a file\nrio::export(avatar, \"data/avatar.csv\")\n\n# or by importing data from a file\navatar <- rio::import(\"data/avatar.csv\")"},{"path":"data.html","id":"table-info","chapter":"4 Working with Data","heading":"4.6.3.2 Table info","text":"can get information table using functions:ncol(): number columnsnrow(): number rowsdim(): number rows number columnsname(): column namesglimpse(): column types","code":"\nnrow(avatar)\nncol(avatar)\ndim(avatar)\nnames(avatar)\nglimpse(avatar)## [1] 3\n## [1] 3\n## [1] 3 3\n## [1] \"name\"     \"bends\"    \"friendly\"\n## Rows: 3\n## Columns: 3\n## $ name     <chr> \"Katara\", \"Toph\", \"Sokka\"\n## $ bends    <chr> \"water\", \"earth\", NA\n## $ friendly <lgl> TRUE, TRUE, TRUE"},{"path":"data.html","id":"row-col-access","chapter":"4 Working with Data","heading":"4.6.3.3 Accessing rows and columns","text":"various ways accessing specific columns rows table. learning Chapters 6 7.code uses base R produce subsets functions . format useful know , since might see people's scripts.","code":"\nsiblings   <- avatar %>% slice(1, 3) # rows (by number)\nbends      <- avatar %>% pull(2) # column vector (by number)\nfriendly   <- avatar %>% pull(friendly) # column vector (by name)\nbends_name <- avatar %>% select(bends, name) # subset table (by name)\ntoph       <- avatar %>% pull(name) %>% pluck(2) # single cell\n# base R access\n\nsiblings   <- avatar[c(1, 3), ] # rows (by number)\nbends      <- avatar[, 2] # column vector (by number)\nfriendly   <- avatar$friendly  # column vector (by name)\nbends_name <- avatar[, c(\"bends\", \"name\")] # subset table (by name)\ntoph       <- avatar[[2, 1]] # single cell (row, col)"},{"path":"data.html","id":"troubleshooting","chapter":"4 Working with Data","heading":"4.7 Troubleshooting","text":"import data guesses wrong column type? common reason numeric column non-numbers somewhere. Maybe someone wrote note otherwise numeric column. Columns one data type, characters, whole column converted character strings, numbers like 1.2 get represented \"1.2\", cause weird errors like \"100\" < \"9\" == TRUE. can catch using glimpse() check data.data directory created reprores::getdata() contains file called \"mess.csv\". try loading dataset.get warning many parsing errors data table just single column. View file data/mess.csv clicking File pane, choosing \"View File\". first 10 lines. went wrong?First, file starts note: \"messy dataset\". want skip first two lines. can argument skip read_csv().OK, little better, table still serious mess several ways:junk column needorder integer columngood logical columngood uses kinds different ways record TRUE FALSE valuesmin_max contains two pieces numeric information, character columndate date columnWe'll learn deal mess Chapters 6 7, can fix things setting col_types argument read_csv() specify column types two columns guessed wrong skip \"junk\" column. argument col_types takes list name item list column name value table . can use function, like col_double() abbreviation, like \"l\". Omitted column names guessed.get message parsing issues run tells run problems() function see table problems. Warnings look scary first, always start reading message. table tells row (3) column (2) error found , kind data expected (integer), actual value (missing). specifically tell read_csv() import column integer, characters column produce warning like recorded NA. can manually set missing values recorded na argument.Now order integer \"missing\" now NA, good logical value, 0 F converted FALSE 1 T converted TRUE, date date type (adding leading zeros day). learn later chapters fix problems, min_max column containing two different types data.","code":"\n# lazy = FALSE loads the data right away so you can see error messages\n# this default changed in late 2021 and might change back soon\nmess <- read_csv(\"data/mess.csv\", lazy = FALSE)## Warning: One or more parsing issues, see `problems()` for details## Rows: 27 Columns: 1\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (1): This is my messy dataset\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.This is my messy dataset\n\njunk,order,score,letter,good,min_max,date\njunk,1,-1,a,1,1 - 2,2020-01-1\n\njunk,missing,0.72,b,1,2 - 3,2020-01-2\n\njunk,3,-0.62,c,FALSE,3 - 4,2020-01-3\n\njunk,4,2.03,d,T,4 - 5,2020-01-4\nmess <- read_csv(\"data/mess.csv\", \n                 skip = 2, \n                 lazy = FALSE)## Rows: 26 Columns: 7\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (6): junk, order, letter, good, min_max, date\n## dbl (1): score\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nglimpse(mess)## Rows: 26\n## Columns: 7\n## $ junk    <chr> \"junk\", \"junk\", \"junk\", \"junk\", \"junk\", \"junk\", \"junk\", \"junk\"…\n## $ order   <chr> \"1\", \"missing\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\",…\n## $ score   <dbl> -1.00, 0.72, -0.62, 2.03, NA, 0.99, 0.03, 0.67, 0.57, 0.90, -1…\n## $ letter  <chr> \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m…\n## $ good    <chr> \"1\", \"1\", \"FALSE\", \"T\", \"1\", \"0\", \"T\", \"TRUE\", \"1\", \"T\", \"F\", …\n## $ min_max <chr> \"1 - 2\", \"2 - 3\", \"3 - 4\", \"4 - 5\", \"5 - 6\", \"6 - 7\", \"7 - 8\",…\n## $ date    <chr> \"2020-01-1\", \"2020-01-2\", \"2020-01-3\", \"2020-01-4\", \"2020-01-5…\n# omitted values are guessed\n# ?col_date for format options\nct <- list(\n  junk = \"-\", # skip this column\n  order = \"i\",\n  good = \"l\",\n  date = col_date(format = \"%Y-%m-%d\")\n)\n\ntidier <- read_csv(\"data/mess.csv\", \n                   skip = 2,\n                   col_types = ct, \n                   lazy = FALSE)## Warning: One or more parsing issues, see `problems()` for details\nproblems()\ntidiest <- read_csv(\"data/mess.csv\", \n                   skip = 2,\n                   na = \"missing\",\n                   col_types = ct,\n                   lazy = FALSE)\ntidiest"},{"path":"data.html","id":"glossary-data","chapter":"4 Working with Data","heading":"4.8 Glossary","text":"","code":""},{"path":"data.html","id":"resources-data","chapter":"4 Working with Data","heading":"4.9 Further Resources","text":"Data Organization Spreadsheets (Broman & Woo (2018))Chapter 11: Data Import R Data ScienceRStudio Data Import CheatsheetCodebook Package ComparisonHow automatically document data codebook package facilitate data reuse (Arslan (2019))Skimr","code":""},{"path":"joins.html","id":"joins","chapter":"5 Data Relations","heading":"5 Data Relations","text":"","code":""},{"path":"joins.html","id":"ilo-joins","chapter":"5 Data Relations","heading":"5.1 Learning Objectives","text":"able use 4 mutating join verbs: (video)\nleft_join()\nright_join()\ninner_join()\nfull_join()\nleft_join()right_join()inner_join()full_join()able use 2 filtering join verbs: (video)\nsemi_join()\nanti_join()\nsemi_join()anti_join()able use 2 binding join verbs: (video)\nbind_rows()\nbind_cols()\nbind_rows()bind_cols()able use 3 set operations: (video)\nintersect()\nunion()\nsetdiff()\nintersect()union()setdiff()","code":""},{"path":"joins.html","id":"setup-joins","chapter":"5 Data Relations","heading":"5.2 Setup","text":"Open reprores-class-notes projectCreate new R Markdown file called 05-joins.RmdUpdate YAML headerReplace setup chunk one :Download Data transformation cheatsheet.","code":"```{r setup, include = FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n\n# packages needed for this chapter\nlibrary(tidyverse) # loads dplyr for join functions```"},{"path":"joins.html","id":"create-demo-data","chapter":"5 Data Relations","heading":"5.3 Create Demo Data","text":"First, create two small data tables.subject id, gender age subjects 1-5. Age gender missing subject 3.exp subject id score experiment. subjects missing, completed twice, subject table.","code":"\nsubject <- tibble(\n  id = 1:5,\n  gender = c(\"m\", \"m\", NA, \"nb\", \"f\"),\n  age = c(19, 22, NA, 19, 18)\n)\nexp <- tibble(\n  id = c(2, 3, 4, 4, 5, 5, 6, 6, 7),\n  score = c(10, 18, 21, 23, 9, 11, 11, 12, 3)\n)"},{"path":"joins.html","id":"mutating-joins","chapter":"5 Data Relations","heading":"5.4 Mutating Joins","text":"Mutating joins act like mutate() function add new columns one table based values another table.mutating joins basic syntax:****_join(x, y, = NULL, suffix = c(\".x\", \".y\")x = first (left) tabley = second (right) tableby = columns match . leave blank, match columns names two tables.suffix = columns name two tables, joining , get suffix make unambiguous. defaults \".x\" \".y\", can change something meaningful.can leave argument matching columns name, good practice always specify code robust changes loaded data.","code":""},{"path":"joins.html","id":"left_join","chapter":"5 Data Relations","heading":"5.4.1 left_join()","text":"\nFigure 5.1: Left Join\nleft_join keeps data first (left) table joins anything matches second (right) table. right table one match row right table, one row joined table (see ids 4 5).\nFigure 5.2: Left Join (reversed)\norder tables swapped , result rows exp table joined matching rows subject table.","code":"\nleft_join(subject, exp, by = \"id\")\nleft_join(exp, subject, by = \"id\")"},{"path":"joins.html","id":"right_join","chapter":"5 Data Relations","heading":"5.4.2 right_join()","text":"\nFigure 5.3: Right Join\nright_join keeps data second (right) table joins anything matches first (left) table.table information left_join(exp, subject, = \"id\"), columns different order (left table, right table).","code":"\nright_join(subject, exp, by = \"id\")"},{"path":"joins.html","id":"inner_join","chapter":"5 Data Relations","heading":"5.4.3 inner_join()","text":"\nFigure 5.4: Inner Join\ninner_join returns rows match table.","code":"\ninner_join(subject, exp, by = \"id\")"},{"path":"joins.html","id":"full_join","chapter":"5 Data Relations","heading":"5.4.4 full_join()","text":"\nFigure 5.5: Full Join\nfull_join lets join rows two tables keeping information tables. row match table, table's column values set NA.","code":"\nfull_join(subject, exp, by = \"id\")"},{"path":"joins.html","id":"filtering-joins","chapter":"5 Data Relations","heading":"5.5 Filtering Joins","text":"Filtering joins act like filter() function remove rows data one table based values another table. result filtering join contain rows left table number fewer rows left table.","code":""},{"path":"joins.html","id":"semi_join","chapter":"5 Data Relations","heading":"5.5.1 semi_join()","text":"\nFigure 5.6: Semi Join\nsemi_join returns rows left table matching values right table, keeping just columns left table.Unlike inner join, semi join never duplicate rows left table one matching row right table.\nFigure 5.7: Semi Join (Reversed)\nOrder matters semi join.","code":"\nsemi_join(subject, exp, by = \"id\")\nsemi_join(exp, subject, by = \"id\")"},{"path":"joins.html","id":"anti_join","chapter":"5 Data Relations","heading":"5.5.2 anti_join()","text":"\nFigure 5.8: Anti Join\nanti_join return rows left table matching values right table, keeping just columns left table.\nFigure 5.9: Anti Join (Reversed)\nOrder matters anti join.","code":"\nanti_join(subject, exp, by = \"id\")\nanti_join(exp, subject, by = \"id\")"},{"path":"joins.html","id":"binding-joins","chapter":"5 Data Relations","heading":"5.6 Binding Joins","text":"Binding joins bind one table another adding rows columns together.","code":""},{"path":"joins.html","id":"bind_rows","chapter":"5 Data Relations","heading":"5.6.1 bind_rows()","text":"can combine rows two tables bind_rows.add subject data subjects 6-9 bind original subject table.columns just names, order. columns differ two tables just NA values entries table.row duplicated two tables (like id 5 ), row also duplicated resulting table. tables exact columns, can use union() (see ) avoid duplicates.","code":"\nnew_subjects <- tibble(\n  id = 6:9,\n  gender = c(\"nb\", \"m\", \"f\", \"f\"),\n  age = c(19, 16, 20, 19)\n)\n\nbind_rows(subject, new_subjects)\nnew_subjects <- tibble(\n  id = 5:9,\n  age = c(18, 19, 16, 20, 19),\n  gender = c(\"f\", \"nb\", \"m\", \"f\", \"f\"),\n  new = c(1,2,3,4,5)\n)\n\nbind_rows(subject, new_subjects)"},{"path":"joins.html","id":"bind_cols","chapter":"5 Data Relations","heading":"5.6.2 bind_cols()","text":"can merge two tables number rows using bind_cols. useful two tables rows exact order. advantage left join tables IDs join rely solely order.","code":"\nnew_info <- tibble(\n  colour = c(\"red\", \"orange\", \"yellow\", \"green\", \"blue\")\n)\n\nbind_cols(subject, new_info)"},{"path":"joins.html","id":"set-operations","chapter":"5 Data Relations","heading":"5.7 Set Operations","text":"Set operations compare two tables return rows match (intersect), either table (union), one table (setdiff).","code":""},{"path":"joins.html","id":"intersect","chapter":"5 Data Relations","heading":"5.7.1 intersect()","text":"intersect() returns rows two tables match exactly. columns order.forgotten load dplyr tidyverse, base R also intersect() function. error message can confusing looks something like :","code":"\nnew_subjects <- tibble(\n  id = seq(4, 9),\n  age = c(19, 18, 19, 16, 20, 19),\n  gender = c(\"f\", \"f\", \"m\", \"m\", \"f\", \"f\")\n)\n\nintersect(subject, new_subjects)\nbase::intersect(subject, new_subjects)## list()"},{"path":"joins.html","id":"union","chapter":"5 Data Relations","heading":"5.7.2 union()","text":"union() returns rows tables, removing duplicate rows.forgotten load dplyr tidyverse, base R also union() function. usually get error message, output expect.","code":"\nunion(subject, new_subjects)\nbase::union(subject, new_subjects)## [[1]]\n## [1] 1 2 3 4 5\n## \n## [[2]]\n## [1] \"m\"  \"m\"  NA   \"nb\" \"f\" \n## \n## [[3]]\n## [1] 19 22 NA 19 18\n## \n## [[4]]\n## [1] 4 5 6 7 8 9\n## \n## [[5]]\n## [1] 19 18 19 16 20 19\n## \n## [[6]]\n## [1] \"f\" \"f\" \"m\" \"m\" \"f\" \"f\""},{"path":"joins.html","id":"setdiff","chapter":"5 Data Relations","heading":"5.7.3 setdiff()","text":"setdiff returns rows first table, second table.Order matters setdiff.forgotten load dplyr tidyverse, base R also setdiff() function. usually get error message, output might expect base R setdiff() expects columns order, id 5 registers different two tables.","code":"\nsetdiff(subject, new_subjects)\nsetdiff(new_subjects, subject)\nbase::setdiff(subject, new_subjects)## $id\n## [1] 1 2 3 4 5\n## \n## $gender\n## [1] \"m\"  \"m\"  NA   \"nb\" \"f\" \n## \n## $age\n## [1] 19 22 NA 19 18"},{"path":"joins.html","id":"glossary-joins","chapter":"5 Data Relations","heading":"5.8 Glossary","text":"","code":""},{"path":"joins.html","id":"resources-joins","chapter":"5 Data Relations","heading":"5.9 Further Resources","text":"Chapter 13: Relational Data R Data ScienceCheatsheet dplyr join functionsLecture slides dplyr two-table verbs","code":""},{"path":"tidyr.html","id":"tidyr","chapter":"6 Tidy Data","heading":"6 Tidy Data","text":"","code":""},{"path":"tidyr.html","id":"ilo-tidyr","chapter":"6 Tidy Data","heading":"6.1 Learning Objectives","text":"","code":""},{"path":"tidyr.html","id":"basic-1","chapter":"6 Tidy Data","heading":"Basic","text":"Understand concept tidy data (video)able convert long wide formats using pivot functions (video)\npivot_longer()\npivot_wider()\npivot_longer()pivot_wider()able use 4 basic tidyr verbs (video)\ngather()\nseparate()\nspread()\nunite()\ngather()separate()spread()unite()able chain functions using pipes (video)","code":""},{"path":"tidyr.html","id":"intermediate-1","chapter":"6 Tidy Data","heading":"Intermediate","text":"able use regular expressions separate complex columns","code":""},{"path":"tidyr.html","id":"setup-tidyr","chapter":"6 Tidy Data","heading":"6.2 Setup","text":"Open reprores-class-notes projectCreate new R Markdown file called 06-tidyr.RmdUpdate YAML headerReplace setup chunk one :Download Data tidying cheat sheet.","code":"```{r setup, include = FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n\n# packages needed for this chapter\nlibrary(tidyverse) # loads tidyr for pivot functions and tidy verbs\nlibrary(reprores)  # class-specific datasets\n\nset.seed(8675309) # makes sure random numbers are reproducible```"},{"path":"tidyr.html","id":"tidy-data","chapter":"6 Tidy Data","heading":"6.3 Tidy Data","text":"","code":""},{"path":"tidyr.html","id":"three-rules","chapter":"6 Tidy Data","heading":"6.3.1 Three Rules","text":"variable must columnEach observation must rowEach value must cellThis table three observations per row total_meanRT column contains two values.\nTable 6.1: Untidy table\ntidy version.\nTable 6.1: Tidy table\n","code":""},{"path":"tidyr.html","id":"wide_long","chapter":"6 Tidy Data","heading":"6.3.2 Wide versus long","text":"Data tables can wide format long format (sometimes mix two). Wide data observations one subject row, long data observation separate row. often need convert formats different types analyses data processing.Imagine study subject completes questionnaire three items. answer observation subject. probably familiar data like wide format, subject id one column, three item responses column.\nTable 6.2: Wide data\ndata can represented long format creating new column specifies item observation new column specifies value observation.\nTable 6.3: Long data\nCreate long version following table.answer need column headers order.","code":""},{"path":"tidyr.html","id":"pivot","chapter":"6 Tidy Data","heading":"6.4 Pivot Functions","text":"pivot functions allow transform data table wide long long wide one step.","code":""},{"path":"tidyr.html","id":"load-data","chapter":"6 Tidy Data","heading":"6.4.1 Load Data","text":"used dataset personality reprores package (download data personality.csv). data 5-factor (personality) personality questionnaire. question labelled domain (Op = openness, Co = conscientiousness, Ex = extroversion, Ag = agreeableness, Ne = neuroticism) question number.","code":"\ndata(\"personality\", package = \"reprores\")"},{"path":"tidyr.html","id":"pivot_longer","chapter":"6 Tidy Data","heading":"6.4.2 pivot_longer()","text":"pivot_longer() converts wide data table long format converting headers specified columns values new columns, combining values columns new condensed column.cols refers columns want make long can refer names, like col1, col2, col3, col4 col1:col4 numbers, like 8, 9, 10 8:10.names_to want call new columns gathered column headers go ; \"domain\" \"qnumber\" example.names_sep optional argument one value names_to. specifies characters position split values cols headers.values_to want call values columns ...; \"score\" example.can pipe data table glimpse() end quick look . still save object.set names_sep order split cols headers listed results?","code":"\npersonality_long <- pivot_longer(\n  data = personality, \n  cols = Op1:Ex9,                    # columns to make long \n  names_to = c(\"domain\", \"qnumber\"), # new column names for headers\n  names_sep = 2,                     # how to split the headers\n  values_to = \"score\"                # new column name for values\n) |>\n  glimpse()## Rows: 615,000\n## Columns: 5\n## $ user_id <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n## $ date    <date> 2006-03-23, 2006-03-23, 2006-03-23, 2006-03-23, 2006-03-23, 2…\n## $ domain  <chr> \"Op\", \"Ne\", \"Ne\", \"Op\", \"Ex\", \"Ex\", \"Co\", \"Co\", \"Ne\", \"Ag\", \"A…\n## $ qnumber <chr> \"1\", \"1\", \"2\", \"2\", \"1\", \"2\", \"1\", \"2\", \"3\", \"1\", \"2\", \"4\", \"3…\n## $ score   <dbl> 3, 4, 0, 6, 3, 3, 3, 3, 0, 2, 1, 3, 3, 2, 2, 1, 3, 3, 1, 3, 0,…"},{"path":"tidyr.html","id":"pivot_wider","chapter":"6 Tidy Data","heading":"6.4.3 pivot_wider()","text":"can also go long wide format using pivot_wider() function.names_from columns contain new column headers.values_from column contains values new columns.names_sep character string used join names names_from one column.","code":"\npersonality_wide <- pivot_wider(\n  data = personality_long,\n  names_from = c(domain, qnumber),\n  values_from = score,\n  names_sep = \"\"\n) |>\n  glimpse()## Rows: 15,000\n## Columns: 43\n## $ user_id <dbl> 0, 1, 2, 5, 8, 108, 233, 298, 426, 436, 685, 807, 871, 881, 94…\n## $ date    <date> 2006-03-23, 2006-02-08, 2005-10-24, 2005-12-07, 2006-07-27, 2…\n## $ Op1     <dbl> 3, 6, 6, 6, 6, 3, 3, 6, 6, 3, 4, 5, 5, 5, 6, 4, 1, 2, 5, 6, 4,…\n## $ Ne1     <dbl> 4, 0, 0, 4, 1, 2, 3, 4, 0, 3, 3, 3, 2, 1, 1, 3, 4, 5, 2, 4, 5,…\n## $ Ne2     <dbl> 0, 6, 6, 4, 2, 1, 2, 3, 1, 2, 5, 5, 3, 1, 1, 1, 1, 6, 1, 2, 5,…\n## $ Op2     <dbl> 6, 0, 0, 4, 6, 4, 4, 0, 0, 3, 4, 3, 3, 4, 5, 3, 3, 4, 1, 6, 6,…\n## $ Ex1     <dbl> 3, 0, 0, 2, 2, 4, 4, 3, 5, 4, 1, 1, 3, 3, 1, 3, 5, 1, 0, 4, 1,…\n## $ Ex2     <dbl> 3, 0, 0, 3, 3, 4, 5, 2, 5, 3, 4, 1, 3, 2, 1, 6, 5, 3, 4, 4, 1,…\n## $ Co1     <dbl> 3, 0, 0, 3, 5, 4, 3, 4, 5, 3, 3, 3, 1, 5, 5, 4, 4, 5, 6, 4, 2,…\n## $ Co2     <dbl> 3, 0, 0, 3, 4, 3, 3, 4, 5, 3, 5, 3, 3, 4, 5, 1, 5, 4, 5, 2, 5,…\n## $ Ne3     <dbl> 0, 0, 0, 1, 0, 1, 4, 4, 0, 4, 2, 5, 1, 2, 5, 5, 2, 2, 1, 2, 5,…\n## $ Ag1     <dbl> 2, 0, 0, 4, 6, 5, 5, 4, 2, 5, 4, 3, 2, 4, 5, 3, 5, 5, 5, 4, 4,…\n## $ Ag2     <dbl> 1, 6, 6, 0, 5, 4, 5, 3, 4, 3, 5, 1, 5, 4, 2, 6, 5, 5, 5, 5, 2,…\n## $ Ne4     <dbl> 3, 6, 6, 2, 3, 2, 3, 3, 0, 4, 4, 5, 5, 4, 5, 3, 2, 5, 2, 4, 5,…\n## $ Ex3     <dbl> 3, 6, 5, 5, 3, 3, 3, 0, 6, 1, 4, 2, 3, 2, 1, 2, 5, 1, 0, 5, 5,…\n## $ Co3     <dbl> 2, 0, 1, 3, 4, 4, 5, 4, 5, 3, 4, 3, 4, 4, 5, 4, 2, 4, 5, 2, 2,…\n## $ Op3     <dbl> 2, 6, 5, 5, 5, 4, 3, 2, 4, 3, 3, 6, 5, 5, 6, 5, 4, 4, 3, 6, 5,…\n## $ Ex4     <dbl> 1, 0, 1, 3, 3, 3, 4, 3, 5, 3, 2, 0, 3, 3, 1, 2, NA, 4, 4, 4, 1…\n## $ Op4     <dbl> 3, 0, 1, 6, 6, 3, 3, 0, 6, 3, 4, 5, 4, 5, 6, 6, 2, 2, 4, 5, 5,…\n## $ Ex5     <dbl> 3, 0, 1, 6, 3, 3, 4, 2, 5, 2, 2, 4, 2, 3, 0, 4, 5, 2, 3, 1, 1,…\n## $ Ag3     <dbl> 1, 0, 1, 1, 0, 4, 4, 4, 3, 3, 4, 4, 3, 4, 4, 5, 5, 4, 5, 3, 4,…\n## $ Co4     <dbl> 3, 6, 5, 5, 5, 3, 2, 4, 3, 1, 4, 3, 1, 2, 4, 2, NA, 5, 6, 1, 1…\n## $ Co5     <dbl> 0, 6, 5, 5, 5, 3, 3, 1, 5, 1, 2, 4, 4, 4, 2, 1, 6, 4, 3, 1, 3,…\n## $ Ne5     <dbl> 3, 0, 1, 4, 1, 1, 4, 5, 0, 3, 4, 6, 2, 0, 1, 1, 0, 4, 3, 1, 5,…\n## $ Op5     <dbl> 6, 6, 5, 2, 5, 4, 3, 2, 6, 6, 2, 4, 3, 4, 6, 6, 6, 5, 3, 3, 5,…\n## $ Ag4     <dbl> 1, 0, 1, 4, 6, 5, 5, 6, 6, 6, 4, 2, 4, 5, 4, 5, 6, 4, 5, 6, 5,…\n## $ Op6     <dbl> 0, 6, 5, 1, 6, 4, 6, 0, 0, 3, 5, 3, 5, 5, 5, 2, 5, 1, 1, 6, 2,…\n## $ Co6     <dbl> 6, 0, 1, 4, 6, 5, 6, 5, 4, 3, 5, 5, 4, 6, 6, 1, 3, 4, 5, 4, 6,…\n## $ Ex6     <dbl> 3, 6, 5, 3, 0, 4, 3, 1, 6, 3, 2, 1, 4, 2, 1, 5, 6, 2, 1, 2, 1,…\n## $ Ne6     <dbl> 1, 6, 5, 1, 0, 1, 3, 4, 0, 4, 4, 5, 2, 1, 5, 6, 1, 2, 2, 3, 5,…\n## $ Co7     <dbl> 3, 6, 5, 1, 3, 4, NA, 2, 3, 3, 2, 2, 4, 2, 5, 2, 5, 5, 3, 1, 1…\n## $ Ag5     <dbl> 3, 6, 5, 0, 2, 5, 6, 2, 2, 3, 4, 1, 3, 5, 2, 6, 5, 6, 5, 3, 3,…\n## $ Co8     <dbl> 3, 0, 1, 1, 3, 4, 3, 0, 1, 3, 2, 2, 1, 2, 4, 3, 2, 4, 5, 2, 6,…\n## $ Ex7     <dbl> 3, 6, 5, 4, 1, 2, 5, 3, 6, 3, 4, 3, 5, 1, 1, 6, 6, 3, 1, 1, 3,…\n## $ Ne7     <dbl> NA, 0, 1, 2, 0, 2, 4, 4, 0, 3, 2, 5, 1, 2, 5, 2, 2, 4, 1, 3, 5…\n## $ Co9     <dbl> 3, 6, 5, 4, 3, 4, 5, 3, 5, 3, 4, 3, 4, 4, 2, 4, 6, 5, 5, 2, 2,…\n## $ Op7     <dbl> 0, 6, 5, 5, 5, 4, 6, 2, 1, 3, 2, 4, 5, 5, 6, 3, 6, 5, 2, 6, 5,…\n## $ Ne8     <dbl> 2, 0, 1, 1, 1, 1, 5, 4, 0, 4, 4, 5, 1, 2, 5, 2, 1, 5, 1, 2, 5,…\n## $ Ag6     <dbl> NA, 6, 5, 2, 3, 4, 5, 6, 1, 3, 4, 2, 3, 5, 1, 6, 2, 6, 6, 5, 3…\n## $ Ag7     <dbl> 3, 0, 1, 1, 1, 3, 3, 5, 0, 3, 2, 1, 2, 3, 5, 6, 4, 4, 6, 6, 2,…\n## $ Co10    <dbl> 1, 6, 5, 5, 3, 5, 1, 2, 5, 2, 4, 3, 4, 4, 3, 2, 5, 5, 5, 2, 2,…\n## $ Ex8     <dbl> 2, 0, 1, 4, 3, 4, 2, 4, 6, 2, 4, 0, 4, 4, 1, 3, 5, 4, 3, 1, 1,…\n## $ Ex9     <dbl> 4, 6, 5, 5, 5, 2, 3, 3, 6, 3, 3, 4, 4, 3, 2, 5, 5, 4, 4, 0, 4,…"},{"path":"tidyr.html","id":"tidy-verbs","chapter":"6 Tidy Data","heading":"6.5 Tidy Verbs","text":"pivot functions relatively new functions combine four basic tidy verbs. can also convert data long wide formats using functions. Many researchers still use functions older code use pivot functions, useful know interpret .","code":""},{"path":"tidyr.html","id":"gather","chapter":"6 Tidy Data","heading":"6.5.1 gather()","text":"Much like pivot_longer(), gather() makes wide data table long creating column headers column values. main difference turn headers one column.key want call new column gathered column headers go ; \"question\" example. like names_to pivot_longer(), can take one value (multiple values need separated separate()).value want call values gathered columns; \"score\" example. like values_to pivot_longer().... refers columns want gather. like cols pivot_longer().gather() function converts personality wide data table long format, row user/question observation. resulting data table columns: user_id, date, question, score.","code":"\npersonality_gathered <- gather(\n  data = personality, \n  key = \"question\", # new column name for gathered headers\n  value = \"score\",  # new column name for gathered values\n  Op1:Ex9           # columns to gather\n) |>\n  glimpse()## Rows: 615,000\n## Columns: 4\n## $ user_id  <dbl> 0, 1, 2, 5, 8, 108, 233, 298, 426, 436, 685, 807, 871, 881, 9…\n## $ date     <date> 2006-03-23, 2006-02-08, 2005-10-24, 2005-12-07, 2006-07-27, …\n## $ question <chr> \"Op1\", \"Op1\", \"Op1\", \"Op1\", \"Op1\", \"Op1\", \"Op1\", \"Op1\", \"Op1\"…\n## $ score    <dbl> 3, 6, 6, 6, 6, 3, 3, 6, 6, 3, 4, 5, 5, 5, 6, 4, 1, 2, 5, 6, 4…"},{"path":"tidyr.html","id":"separate","chapter":"6 Tidy Data","heading":"6.5.2 separate()","text":"col column want separateinto vector new column namessep character(s) separate new columns. defaults anything alphanumeric, like .,_-/: like names_sep argument pivot_longer().Split question column two columns: domain qnumber.character split , , can separate column specific number characters setting sep integer. example, split \"abcde\" third character, use sep = 3, results c(\"abc\", \"de\"). can also use negative number split nth character right. example, split column words various lengths 2-digit suffixes (like \"lisa03\"\", \"amanda38\"), can use sep = -2.want separate just full stops, need use sep = \"\\\\.\", sep = \".\". two slashes escape full stop, making interpreted literal full stop regular expression character.","code":"\npersonality_sep <- separate(\n  data = personality_gathered, \n  col = question,                # column to separate\n  into = c(\"domain\", \"qnumber\"), # new column names\n  sep = 2                        # where to separate\n) |>\n  glimpse()## Rows: 615,000\n## Columns: 5\n## $ user_id <dbl> 0, 1, 2, 5, 8, 108, 233, 298, 426, 436, 685, 807, 871, 881, 94…\n## $ date    <date> 2006-03-23, 2006-02-08, 2005-10-24, 2005-12-07, 2006-07-27, 2…\n## $ domain  <chr> \"Op\", \"Op\", \"Op\", \"Op\", \"Op\", \"Op\", \"Op\", \"Op\", \"Op\", \"Op\", \"O…\n## $ qnumber <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1…\n## $ score   <dbl> 3, 6, 6, 6, 6, 3, 3, 6, 6, 3, 4, 5, 5, 5, 6, 4, 1, 2, 5, 6, 4,…"},{"path":"tidyr.html","id":"unite","chapter":"6 Tidy Data","heading":"6.5.3 unite()","text":"col new united column... refers columns want unitesep character(s) separate united columnsPut domain qnumber columns back together new column named domain_n. Make format like \"Op_Q1\".","code":"\npersonality_unite <- unite(\n  data = personality_sep, \n  col = \"domain_n\", # new column name\n  domain, qnumber,  # columns to unite\n  sep = \"_Q\"        # separation characters\n) |>\n  glimpse()## Rows: 615,000\n## Columns: 4\n## $ user_id  <dbl> 0, 1, 2, 5, 8, 108, 233, 298, 426, 436, 685, 807, 871, 881, 9…\n## $ date     <date> 2006-03-23, 2006-02-08, 2005-10-24, 2005-12-07, 2006-07-27, …\n## $ domain_n <chr> \"Op_Q1\", \"Op_Q1\", \"Op_Q1\", \"Op_Q1\", \"Op_Q1\", \"Op_Q1\", \"Op_Q1\"…\n## $ score    <dbl> 3, 6, 6, 6, 6, 3, 3, 6, 6, 3, 4, 5, 5, 5, 6, 4, 1, 2, 5, 6, 4…"},{"path":"tidyr.html","id":"spread","chapter":"6 Tidy Data","heading":"6.5.4 spread()","text":"can reverse processes , well. example, can convert data long format wide format.key column contains new column headers. like names_from pivot_wider(), can take one value (multiple values need merged first using unite()).value column contains values new spread columns. like values_from pivot_wider().","code":"\npersonality_spread <- spread(\n  data = personality_unite,\n  key = domain_n, # column that contains new headers\n  value = score   # column that contains new values\n) |>\n  glimpse()## Rows: 15,000\n## Columns: 43\n## $ user_id <dbl> 0, 1, 2, 5, 8, 108, 233, 298, 426, 436, 685, 807, 871, 881, 94…\n## $ date    <date> 2006-03-23, 2006-02-08, 2005-10-24, 2005-12-07, 2006-07-27, 2…\n## $ Ag_Q1   <dbl> 2, 0, 0, 4, 6, 5, 5, 4, 2, 5, 4, 3, 2, 4, 5, 3, 5, 5, 5, 4, 4,…\n## $ Ag_Q2   <dbl> 1, 6, 6, 0, 5, 4, 5, 3, 4, 3, 5, 1, 5, 4, 2, 6, 5, 5, 5, 5, 2,…\n## $ Ag_Q3   <dbl> 1, 0, 1, 1, 0, 4, 4, 4, 3, 3, 4, 4, 3, 4, 4, 5, 5, 4, 5, 3, 4,…\n## $ Ag_Q4   <dbl> 1, 0, 1, 4, 6, 5, 5, 6, 6, 6, 4, 2, 4, 5, 4, 5, 6, 4, 5, 6, 5,…\n## $ Ag_Q5   <dbl> 3, 6, 5, 0, 2, 5, 6, 2, 2, 3, 4, 1, 3, 5, 2, 6, 5, 6, 5, 3, 3,…\n## $ Ag_Q6   <dbl> NA, 6, 5, 2, 3, 4, 5, 6, 1, 3, 4, 2, 3, 5, 1, 6, 2, 6, 6, 5, 3…\n## $ Ag_Q7   <dbl> 3, 0, 1, 1, 1, 3, 3, 5, 0, 3, 2, 1, 2, 3, 5, 6, 4, 4, 6, 6, 2,…\n## $ Co_Q1   <dbl> 3, 0, 0, 3, 5, 4, 3, 4, 5, 3, 3, 3, 1, 5, 5, 4, 4, 5, 6, 4, 2,…\n## $ Co_Q10  <dbl> 1, 6, 5, 5, 3, 5, 1, 2, 5, 2, 4, 3, 4, 4, 3, 2, 5, 5, 5, 2, 2,…\n## $ Co_Q2   <dbl> 3, 0, 0, 3, 4, 3, 3, 4, 5, 3, 5, 3, 3, 4, 5, 1, 5, 4, 5, 2, 5,…\n## $ Co_Q3   <dbl> 2, 0, 1, 3, 4, 4, 5, 4, 5, 3, 4, 3, 4, 4, 5, 4, 2, 4, 5, 2, 2,…\n## $ Co_Q4   <dbl> 3, 6, 5, 5, 5, 3, 2, 4, 3, 1, 4, 3, 1, 2, 4, 2, NA, 5, 6, 1, 1…\n## $ Co_Q5   <dbl> 0, 6, 5, 5, 5, 3, 3, 1, 5, 1, 2, 4, 4, 4, 2, 1, 6, 4, 3, 1, 3,…\n## $ Co_Q6   <dbl> 6, 0, 1, 4, 6, 5, 6, 5, 4, 3, 5, 5, 4, 6, 6, 1, 3, 4, 5, 4, 6,…\n## $ Co_Q7   <dbl> 3, 6, 5, 1, 3, 4, NA, 2, 3, 3, 2, 2, 4, 2, 5, 2, 5, 5, 3, 1, 1…\n## $ Co_Q8   <dbl> 3, 0, 1, 1, 3, 4, 3, 0, 1, 3, 2, 2, 1, 2, 4, 3, 2, 4, 5, 2, 6,…\n## $ Co_Q9   <dbl> 3, 6, 5, 4, 3, 4, 5, 3, 5, 3, 4, 3, 4, 4, 2, 4, 6, 5, 5, 2, 2,…\n## $ Ex_Q1   <dbl> 3, 0, 0, 2, 2, 4, 4, 3, 5, 4, 1, 1, 3, 3, 1, 3, 5, 1, 0, 4, 1,…\n## $ Ex_Q2   <dbl> 3, 0, 0, 3, 3, 4, 5, 2, 5, 3, 4, 1, 3, 2, 1, 6, 5, 3, 4, 4, 1,…\n## $ Ex_Q3   <dbl> 3, 6, 5, 5, 3, 3, 3, 0, 6, 1, 4, 2, 3, 2, 1, 2, 5, 1, 0, 5, 5,…\n## $ Ex_Q4   <dbl> 1, 0, 1, 3, 3, 3, 4, 3, 5, 3, 2, 0, 3, 3, 1, 2, NA, 4, 4, 4, 1…\n## $ Ex_Q5   <dbl> 3, 0, 1, 6, 3, 3, 4, 2, 5, 2, 2, 4, 2, 3, 0, 4, 5, 2, 3, 1, 1,…\n## $ Ex_Q6   <dbl> 3, 6, 5, 3, 0, 4, 3, 1, 6, 3, 2, 1, 4, 2, 1, 5, 6, 2, 1, 2, 1,…\n## $ Ex_Q7   <dbl> 3, 6, 5, 4, 1, 2, 5, 3, 6, 3, 4, 3, 5, 1, 1, 6, 6, 3, 1, 1, 3,…\n## $ Ex_Q8   <dbl> 2, 0, 1, 4, 3, 4, 2, 4, 6, 2, 4, 0, 4, 4, 1, 3, 5, 4, 3, 1, 1,…\n## $ Ex_Q9   <dbl> 4, 6, 5, 5, 5, 2, 3, 3, 6, 3, 3, 4, 4, 3, 2, 5, 5, 4, 4, 0, 4,…\n## $ Ne_Q1   <dbl> 4, 0, 0, 4, 1, 2, 3, 4, 0, 3, 3, 3, 2, 1, 1, 3, 4, 5, 2, 4, 5,…\n## $ Ne_Q2   <dbl> 0, 6, 6, 4, 2, 1, 2, 3, 1, 2, 5, 5, 3, 1, 1, 1, 1, 6, 1, 2, 5,…\n## $ Ne_Q3   <dbl> 0, 0, 0, 1, 0, 1, 4, 4, 0, 4, 2, 5, 1, 2, 5, 5, 2, 2, 1, 2, 5,…\n## $ Ne_Q4   <dbl> 3, 6, 6, 2, 3, 2, 3, 3, 0, 4, 4, 5, 5, 4, 5, 3, 2, 5, 2, 4, 5,…\n## $ Ne_Q5   <dbl> 3, 0, 1, 4, 1, 1, 4, 5, 0, 3, 4, 6, 2, 0, 1, 1, 0, 4, 3, 1, 5,…\n## $ Ne_Q6   <dbl> 1, 6, 5, 1, 0, 1, 3, 4, 0, 4, 4, 5, 2, 1, 5, 6, 1, 2, 2, 3, 5,…\n## $ Ne_Q7   <dbl> NA, 0, 1, 2, 0, 2, 4, 4, 0, 3, 2, 5, 1, 2, 5, 2, 2, 4, 1, 3, 5…\n## $ Ne_Q8   <dbl> 2, 0, 1, 1, 1, 1, 5, 4, 0, 4, 4, 5, 1, 2, 5, 2, 1, 5, 1, 2, 5,…\n## $ Op_Q1   <dbl> 3, 6, 6, 6, 6, 3, 3, 6, 6, 3, 4, 5, 5, 5, 6, 4, 1, 2, 5, 6, 4,…\n## $ Op_Q2   <dbl> 6, 0, 0, 4, 6, 4, 4, 0, 0, 3, 4, 3, 3, 4, 5, 3, 3, 4, 1, 6, 6,…\n## $ Op_Q3   <dbl> 2, 6, 5, 5, 5, 4, 3, 2, 4, 3, 3, 6, 5, 5, 6, 5, 4, 4, 3, 6, 5,…\n## $ Op_Q4   <dbl> 3, 0, 1, 6, 6, 3, 3, 0, 6, 3, 4, 5, 4, 5, 6, 6, 2, 2, 4, 5, 5,…\n## $ Op_Q5   <dbl> 6, 6, 5, 2, 5, 4, 3, 2, 6, 6, 2, 4, 3, 4, 6, 6, 6, 5, 3, 3, 5,…\n## $ Op_Q6   <dbl> 0, 6, 5, 1, 6, 4, 6, 0, 0, 3, 5, 3, 5, 5, 5, 2, 5, 1, 1, 6, 2,…\n## $ Op_Q7   <dbl> 0, 6, 5, 5, 5, 4, 6, 2, 1, 3, 2, 4, 5, 5, 6, 3, 6, 5, 2, 6, 5,…"},{"path":"tidyr.html","id":"pipes","chapter":"6 Tidy Data","heading":"6.6 Pipes","text":"Pipes way order code readable format.Base R recently added \"native pipe\" looks like : |>, tidyverse traditionally used \"magrittr pipe\" looks like %>%. small differences need learn yet. using new native pipe, might see magrittr pipe materials updated yet.say small data table 10 participant IDs, two columns variable type , 2 columns variable type B. want calculate mean variables mean B variables return table 10 rows (1 participant) 3 columns (id, A_mean B_mean).One way creating new object every step using object next step. pretty clear, created 6 unnecessary data objects environment. can get confusing long scripts.can name object data keep replacing old data object new one step. keep environment clean, recommend makes easy accidentally run code order running line--line development debugging.One way avoid extra objects nest functions, literally replacing data object code generated previous step. can fine short chains.gets extremely confusing long chains:pipe lets \"pipe\" result function next function, allowing put code logical order without creating many extra objects.can read code top bottom follows:Make tibble called data \nid 1 10,\nA1 10 random numbers normal distribution,\nA2 10 random numbers normal distribution,\nB1 10 random numbers normal distribution,\nB2 10 random numbers normal distribution; \nid 1 10,A1 10 random numbers normal distribution,A2 10 random numbers normal distribution,B1 10 random numbers normal distribution,B2 10 random numbers normal distribution; thenGather create variable value column columns A_1 B_2; thenSeparate column variable 2 new columns called varand var_n, separate character 1; thenGroup columns id var; thenSummarise new column called mean mean value column group drop grouping; thenSpread make new columns key names var values mean; thenRename make columns called A_mean (old ) B_mean (old B)can make intermediate objects whenever need break code getting complicated need debug something.can debug pipe highlighting beginning just pipe want stop . Try highlighting data <- end separate function typing cmd-return. data look like now?Chain steps using pipes.","code":"\n# make a data table with 10 subjects\ndata_original <- tibble(\n  id = 1:10,\n  A1 = rnorm(10, 0),\n  A2 = rnorm(10, 1),\n  B1 = rnorm(10, 2),\n  B2 = rnorm(10, 3)\n)\n\n# gather columns A1 to B2 into \"variable\" and \"value\" columns\ndata_gathered <- gather(data_original, variable, value, A1:B2)\n\n# separate the variable column at the _ into \"var\" and \"var_n\" columns\ndata_separated <- separate(data_gathered, variable, c(\"var\", \"var_n\"), sep = 1)\n\n# group the data by id and var\ndata_grouped <- group_by(data_separated, id, var)\n\n# calculate the mean value for each id/var \ndata_summarised <- summarise(data_grouped, mean = mean(value), .groups = \"drop\")\n\n# spread the mean column into A and B columns\ndata_spread <- spread(data_summarised, var, mean)\n\n# rename A and B to A_mean and B_mean\ndata <- rename(data_spread, A_mean = A, B_mean = B)\n\ndata\nmean_petal_width <- round(mean(iris$Petal.Width), 2)\n# do not ever do this!!\ndata <- rename(\n  spread(\n    summarise(\n      group_by(\n        separate(\n          gather(\n            tibble(\n              id = 1:10,\n              A1 = rnorm(10, 0),\n              A2 = rnorm(10, 1),\n              B1 = rnorm(10, 2),\n              B2 = rnorm(10,3)), \n            variable, value, A1:B2), \n          variable, c(\"var\", \"var_n\"), sep = 1), \n        id, var), \n      mean = mean(value), .groups = \"drop\"), \n    var, mean), \n  A_mean = A, B_mean = B)\n# calculate mean of A and B variables for each participant\ndata <- tibble(\n  id = 1:10,\n  A1 = rnorm(10, 0),\n  A2 = rnorm(10, 1),\n  B1 = rnorm(10, 2),\n  B2 = rnorm(10,3)\n) |>\n  gather(variable, value, A1:B2) |>\n  separate(variable, c(\"var\", \"var_n\"), sep=1) |>\n  group_by(id, var) |>\n  summarise(mean = mean(value), .groups = \"drop\") |>\n  spread(var, mean) |>\n  rename(A_mean = A, B_mean = B)\npersonality_reshaped <- personality |>\n  gather(\"question\", \"score\", Op1:Ex9) |>\n  separate(question, c(\"domain\", \"qnumber\"), sep = 2) |>\n  unite(\"domain_n\", domain, qnumber, sep = \"_Q\") |>\n  spread(domain_n, score)"},{"path":"tidyr.html","id":"more-complex-example","chapter":"6 Tidy Data","heading":"6.7 More Complex Example","text":"","code":""},{"path":"tidyr.html","id":"load-data-1","chapter":"6 Tidy Data","heading":"6.7.1 Load Data","text":"Get data infant maternal mortality rates reprores package. package, can download :infant mortalitymaternal mortality","code":"\ndata(\"infmort\")\nhead(infmort)\ndata(\"matmort\")\nhead(matmort)"},{"path":"tidyr.html","id":"wide-to-long","chapter":"6 Tidy Data","heading":"6.7.2 Wide to Long","text":"matmort wide format, separate column year. Change long format, row Country/Year observation.example complicated column names gather numbers. column names non-standard (e.g., spaces, start numbers, special characters), can enclose backticks (`) like example .can put matmort first argument pivot_longer(); pipe . working data processing often find needing insert rearrange steps constantly introduce errors forgetting take first argument pipe chain, now start original data table pipe .Alternatively, can use gather() function.","code":"\nmatmort_long <- matmort |>\n  pivot_longer(cols = `1990`:`2015`,\n               names_to = \"Year\",\n               values_to = \"stats\") |>\n  glimpse()## Rows: 543\n## Columns: 3\n## $ Country <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Albania\", \"Alban…\n## $ Year    <chr> \"1990\", \"2000\", \"2015\", \"1990\", \"2000\", \"2015\", \"1990\", \"2000\"…\n## $ stats   <chr> \"1 340 [ 878 - 1 950]\", \"1 100 [ 745 - 1 570]\", \"396 [ 253 -  …\nmatmort_long <- matmort |>\n  gather(\"Year\", \"stats\", `1990`:`2015`) |>\n  glimpse()## Rows: 543\n## Columns: 3\n## $ Country <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", \"A…\n## $ Year    <chr> \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\"…\n## $ stats   <chr> \"1 340 [ 878 - 1 950]\", \"71 [ 58 -  88]\", \"216 [ 141 -  327]\",…"},{"path":"tidyr.html","id":"one-piece-of-data-per-column","chapter":"6 Tidy Data","heading":"6.7.3 One Piece of Data per Column","text":"data stats column unusual format sort confidence interval brackets lots extra spaces. need spaces, first remove mutate(), learn next lesson.separate function separate data anything number letter, try first without specifying sep argument. argument list new column names.gsub(pattern, replacement, x) function \nflexible way search replace. example replaces occurances pattern \" \" (space), replacement \"\" (nothing), string x (stats column). Use sub() instead want replace first occurance pattern. used simple pattern , can use complicated regex patterns replace, example, even numbers (e.g., gsub(\"[:02468:]\", \"*\", \"id = 123456\")) occurances word colour US UK spelling\n(e.g., gsub(\"colo(u)?r\", \"***\", \"replace color, colour, colours, collors\")).","code":"\nmatmort_split <- matmort_long |>\n  mutate(stats = gsub(\" \", \"\", stats)) |>\n  separate(stats, c(\"rate\", \"ci_low\", \"ci_hi\")) |>\n  glimpse()## Warning: Expected 3 pieces. Additional pieces discarded in 543 rows [1, 2, 3, 4,\n## 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].## Rows: 543\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", \"A…\n## $ Year    <chr> \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\"…\n## $ rate    <chr> \"1340\", \"71\", \"216\", \"1160\", \"72\", \"58\", \"8\", \"8\", \"64\", \"46\",…\n## $ ci_low  <chr> \"878\", \"58\", \"141\", \"627\", \"64\", \"51\", \"7\", \"7\", \"56\", \"34\", \"…\n## $ ci_hi   <chr> \"1950\", \"88\", \"327\", \"2020\", \"80\", \"65\", \"9\", \"10\", \"74\", \"61\"…"},{"path":"tidyr.html","id":"extra","chapter":"6 Tidy Data","heading":"6.7.3.1 Handle spare columns with extra","text":"previous example given error warning \n\"Additional pieces discarded 543 rows\". separate splits column brackets dashes, text 100[90-110] split four values c(\"100\", \"90\", \"110\", \"\"), specified 3 new columns. fourth value always empty (just part last bracket), happy drop , separate generates warning accidentally. can turn warning adding extra argument setting \"drop\". Look help ??tidyr::separate see options .","code":"\nmatmort_split <- matmort_long |>\n  mutate(stats = gsub(\" \", \"\", stats)) |>\n  separate(stats, c(\"rate\", \"ci_low\", \"ci_hi\"), extra = \"drop\") |>\n  glimpse()## Rows: 543\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", \"A…\n## $ Year    <chr> \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\"…\n## $ rate    <chr> \"1340\", \"71\", \"216\", \"1160\", \"72\", \"58\", \"8\", \"8\", \"64\", \"46\",…\n## $ ci_low  <chr> \"878\", \"58\", \"141\", \"627\", \"64\", \"51\", \"7\", \"7\", \"56\", \"34\", \"…\n## $ ci_hi   <chr> \"1950\", \"88\", \"327\", \"2020\", \"80\", \"65\", \"9\", \"10\", \"74\", \"61\"…"},{"path":"tidyr.html","id":"sep","chapter":"6 Tidy Data","heading":"6.7.3.2 Set delimiters with sep","text":"Now infmort. already long format, need use gather, third column ridiculously long name, can just refer column number (3).Wait, work ! split column spaces, brackets, full stops. just want split spaces, brackets dashes. need manually set sep delimiters . Also, arguments specified function, easier read put one argument line.","code":"\ninfmort_split <- infmort |>\n  separate(3, c(\"rate\", \"ci_low\", \"ci_hi\"), extra = \"drop\") |>\n  glimpse()## Rows: 5,044\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"A…\n## $ Year    <dbl> 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 20…\n## $ rate    <chr> \"66\", \"68\", \"69\", \"71\", \"73\", \"75\", \"76\", \"78\", \"80\", \"82\", \"8…\n## $ ci_low  <chr> \"3\", \"1\", \"9\", \"7\", \"4\", \"1\", \"8\", \"6\", \"4\", \"3\", \"4\", \"7\", \"0…\n## $ ci_hi   <chr> \"52\", \"55\", \"58\", \"61\", \"64\", \"66\", \"69\", \"71\", \"73\", \"75\", \"7…"},{"path":"tidyr.html","id":"regex","chapter":"6 Tidy Data","heading":"","text":"can use regular expressions\nseparate complex columns. , want separate dashes brackets. can separate list delimiters putting parentheses, separated \"|\". little complicated brackets special meaning regex, need \"escape\" left one two backslashes \"\\\\\".","code":"\ninfmort_split <- infmort |>\n  separate(\n    col = 3, \n    into = c(\"rate\", \"ci_low\", \"ci_hi\"), \n    extra = \"drop\", \n    sep = \"(\\\\[|-|])\"\n  ) |>\n  glimpse()## Rows: 5,044\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"A…\n## $ Year    <dbl> 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 20…\n## $ rate    <chr> \"66.3 \", \"68.1 \", \"69.9 \", \"71.7 \", \"73.4 \", \"75.1 \", \"76.8 \",…\n## $ ci_low  <chr> \"52.7\", \"55.7\", \"58.7\", \"61.6\", \"64.4\", \"66.9\", \"69.0\", \"71.2\"…\n## $ ci_hi   <chr> \"83.9\", \"83.6\", \"83.5\", \"83.7\", \"84.2\", \"85.1\", \"86.1\", \"87.3\"…"},{"path":"tidyr.html","id":"convert","chapter":"6 Tidy Data","heading":"6.7.3.3 Fix data types with convert","text":"better. Notice  next Year, rate, ci_low ci_hi. means columns hold characters (like words), numbers integers. can cause problems try thigs like average numbers (average words), can fix adding argument convert setting TRUE.matmort.","code":"\ninfmort_split <- infmort |>\n  separate(col = 3, \n           into = c(\"rate\", \"ci_low\", \"ci_hi\"), \n           extra = \"drop\", \n           sep = \"(\\\\[|-|])\", \n           convert = TRUE) |>\n  glimpse()## Rows: 5,044\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"A…\n## $ Year    <dbl> 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 20…\n## $ rate    <dbl> 66.3, 68.1, 69.9, 71.7, 73.4, 75.1, 76.8, 78.6, 80.4, 82.3, 84…\n## $ ci_low  <dbl> 52.7, 55.7, 58.7, 61.6, 64.4, 66.9, 69.0, 71.2, 73.4, 75.5, 77…\n## $ ci_hi   <dbl> 83.9, 83.6, 83.5, 83.7, 84.2, 85.1, 86.1, 87.3, 88.9, 90.7, 92…\nmatmort_split <- matmort_long |>\n  mutate(stats = gsub(\" \", \"\", stats)) |>\n  separate(col = stats, \n           into = c(\"rate\", \"ci_low\", \"ci_hi\"), \n           extra = \"drop\", \n           convert = TRUE) |>\n  glimpse()## Rows: 543\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", \"A…\n## $ Year    <chr> \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\"…\n## $ rate    <int> 1340, 71, 216, 1160, 72, 58, 8, 8, 64, 46, 26, 569, 58, 33, 9,…\n## $ ci_low  <int> 878, 58, 141, 627, 64, 51, 7, 7, 56, 34, 20, 446, 47, 28, 7, 4…\n## $ ci_hi   <int> 1950, 88, 327, 2020, 80, 65, 9, 10, 74, 61, 33, 715, 72, 38, 1…"},{"path":"tidyr.html","id":"all-in-one-step","chapter":"6 Tidy Data","heading":"6.7.4 All in one step","text":"can chain steps matmort together, since need intermediate data tables.","code":"\nmatmort2 <- matmort |>\n  gather(\"Year\", \"stats\", `1990`:`2015`) |>\n  mutate(stats = gsub(\" \", \"\", stats)) |>\n  separate(\n    col = stats, \n    into = c(\"rate\", \"ci_low\", \"ci_hi\"), \n    extra = \"drop\", \n    convert = TRUE\n  ) |>\n  glimpse()## Rows: 543\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", \"A…\n## $ Year    <chr> \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\"…\n## $ rate    <int> 1340, 71, 216, 1160, 72, 58, 8, 8, 64, 46, 26, 569, 58, 33, 9,…\n## $ ci_low  <int> 878, 58, 141, 627, 64, 51, 7, 7, 56, 34, 20, 446, 47, 28, 7, 4…\n## $ ci_hi   <int> 1950, 88, 327, 2020, 80, 65, 9, 10, 74, 61, 33, 715, 72, 38, 1…"},{"path":"tidyr.html","id":"columns-by-year","chapter":"6 Tidy Data","heading":"6.7.5 Columns by Year","text":"Spread maternal mortality rate year.Nope, work , really common mistake spreading data. spread matches remaining columns, Afghanistan ci_low 253 treated different observation Afghanistan ci_low 745.pivot_wider() can useful. can set values_from multiple column names names added names_from values.","code":"\nmatmort_wide <- matmort2 |>\n  spread(key = Year, value = rate) |>\n  print()## # A tibble: 542 × 6\n##    Country     ci_low ci_hi `1990` `2000` `2015`\n##    <chr>        <int> <int>  <int>  <int>  <int>\n##  1 Afghanistan    253   620     NA     NA    396\n##  2 Afghanistan    745  1570     NA   1100     NA\n##  3 Afghanistan    878  1950   1340     NA     NA\n##  4 Albania         16    46     NA     NA     29\n##  5 Albania         33    56     NA     43     NA\n##  6 Albania         58    88     71     NA     NA\n##  7 Algeria         82   244     NA     NA    140\n##  8 Algeria        118   241     NA    170     NA\n##  9 Algeria        141   327    216     NA     NA\n## 10 Angola         221   988     NA     NA    477\n## # … with 532 more rows\n## # ℹ Use `print(n = ...)` to see more rows\nmatmort_wide <- matmort2 |>\n  pivot_wider(\n    names_from = Year,\n    values_from = c(rate, ci_low, ci_hi)\n  )\n              \nglimpse(matmort_wide)## Rows: 181\n## Columns: 10\n## $ Country     <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\"…\n## $ rate_1990   <int> 1340, 71, 216, 1160, 72, 58, 8, 8, 64, 46, 26, 569, 58, 33…\n## $ rate_2000   <int> 1100, 43, 170, 924, 60, 40, 9, 5, 48, 61, 21, 399, 48, 26,…\n## $ rate_2015   <int> 396, 29, 140, 477, 52, 25, 6, 4, 25, 80, 15, 176, 27, 4, 7…\n## $ ci_low_1990 <int> 878, 58, 141, 627, 64, 51, 7, 7, 56, 34, 20, 446, 47, 28, …\n## $ ci_low_2000 <int> 745, 33, 118, 472, 54, 35, 8, 4, 42, 50, 18, 322, 38, 22, …\n## $ ci_low_2015 <int> 253, 16, 82, 221, 44, 21, 5, 3, 17, 53, 12, 125, 19, 3, 5,…\n## $ ci_hi_1990  <int> 1950, 88, 327, 2020, 80, 65, 9, 10, 74, 61, 33, 715, 72, 3…\n## $ ci_hi_2000  <int> 1570, 56, 241, 1730, 65, 46, 10, 6, 55, 74, 26, 496, 58, 3…\n## $ ci_hi_2015  <int> 620, 46, 244, 988, 63, 31, 7, 5, 35, 124, 19, 280, 37, 6, …"},{"path":"tidyr.html","id":"experimentum-data","chapter":"6 Tidy Data","heading":"6.7.6 Experimentum Data","text":"Students Institute Neuroscience Psychology University Glasgow can use online experiment builder platform, Experimentum. platform also open source github anyone can install web server. allows group questionnaires experiments projects randomisation counterbalancing. Data questionnaires experiments downloadable long format, researchers often need put wide format analysis.Look help menu built-dataset experimentum_quests learn column . Subjects asked questions dogs test different questionnaire response types.current: dog? (yes/)past: ever owned dog? (yes/)name: best name dog? (free short text)good: good dogs? (1=pretty good:7=good)country: country borzois come ?good_borzoi: good borzois? (0=pretty good:100=good)text: Write text dogs. (free long text)time: time ? (time)get dataset wide format, question separate column, use following code:responses dv column multiple types (e.g., integer, double, character), represented character strings column. spread data wide format, column given ocrrect data type. function type.convert() makes best guess type new column converts . argument .= TRUE converts columns none numbers decimal places integers.","code":"\nq <- experimentum_quests |>\n  pivot_wider(id_cols = session_id:user_age,\n              names_from = q_name,\n              values_from = dv) |>\n  type.convert(as.is = TRUE) |>\n  print()## # A tibble: 24 × 15\n##    session…¹ proje…² quest…³ user_id user_…⁴ user_…⁵ user_…⁶ current  past name \n##        <int>   <int>   <int>   <int> <chr>   <chr>     <dbl>   <int> <int> <chr>\n##  1     34034       1       1   31105 female  guest      28.2       1     1 Ruby \n##  2     34104       1       1   31164 male    regist…    19.4       1     1 stev…\n##  3     34326       1       1   31392 female  guest      17         0     0 Cat  \n##  4     34343       1       1   31397 male    guest      22         1     1 Dukee\n##  5     34765       1       1   31770 female  guest      44         1     1 <NA> \n##  6     34796       1       1   31796 female  guest      35.9       0     0 Patch\n##  7     34806       1       1   31798 female  guest      35         0     1 Teddy\n##  8     34822       1       1   31802 female  guest      58         1     1 Lara \n##  9     34864       1       1   31820 male    guest      20         0     0 Pawpy\n## 10     35014       1       1   31921 female  student    39.2       1     1 Herb…\n## # … with 14 more rows, 5 more variables: good <int>, country <chr>, text <chr>,\n## #   good_borzoi <int>, time <chr>, and abbreviated variable names ¹​session_id,\n## #   ²​project_id, ³​quest_id, ⁴​user_sex, ⁵​user_status, ⁶​user_age\n## # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"},{"path":"tidyr.html","id":"glossary-tidyr","chapter":"6 Tidy Data","heading":"6.8 Glossary","text":"","code":""},{"path":"tidyr.html","id":"resources-tidyr","chapter":"6 Tidy Data","heading":"6.9 Further Resources","text":"Tidy DataChapter 12: Tidy Data R Data ScienceChapter 18: Pipes R Data ScienceData wrangling cheat sheet","code":""},{"path":"dplyr.html","id":"dplyr","chapter":"7 Data Wrangling","heading":"7 Data Wrangling","text":"","code":""},{"path":"dplyr.html","id":"ilo-dplyr","chapter":"7 Data Wrangling","heading":"7.1 Learning Objectives","text":"","code":""},{"path":"dplyr.html","id":"basic-2","chapter":"7 Data Wrangling","heading":"Basic","text":"able use 6 main dplyr one-table verbs: (video)\nselect()\nfilter()\narrange()\nmutate()\nsummarise()\ngroup_by()\nselect()filter()arrange()mutate()summarise()group_by()able wrangle data chaining tidyr dplyr functions (video)able use additional one-table verbs: (video)\nrename()\ndistinct()\ncount()\nslice()\npull()\nrename()distinct()count()slice()pull()","code":""},{"path":"dplyr.html","id":"intermediate-2","chapter":"7 Data Wrangling","heading":"Intermediate","text":"Fine control select() operations (video)Use window functions (video)","code":""},{"path":"dplyr.html","id":"setup-dplyr","chapter":"7 Data Wrangling","heading":"7.2 Setup","text":"Open reprores-class-notes projectCreate new R Markdown file called 07-dplyr.RmdUpdate YAML headerReplace setup chunk one :Download Data transformation cheat sheet.","code":"```{r setup, include = FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n\n# packages needed for this chapter\nlibrary(tidyverse) # loads tidyr for pivot functions and tidy verbs\nlibrary(lubridate) # handling dates and times\nlibrary(reprores)  # class-specific datasets\n\nset.seed(8675309) # makes sure random numbers are reproducible```"},{"path":"dplyr.html","id":"data-disgust","chapter":"7 Data Wrangling","heading":"7.2.1 The disgust dataset","text":"examples use data reprores::disgust, contains data Three Domain Disgust Scale. participant identified unique user_id questionnaire completion unique id. Look Help dataset see individual questions.","code":"\ndata(\"disgust\", package = \"reprores\")\n\n#disgust <- read_csv(\"https://psyteachr.github.io/reprores/data/disgust.csv\")"},{"path":"dplyr.html","id":"six-main-dplyr-verbs","chapter":"7 Data Wrangling","heading":"7.3 Six main dplyr verbs","text":"data wrangling want psychological data involve tidyr functions learned Chapter 4 six main dplyr verbs: select, filter, arrange, mutate, summarise, group_by.","code":""},{"path":"dplyr.html","id":"select","chapter":"7 Data Wrangling","heading":"7.3.1 select()","text":"Select columns name number.can select column individually, separated commas (e.g., col1, col2). can also select columns two columns separating colon (e.g., start_col:end_col).can select columns number, useful column names long complicated.can use minus symbol unselect columns, leaving columns. want exclude span columns, put parentheses around span first (e.g., -(moral1:moral7), -moral1:moral7).","code":"\nmoral <- disgust |> select(user_id, moral1:moral7)\nnames(moral)## [1] \"user_id\" \"moral1\"  \"moral2\"  \"moral3\"  \"moral4\"  \"moral5\"  \"moral6\" \n## [8] \"moral7\"\nsexual <- disgust |> select(2, 11:17)\nnames(sexual)## [1] \"user_id\" \"sexual1\" \"sexual2\" \"sexual3\" \"sexual4\" \"sexual5\" \"sexual6\"\n## [8] \"sexual7\"\npathogen <- disgust |> select(-id, -date, -(moral1:sexual7))\nnames(pathogen)## [1] \"user_id\"   \"pathogen1\" \"pathogen2\" \"pathogen3\" \"pathogen4\" \"pathogen5\"\n## [7] \"pathogen6\" \"pathogen7\""},{"path":"dplyr.html","id":"select_helpers","chapter":"7 Data Wrangling","heading":"7.3.1.1 Select helpers","text":"can select columns based criteria column names.","code":""},{"path":"dplyr.html","id":"starts_with","chapter":"7 Data Wrangling","heading":"7.3.1.1.1 starts_with()","text":"Select columns start character string.","code":"\nu <- disgust |> select(starts_with(\"u\"))\nnames(u)## [1] \"user_id\""},{"path":"dplyr.html","id":"ends_with","chapter":"7 Data Wrangling","heading":"7.3.1.1.2 ends_with()","text":"Select columns end character string.","code":"\nfirstq <- disgust |> select(ends_with(\"1\"))\nnames(firstq)## [1] \"moral1\"    \"sexual1\"   \"pathogen1\""},{"path":"dplyr.html","id":"contains","chapter":"7 Data Wrangling","heading":"7.3.1.1.3 contains()","text":"Select columns contain character string.","code":"\npathogen <- disgust |> select(contains(\"pathogen\"))\nnames(pathogen)## [1] \"pathogen1\" \"pathogen2\" \"pathogen3\" \"pathogen4\" \"pathogen5\" \"pathogen6\"\n## [7] \"pathogen7\""},{"path":"dplyr.html","id":"num_range","chapter":"7 Data Wrangling","heading":"7.3.1.1.4 num_range()","text":"Select columns name matches pattern prefix.Use width set number digits leading\nzeros. example, num_range('var_', 8:10, width=2) selects columns var_08, var_09, var_10.","code":"\nmoral2_4 <- disgust |> select(num_range(\"moral\", 2:4))\nnames(moral2_4)## [1] \"moral2\" \"moral3\" \"moral4\""},{"path":"dplyr.html","id":"filter","chapter":"7 Data Wrangling","heading":"7.3.2 filter()","text":"Select rows matching column criteria.Select rows user_id 1 (Lisa).Remember use == = check two things equivalent. single = assigns righthand value lefthand variable (usually) evaluates TRUE.can select multiple criteria separating commas.can use symbols &, |, ! mean \"\", \"\", \"\". can also use operators make equations.","code":"\ndisgust |> filter(user_id == 1)\namoral <- disgust |> filter(\n  moral1 == 0, \n  moral2 == 0,\n  moral3 == 0, \n  moral4 == 0,\n  moral5 == 0,\n  moral6 == 0,\n  moral7 == 0\n)\n# everyone who chose either 0 or 7 for question moral1\nmoral_extremes <- disgust |> \n  filter(moral1 == 0 | moral1 == 7)\n\n# everyone who chose the same answer for all moral questions\nmoral_consistent <- disgust |> \n  filter(\n    moral2 == moral1 & \n    moral3 == moral1 & \n    moral4 == moral1 &\n    moral5 == moral1 &\n    moral6 == moral1 &\n    moral7 == moral1\n  )\n\n# everyone who did not answer 7 for all 7 moral questions\nmoral_no_ceiling <- disgust |>\n  filter(moral1+moral2+moral3+moral4+moral5+moral6+moral7 != 7*7)"},{"path":"dplyr.html","id":"match-operator","chapter":"7 Data Wrangling","heading":"7.3.2.1 Match operator (%in%)","text":"Sometimes need exclude participant IDs reasons described code. match operator (%%) useful testing column value list. Surround equation parentheses put ! front test value list.","code":"\nno_researchers <- disgust |>\n  filter(!(user_id %in% c(1,2)))"},{"path":"dplyr.html","id":"dates","chapter":"7 Data Wrangling","heading":"7.3.2.2 Dates","text":"can use lubridate package work dates. example, can use year() function return just year date column select data collected 2010.\nTable 7.1: Rows 1-6 disgust2010\nselect data least 5 years ago. can use range function check minimum maximum dates resulting dataset.","code":"\ndisgust2010 <- disgust |>\n  filter(year(date) == 2010)\ndisgust_5ago <- disgust |>\n  filter(date < today() - dyears(5))\n\nrange(disgust_5ago$date)## [1] \"2008-07-10\" \"2017-08-21\""},{"path":"dplyr.html","id":"arrange","chapter":"7 Data Wrangling","heading":"7.3.3 arrange()","text":"Sort dataset using arrange(). find needing sort data R much less Excel, since need rows next order , example, calculate group means. arrange() can useful preparing data display tables.\nTable 7.2: Rows 1-6 disgust_order\nReverse order using desc()\nTable 7.3: Rows 1-6 disgust_order_desc\n","code":"\ndisgust_order <- disgust |>\n  arrange(date, moral1)\ndisgust_order_desc <- disgust |>\n  arrange(desc(date))"},{"path":"dplyr.html","id":"mutate","chapter":"7 Data Wrangling","heading":"7.3.4 mutate()","text":"Add new columns. one useful functions tidyverse.Refer columns names (unquoted). can add one column mutate function, just separate columns comma. make new column, can use column definitions e.g., total ).\nTable 7.4: Rows 1-6 disgust_total\ncan overwrite column giving new column name old column (see user_id) . Make sure mean trying use old column value redefine .","code":"\ndisgust_total <- disgust |>\n  mutate(\n    pathogen = pathogen1 + pathogen2 + pathogen3 + pathogen4 + pathogen5 + pathogen6 + pathogen7,\n    moral = moral1 + moral2 + moral3 + moral4 + moral5 + moral6 + moral7,\n    sexual = sexual1 + sexual2 + sexual3 + sexual4 + sexual5 + sexual6 + sexual7,\n    total = pathogen + moral + sexual,\n    user_id = paste0(\"U\", user_id)\n  )"},{"path":"dplyr.html","id":"summarise","chapter":"7 Data Wrangling","heading":"7.3.5 summarise()","text":"Create summary statistics dataset. Check Data Wrangling Cheat Sheet Data Transformation Cheat Sheet various summary functions. common ones : mean(), sd(), n(), sum(), quantile().\nTable 7.5: rows disgust_summary\n","code":"\ndisgust_summary<- disgust_total |>\n  summarise(\n    n = n(),\n    q25 = quantile(total, .25, na.rm = TRUE),\n    q50 = quantile(total, .50, na.rm = TRUE),\n    q75 = quantile(total, .75, na.rm = TRUE),\n    avg_total = mean(total, na.rm = TRUE),\n    sd_total  = sd(total, na.rm = TRUE),\n    min_total = min(total, na.rm = TRUE),\n    max_total = max(total, na.rm = TRUE)\n  )"},{"path":"dplyr.html","id":"group_by","chapter":"7 Data Wrangling","heading":"7.3.6 group_by()","text":"Create subsets data. can use create summaries,\nlike mean value experimental groups., use mutate create new column called year, group year, calculate average scores.\nTable 7.6: rows disgust_groups\nadd .groups = \"drop\" end summarise() function, get following message: \"summarise() ungrouping output (override .groups argument)\". just reminds groups still effect functions also grouped.Older versions dplyr , older code generate warning run newer version dplyr. Older code might ungroup() summarise() indicate groupings dropped. default behaviour usually correct, need worry, best explicitly set .groups summarise() function group_by() want \"keep\" \"drop\" groupings.can use filter group_by. following example returns lowest total score year (.e., row rank() value column total equivalent 1).\nTable 7.7: rows disgust_lowest\ncan also use mutate group_by. following example calculates subject-mean-centered scores grouping scores user_id subtracting group-specific mean score. Note use gather tidy data long format first.Use ungroup() soon done grouped functions, otherwise data table still grouped use future.\nTable 7.8: Rows 1-6 disgust_smc\n","code":"\ndisgust_groups <- disgust_total |>\n  mutate(year = year(date)) |>\n  group_by(year) |>\n  summarise(\n    n = n(),\n    avg_total = mean(total, na.rm = TRUE),\n    sd_total  = sd(total, na.rm = TRUE),\n    min_total = min(total, na.rm = TRUE),\n    max_total = max(total, na.rm = TRUE),\n    .groups = \"drop\"\n  )\ndisgust_lowest <- disgust_total |>\n  mutate(year = year(date)) |>\n  select(user_id, year, total) |>\n  group_by(year) |>\n  filter(rank(total) == 1) |>\n  arrange(year)\ndisgust_smc <- disgust |>\n  gather(\"question\", \"score\", moral1:pathogen7) |>\n  group_by(user_id) |>\n  mutate(score_smc = score - mean(score, na.rm = TRUE)) |> \n  ungroup()"},{"path":"dplyr.html","id":"all-together","chapter":"7 Data Wrangling","heading":"7.3.7 All Together","text":"lot easier data tidy, first. can use group_by calculate domain scores., can spread 3 domains, calculate total score, remove rows missing (NA) total, calculate mean values year.\nTable 7.9: Rows 1-6 disgust_tidy\n\nTable 7.10: Rows 1-6 disgust_scored\n\nTable 7.11: Rows 1-6 disgust_summarised\n","code":"\ndisgust_tidy <- reprores::disgust |>\n  gather(\"question\", \"score\", moral1:pathogen7) |>\n  separate(question, c(\"domain\",\"q_num\"), sep = -1) |>\n  group_by(id, user_id, date, domain) |>\n  summarise(score = mean(score), .groups = \"drop\")\ndisgust_scored <- disgust_tidy |>\n  spread(domain, score) |>\n  mutate(\n    total = moral + sexual + pathogen,\n    year = year(date)\n  ) |>\n  filter(!is.na(total)) |>\n  arrange(user_id) \ndisgust_summarised <- disgust_scored |>\n  group_by(year) |>\n  summarise(\n    n = n(),\n    avg_pathogen = mean(pathogen),\n    avg_moral = mean(moral),\n    avg_sexual = mean(sexual),\n    first_user = first(user_id),\n    last_user = last(user_id),\n    .groups = \"drop\"\n  )"},{"path":"dplyr.html","id":"additional-dplyr-one-table-verbs","chapter":"7 Data Wrangling","heading":"7.4 Additional dplyr one-table verbs","text":"Use code examples help pages figure following one-table verbs . pretty self-explanatory names.","code":""},{"path":"dplyr.html","id":"rename","chapter":"7 Data Wrangling","heading":"7.4.1 rename()","text":"can rename columns rename(). Set argument name new name, value old name. need put name quotes backticks follow rules good variable name (contains letter, numbers, underscores, full stops; start number).Almost everyone gets confused point rename() tries put original names left new names right. Try see error message looks like.","code":"\nsw <- starwars |>\n  rename(Name = name,\n         Height = height,\n         Mass = mass,\n         `Hair Colour` = hair_color,\n         `Skin Colour` = skin_color,\n         `Eye Colour` = eye_color,\n         `Birth Year` = birth_year)\n\nnames(sw)##  [1] \"Name\"        \"Height\"      \"Mass\"        \"Hair Colour\" \"Skin Colour\"\n##  [6] \"Eye Colour\"  \"Birth Year\"  \"sex\"         \"gender\"      \"homeworld\"  \n## [11] \"species\"     \"films\"       \"vehicles\"    \"starships\""},{"path":"dplyr.html","id":"distinct","chapter":"7 Data Wrangling","heading":"7.4.2 distinct()","text":"Get rid exactly duplicate rows distinct(). can helpful , example, merging data multiple computers data got copied one computer another, creating duplicate rows.","code":"\n# create a data table with duplicated values\ndupes <- tibble(\n  id = c( 1,   2,   1,   2,   1,   2),\n  dv = c(\"A\", \"B\", \"C\", \"D\", \"A\", \"B\")\n)\n\ndistinct(dupes)"},{"path":"dplyr.html","id":"count","chapter":"7 Data Wrangling","heading":"7.4.3 count()","text":"function count() quick shortcut common combination group_by() summarise() used count number rows per group.","code":"\nstarwars |>\n  group_by(sex) |>\n  summarise(n = n(), .groups = \"drop\")\ncount(starwars, sex)"},{"path":"dplyr.html","id":"slice","chapter":"7 Data Wrangling","heading":"7.4.4 slice()","text":"","code":"\nslice(starwars, 1:3, 10)"},{"path":"dplyr.html","id":"pull","chapter":"7 Data Wrangling","heading":"7.4.5 pull()","text":"","code":"\nstarwars |>\n  filter(species == \"Droid\") |>\n  pull(name)## [1] \"C-3PO\"  \"R2-D2\"  \"R5-D4\"  \"IG-88\"  \"R4-P17\" \"BB8\""},{"path":"dplyr.html","id":"window","chapter":"7 Data Wrangling","heading":"7.5 Window functions","text":"Window functions use order rows calculate values. can use things require ranking ordering, like choose top scores class, accessing previous next rows, like calculating cumulative sums means.dplyr window functions vignette good detailed explanations functions, described useful ones .","code":""},{"path":"dplyr.html","id":"ranking-functions","chapter":"7 Data Wrangling","heading":"7.5.1 Ranking functions","text":"\nTable 6.1: rows grades\ndifferences among row_number(), rank(), min_rank(), dense_rank(), ntile()?row_number() need argument?happen gave argument grade class?think happen removed group_by(class) line ?added id grouping?happens change order rows?second argument ntile() ?can use window functions group data quantiles.\nTable 7.12: rows sw_mass\nrow NA values? get rid ?","code":"\ngrades <- tibble(\n  id = 1:5,\n  \"Data Skills\" = c(16, 17, 17, 19, 20), \n  \"Statistics\"  = c(14, 16, 18, 18, 19)\n) |>\n  gather(class, grade, 2:3) |>\n  group_by(class) |>\n  mutate(row_number = row_number(),\n         rank       = rank(grade),\n         min_rank   = min_rank(grade),\n         dense_rank = dense_rank(grade),\n         quartile   = ntile(grade, 4),\n         percentile = ntile(grade, 100))\nsw_mass <- starwars |>\n  group_by(tertile = ntile(mass, 3)) |>\n  summarise(min = min(mass),\n            max = max(mass),\n            mean = mean(mass),\n            .groups = \"drop\")"},{"path":"dplyr.html","id":"offset-functions","chapter":"7 Data Wrangling","heading":"7.5.2 Offset functions","text":"function lag() gives previous row's value. defaults 1 row back, can change n argument. function lead() gives values ahead current row.\nTable 7.13: rows lag_lead\ncan use offset functions calculate change trials value changes. Use order_by argument specify order rows. Alternatively, can use arrange() offset functions.\nTable 7.14: rows trials\nLook help pages lag() lead().happens remove order_by argument change cond?default argument ?Can think circumstances data might need use lag() lead()?","code":"\nlag_lead <- tibble(x = 1:6) |>\n  mutate(lag = lag(x),\n         lag2 = lag(x, n = 2),\n         lead = lead(x, default = 0))\ntrials <- tibble(\n  trial = sample(1:10, 10),\n  cond = sample(c(\"exp\", \"ctrl\"), 10, T),\n  score = rpois(10, 4)\n) |>\n  mutate(\n    score_change = score - lag(score, order_by = trial),\n    change_cond = cond != lag(cond, order_by = trial, \n                              default = \"no condition\")\n  ) |>\n  arrange(trial)"},{"path":"dplyr.html","id":"cumulative-aggregates","chapter":"7 Data Wrangling","heading":"7.5.3 Cumulative aggregates","text":"cumsum(), cummin(), cummax() base R functions calculating cumulative means, minimums, maximums. dplyr package introduces cumany() cumall(), return TRUE previous values meet criteria.\nTable 7.15: rows cumulative\nhappen change cumany(obs == 3) cumany(obs > 2)?happen change cumall(obs < 4) cumall(obs < 2)?Can think circumstances data might need use cumany() cumall()?","code":"\ncumulative <- tibble(\n  time = 1:10,\n  obs = c(2, 2, 1, 2, 4, 3, 1, 0, 3, 5)\n) |>\n  mutate(\n    cumsum = cumsum(obs),\n    cummin = cummin(obs),\n    cummax = cummax(obs),\n    cumany = cumany(obs == 3),\n    cumall = cumall(obs < 4)\n  )"},{"path":"dplyr.html","id":"glossary-dplyr","chapter":"7 Data Wrangling","heading":"7.6 Glossary","text":"","code":""},{"path":"dplyr.html","id":"resources-dplyr","chapter":"7 Data Wrangling","heading":"7.7 Further Resources","text":"Chapter 5: Data Transformation R Data ScienceData transformation cheat sheetChapter 16: Date times R Data Science","code":""},{"path":"func.html","id":"func","chapter":"8 Iteration & Functions","heading":"8 Iteration & Functions","text":"","code":""},{"path":"func.html","id":"ilo-func","chapter":"8 Iteration & Functions","heading":"8.1 Learning Objectives","text":"learn functions iteration using simulation calculate power analysis independent samples t-test.","code":""},{"path":"func.html","id":"basic-3","chapter":"8 Iteration & Functions","heading":"Basic","text":"Work basic iteration functions rep, seq, replicate (video)Use map() apply() functions (video)Write custom functions function() (video)Set default values arguments functions","code":""},{"path":"func.html","id":"intermediate-3","chapter":"8 Iteration & Functions","heading":"Intermediate","text":"Understand scopeUse error handling warnings function","code":""},{"path":"func.html","id":"advanced","chapter":"8 Iteration & Functions","heading":"Advanced","text":"topics (yet) covered materials, directions independent learning.Repeat commands multiple arguments using purrr::map2_*() purrr::pmap_*()Create nested data frames using dplyr::group_by() tidyr::nest()Work nested data frames dplyrCapture deal errors using 'adverb' functions purrr::safely() purrr::possibly()next two lectures, going learn iteration (commands ) custom functions data simulation exercise, also lead us traditional statistical topics.","code":""},{"path":"func.html","id":"setup-func","chapter":"8 Iteration & Functions","heading":"8.2 Setup","text":"Open reprores-class-notes projectCreate new R Markdown file called 08-func.RmdUpdate YAML headerReplace setup chunk one :Download Apply functions purrr cheat sheet.","code":"```{r setup, include = FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n\n# packages needed for this chapter\nlibrary(tidyverse)  # loads purrr for iteration\nlibrary(broom)      # converts test output to tidy tables\n\nset.seed(8675309) # makes sure random numbers are reproducible```"},{"path":"func.html","id":"iteration-functions","chapter":"8 Iteration & Functions","heading":"8.3 Iteration functions","text":"first learned two basic iteration functions, rep() seq() Working Data chapter.","code":""},{"path":"func.html","id":"rep","chapter":"8 Iteration & Functions","heading":"8.3.1 rep()","text":"function rep() lets repeat first argument number times.Use rep() create vector alternating \"\" \"B\" values length 24.specify second argument , defaults times, repeating vector first argument many times. Make vector , setting second argument explicitly.second argument vector length first argument, element first vector repeated many times. Use rep() create vector 11 \"\" values followed 3 \"B\" values.can repeat element vector sepcified number times using argument, Use rep() create vector 12 \"\" values followed 12 \"B\" values.think happen set times 3 2?","code":"\nrep(c(\"A\", \"B\"), 12)##  [1] \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\"\n## [20] \"B\" \"A\" \"B\" \"A\" \"B\"\nrep(c(\"A\", \"B\"), times = 12)##  [1] \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\"\n## [20] \"B\" \"A\" \"B\" \"A\" \"B\"\nrep(c(\"A\", \"B\"), c(11, 3))##  [1] \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"B\" \"B\" \"B\"\nrep(c(\"A\", \"B\"), each = 12)##  [1] \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"B\" \"B\" \"B\" \"B\" \"B\" \"B\" \"B\"\n## [20] \"B\" \"B\" \"B\" \"B\" \"B\"\nrep(c(\"A\", \"B\"), times = 3, each = 2)##  [1] \"A\" \"A\" \"B\" \"B\" \"A\" \"A\" \"B\" \"B\" \"A\" \"A\" \"B\" \"B\""},{"path":"func.html","id":"seq","chapter":"8 Iteration & Functions","heading":"8.3.2 seq()","text":"function seq() useful generating sequence numbers pattern.Use seq() create vector integers 0 10.can set argument count numbers 1 (default). Use seq() create vector numbers 0 100 10s.argument length.useful know many steps want divide something . Use seq() create vector starts 0, ends 100, 12 equally spaced steps (hint: many numbers vector 2 steps?).","code":"\nseq(0, 10)##  [1]  0  1  2  3  4  5  6  7  8  9 10\nseq(0, 100, by = 10)##  [1]   0  10  20  30  40  50  60  70  80  90 100\nseq(0, 100, length.out = 13)##  [1]   0.000000   8.333333  16.666667  25.000000  33.333333  41.666667\n##  [7]  50.000000  58.333333  66.666667  75.000000  83.333333  91.666667\n## [13] 100.000000"},{"path":"func.html","id":"replicate","chapter":"8 Iteration & Functions","heading":"8.3.3 replicate()","text":"can use replicate() function run function n times.example, can get 3 sets 5 numbers random normal distribution setting n 3 expr rnorm(5).default, replicate() simplifies result matrix easy convert table function returns vectors length. rather list vectors, set simplify = FALSE.","code":"\nreplicate(n = 3, expr = rnorm(5))##            [,1]       [,2]       [,3]\n## [1,] -0.9965824 0.98721974 -1.5495524\n## [2,]  0.7218241 0.02745393  1.0226378\n## [3,] -0.6172088 0.67287232  0.1500832\n## [4,]  2.0293916 0.57206650 -0.6599640\n## [5,]  1.0654161 0.90367770 -0.9945890\nreplicate(n = 3, expr = rnorm(5), simplify = FALSE)## [[1]]\n## [1]  1.9724587 -0.4418016 -0.9006372 -0.1505882 -0.8278942\n## \n## [[2]]\n## [1]  1.98582582  0.04400503 -0.40428231 -0.47299855 -0.41482324\n## \n## [[3]]\n## [1]  0.6832342  0.6902011  0.5334919 -0.1861048  0.3829458"},{"path":"func.html","id":"map-apply","chapter":"8 Iteration & Functions","heading":"8.3.4 map() and apply() functions","text":"purrr::map() lapply() return list length vector list, element result applying function corresponding element. function much , purrr functions optimisations working tidyverse. working mostly purrr functions course, apply functions common code might see examples web.Imagine want calculate power two-sample t-test mean difference 0.2 SD 1, sample sizes 100 1000 (100s). run power.t.test() function 20 times extract values \"power\" resulting list put table.However, apply() map() functions allow perform function item vector list. First make object n vector sample sizes want test, use lapply() map() run function power.t.test() item. can set arguments power.t.test() function argument.functions return list item result power.t.test(), returns list results includes named item \"power\". special list summary format just print directly:can see individual items using str() function.sapply() version lapply() returns vector array instead list, appropriate. corresponding purrr functions map_dbl(), map_chr(), map_int() map_lgl(), return vectors corresponding data type.can extract value list function [[. usually see written pcalc[[1]], put inside backticks, can use apply map functions.use map_dbl() value \"power\" double.can use map() functions inside mutate() function run power.t.test() function value n row table, extract value \"power\", delete column power calculations.\nFigure 8.1: Power two-sample t-test d = 0.2\n","code":"\np100 <- power.t.test(n = 100, delta = 0.2, sd = 1, type=\"two.sample\")\n# 18 more lines\np1000 <- power.t.test(n = 500, delta = 0.2, sd = 1, type=\"two.sample\")\n\ntibble(\n  n = c(100, \"...\", 1000),\n  power = c(p100$power, \"...\", p1000$power)\n)\nn <- seq(100, 1000, 100)\npcalc <- lapply(n, power.t.test, \n                delta = 0.2, sd = 1, type=\"two.sample\")\n# or\npcalc <- purrr::map(n, power.t.test, \n                delta = 0.2, sd = 1, type=\"two.sample\")\npcalc[[1]]## \n##      Two-sample t test power calculation \n## \n##               n = 100\n##           delta = 0.2\n##              sd = 1\n##       sig.level = 0.05\n##           power = 0.2902664\n##     alternative = two.sided\n## \n## NOTE: n is number in *each* group\npcalc[[1]] |> str()## List of 8\n##  $ n          : num 100\n##  $ delta      : num 0.2\n##  $ sd         : num 1\n##  $ sig.level  : num 0.05\n##  $ power      : num 0.29\n##  $ alternative: chr \"two.sided\"\n##  $ note       : chr \"n is number in *each* group\"\n##  $ method     : chr \"Two-sample t test power calculation\"\n##  - attr(*, \"class\")= chr \"power.htest\"\nsapply(pcalc, `[[`, \"power\")##  [1] 0.2902664 0.5140434 0.6863712 0.8064964 0.8847884 0.9333687 0.9623901\n##  [8] 0.9792066 0.9887083 0.9939638\npurrr::map_dbl(pcalc, `[[`, \"power\")##  [1] 0.2902664 0.5140434 0.6863712 0.8064964 0.8847884 0.9333687 0.9623901\n##  [8] 0.9792066 0.9887083 0.9939638\nmypower <- tibble(\n  n = seq(100, 1000, 100)) |>\n  mutate(pcalc = purrr::map(n, power.t.test, \n                            delta = 0.2, \n                            sd = 1, \n                            type=\"two.sample\"),\n         power = purrr::map_dbl(pcalc, `[[`, \"power\")) |>\n  select(-pcalc)"},{"path":"func.html","id":"custom-functions","chapter":"8 Iteration & Functions","heading":"8.4 Custom functions","text":"addition built-functions functions can access packages, can also write functions (eventually even packages!).","code":""},{"path":"func.html","id":"structure-function","chapter":"8 Iteration & Functions","heading":"8.4.1 Structuring a function","text":"general structure function follows:simple function. Can guess ?make function reports p-values APA format (\"p = [rounded value]\" p >= .001 \"p < .001\" p < .001).First, name function. can name anything, try duplicate existing functions overwrite . example, call function rep, need use base::rep() access normal rep function. call p-value function report_p set framework function.","code":"\nfunction_name <- function(my_args) {\n  # process the arguments\n  # return some value\n}\nadd1 <- function(my_number) {\n  my_number + 1\n}\n\nadd1(10)## [1] 11\nreport_p <- function() {\n}"},{"path":"func.html","id":"arguments","chapter":"8 Iteration & Functions","heading":"8.4.2 Arguments","text":"need add one argument, p-value want report. names choose arguments private argument, problem conflict variables script. put arguments parentheses function() order want default (just like built-functions used ).","code":"\nreport_p <- function(p) {\n}"},{"path":"func.html","id":"defaults","chapter":"8 Iteration & Functions","heading":"8.4.3 Argument defaults","text":"can add default value argument. argument skipped, function uses default argument. probably make sense run function without specifying p-value, can add second argument called digits defaults 3, can round p-values number digits.Now need write code inside function process input arguments turn returned output. Put output last item function.might also see returned output inside return() function. thing.run code defining function, output anything, makes new object Environment tab Functions. Now can run function.","code":"\nreport_p <- function(p, digits = 3) {\n}\nreport_p <- function(p, digits = 3) {\n  if (p < .001) {\n    reported = \"p < .001\"\n  } else {\n    roundp <- round(p, digits)\n    reported = paste(\"p =\", roundp)\n  }\n  \n  reported\n}\nreport_p <- function(p, digits = 3) {\n  if (p < .001) {\n    reported = \"p < .001\"\n  } else {\n    roundp <- round(p, digits)\n    reported = paste(\"p =\", roundp)\n  }\n  \n  return(reported)\n}\nreport_p(0.04869)\nreport_p(0.0000023)## [1] \"p = 0.049\"\n## [1] \"p < .001\""},{"path":"func.html","id":"scope","chapter":"8 Iteration & Functions","heading":"8.4.4 Scope","text":"happens function stays function. can change value variable passed function, change value variable outside function, even variable name one function.","code":"\nreported <- \"not changed\"\n\n# inside this function, reported == \"p = 0.002\"\nreport_p(0.0023) \n\nreported # still \"not changed\"## [1] \"p = 0.002\"\n## [1] \"not changed\""},{"path":"func.html","id":"warnings-errors","chapter":"8 Iteration & Functions","heading":"8.4.5 Warnings and errors","text":"might want add specific warning stop running function code someone enters value number. can stop() function.someone enters number possible p-value (0-1), might want warn probably intended, still continue function. can warning().","code":"\nreport_p <- function(p, digits = 3) {\n  if (!is.numeric(p)) stop(\"p must be a number\")\n  if (p <= 0) warning(\"p-values are normally greater than 0\")\n  if (p >= 1) warning(\"p-values are normally less than 1\")\n  \n  if (p < .001) {\n    reported = \"p < .001\"\n  } else {\n    roundp <- round(p, digits)\n    reported = paste(\"p =\", roundp)\n  }\n  \n  reported\n}\nreport_p()## Error in report_p(): argument \"p\" is missing, with no default\nreport_p(\"a\")## Error in report_p(\"a\"): p must be a number\nreport_p(-2)## Warning in report_p(-2): p-values are normally greater than 0\nreport_p(2)## Warning in report_p(2): p-values are normally less than 1## [1] \"p < .001\"\n## [1] \"p = 2\""},{"path":"func.html","id":"iterating-your-own-functions","chapter":"8 Iteration & Functions","heading":"8.5 Iterating your own functions","text":"","code":""},{"path":"func.html","id":"build-code","chapter":"8 Iteration & Functions","heading":"8.5.1 Build code","text":"First, build code want iterate.","code":""},{"path":"func.html","id":"simulate-and-structure-data","chapter":"8 Iteration & Functions","heading":"8.5.1.1 Simulate and structure data","text":"Create vector 20 random numbers drawn normal distribution mean 5 standard deviation 1 using rnorm() function store variable .tibble type table data.frame. function tibble::tibble() creates tibble column argument. argument takes form column_name = data_vector.Create table called dat including two vectors: vector 20 random normally distributed numbers mean 5 SD 1, B vector 20 random normally distributed numbers mean 5.5 SD 1.","code":"\nA <- rnorm(20, mean = 5, sd = 1)\ndat <- tibble(\n  A = rnorm(20, 5, 1),\n  B = rnorm(20, 5.5, 1)\n)"},{"path":"func.html","id":"statistical-test","chapter":"8 Iteration & Functions","heading":"8.5.1.2 Statistical test","text":"can run Welch two-sample t-test including two samples made first two arguments function t.test. can reference one column table names using format table_name$column_nameYou can also convert table long format using gather function specify t-test using format dv_column~grouping_column.","code":"\nt.test(dat$A, dat$B)## \n##  Welch Two Sample t-test\n## \n## data:  dat$A and dat$B\n## t = -1.7716, df = 36.244, p-value = 0.08487\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -1.2445818  0.0838683\n## sample estimates:\n## mean of x mean of y \n##  4.886096  5.466453\nlongdat <- gather(dat, group, score, A:B)\n\nt.test(score~group, data = longdat) ## \n##  Welch Two Sample t-test\n## \n## data:  score by group\n## t = -1.7716, df = 36.244, p-value = 0.08487\n## alternative hypothesis: true difference in means between group A and group B is not equal to 0\n## 95 percent confidence interval:\n##  -1.2445818  0.0838683\n## sample estimates:\n## mean in group A mean in group B \n##        4.886096        5.466453"},{"path":"func.html","id":"tidy-output","chapter":"8 Iteration & Functions","heading":"8.5.1.3 Tidy output","text":"can use function broom::tidy() extract data statistical test table format. example pipes everything together.pipeline , t.test(score~group, data = _) uses _ notation change location piped-data table default position first argument different position.","code":"\ntibble(\n  A = rnorm(20, 5, 1),\n  B = rnorm(20, 5.5, 1)\n) |>\n  gather(group, score, A:B) |>\n  t.test(score~group, data = _) |>\n  broom::tidy()"},{"path":"func.html","id":"extract-important-values","chapter":"8 Iteration & Functions","heading":"8.5.1.4 Extract important values","text":"Finally, can extract single value results table using pull().","code":"\ntibble(\n  A = rnorm(20, 5, 1),\n  B = rnorm(20, 5.5, 1)\n) |>\n  gather(group, score, A:B) |>\n  t.test(score~group, data = _) |>\n  broom::tidy() |>\n  pull(p.value)## [1] 0.7550108"},{"path":"func.html","id":"custom-function","chapter":"8 Iteration & Functions","heading":"8.5.2 Custom function","text":"Next, can group code inside function.First, name function t_sim wrap code function arguments.Run times see happens.","code":"\nt_sim <- function() {\n  tibble(\n    A = rnorm(20, 5, 1),\n    B = rnorm(20, 5.5, 1)\n  ) |>\n    gather(group, score, A:B) |>\n    t.test(score~group, data = _) |>\n    broom::tidy() |>\n    pull(p.value) \n}\nt_sim()## [1] 0.2744559"},{"path":"func.html","id":"iterate","chapter":"8 Iteration & Functions","heading":"8.5.2.1 Iterate","text":"run t_sim function 1000 times, assign resulting p-values vector called reps, check proportion p-values lower alpha (e.g., .05). number power analysis.","code":"\nreps <- replicate(1000, t_sim())\nalpha <- .05\npower <- mean(reps < alpha)\npower## [1] 0.329"},{"path":"func.html","id":"seed","chapter":"8 Iteration & Functions","heading":"8.5.2.2 Set seed","text":"can use set.seed function run function uses random numbers make sure get random data back time. can use integer like seed.Make sure ever use set.seed() inside simulation function, just simulate exact data .\nFigure 8.2: @KellyBodwin\n","code":"\nset.seed(90201)"},{"path":"func.html","id":"add-arguments","chapter":"8 Iteration & Functions","heading":"8.5.2.3 Add arguments","text":"can just edit function time want calculate power different sample n, efficient build function arguments. Redefine t_sim, setting arguments mean SD group , mean SD group B, number subjects per group. Give default values.","code":"\nt_sim <- function(n = 10, m1=0, sd1=1, m2=0, sd2=1) {\n  tibble(\n    A = rnorm(n, m1, sd1),\n    B = rnorm(n, m2, sd2)\n  ) |>\n    gather(group, score, A:B) |>\n    t.test(score~group, data = _) |>\n    broom::tidy() |>\n    pull(p.value) \n}"},{"path":"func.html","id":"test-your-function","chapter":"8 Iteration & Functions","heading":"8.5.3 Test your function","text":"Test function different values see results make sense.Use replicate calculate power 100 subjects/group effect size 0.2 (e.g., : m = 0, SD = 1; B: m = 0.2, SD = 1). Use 1000 replications.Compare power calculated power.t.test function.Calculate power via simulation power.t.test following tests:20 subjects/group, : m = 0, SD = 1; B: m = 0.2, SD = 140 subjects/group, : m = 0, SD = 1; B: m = 0.2, SD = 120 subjects/group, : m = 10, SD = 1; B: m = 12, SD = 1.5","code":"\nt_sim(100)\nt_sim(100, 0, 1, 0.5, 1)## [1] 0.8460064\n## [1] 0.0002446404\nreps <- replicate(1000, t_sim(100, 0, 1, 0.2, 1))\npower <- mean(reps < .05)\npower## [1] 0.284\npower.t.test(n = 100, delta = 0.2, sd = 1, type=\"two.sample\")## \n##      Two-sample t test power calculation \n## \n##               n = 100\n##           delta = 0.2\n##              sd = 1\n##       sig.level = 0.05\n##           power = 0.2902664\n##     alternative = two.sided\n## \n## NOTE: n is number in *each* group"},{"path":"func.html","id":"glossary-func","chapter":"8 Iteration & Functions","heading":"8.6 Glossary","text":"","code":""},{"path":"func.html","id":"resources-func","chapter":"8 Iteration & Functions","heading":"8.7 Further Resources","text":"Chapters 19 21 R Data ScienceApply functions purrr cheat sheet","code":""},{"path":"sim.html","id":"sim","chapter":"9 Probability & Simulation","heading":"9 Probability & Simulation","text":"","code":""},{"path":"sim.html","id":"ilo-sim","chapter":"9 Probability & Simulation","heading":"9.1 Learning Objectives","text":"","code":""},{"path":"sim.html","id":"basic-4","chapter":"9 Probability & Simulation","heading":"Basic","text":"Generate plot data randomly sampled common distributions (video)\nuniform\nbinomial\nnormal\npoisson\nuniformbinomialnormalpoissonGenerate related variables multivariate distribution (video)Define following statistical terms:\np-value\nalpha\npower\nsmallest effect size interest (SESOI)\nfalse positive (type error)\nfalse negative (type II error)\nconfidence interval (CI)\np-valuealphapowersmallest effect size interest (SESOI)false positive (type error)false negative (type II error)confidence interval (CI)Test sampled distributions null hypothesis (video)\nexact binomial test\nt-test (1-sample, independent samples, paired samples)\ncorrelation (pearson, kendall spearman)\nexact binomial testt-test (1-sample, independent samples, paired samples)correlation (pearson, kendall spearman)Calculate power using iteration sampling function","code":""},{"path":"sim.html","id":"intermediate-4","chapter":"9 Probability & Simulation","heading":"Intermediate","text":"Calculate minimum sample size specific power level designCalculate power range study parameters","code":""},{"path":"sim.html","id":"setup-sim","chapter":"9 Probability & Simulation","heading":"9.2 Setup","text":"Open reprores-class-notes projectCreate new R Markdown file called 09-sim.RmdUpdate YAML headerReplace setup chunk one :Simulating data powerful way test understanding statistical concepts. going use simulations learn basics probability.","code":"```{r setup, include = FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n\n# packages needed for this chapter\nlibrary(tidyverse) # for data wrangling\nlibrary(faux)      # data simulation\nlibrary(plotly)    # create a 3D plot to visualise correlations\n# MASS::mvrnorm() is used without loading MASS\n\nset.seed(8675309) # makes sure random numbers are reproducible```"},{"path":"sim.html","id":"univariate-distributions","chapter":"9 Probability & Simulation","heading":"9.3 Univariate Distributions","text":"First, need understand different ways data might distributed simulate data distributions. univariate distribution distribution single variable.","code":""},{"path":"sim.html","id":"uniform","chapter":"9 Probability & Simulation","heading":"9.3.1 Uniform Distribution","text":"uniform distribution simplest distribution. numbers range equal probability sampled.Take minute think things research uniformly distributed.","code":""},{"path":"sim.html","id":"continuous-distribution","chapter":"9 Probability & Simulation","heading":"9.3.1.1 Continuous distribution","text":"runif(n, min=0, max=1)Use runif() sample continuous uniform distribution.","code":"\nu <- runif(100000, min = 0, max = 1)\n\n# plot to visualise\nggplot() + \n  geom_histogram(aes(u), binwidth = 0.05, boundary = 0,\n                 fill = \"white\", colour = \"black\")"},{"path":"sim.html","id":"discrete","chapter":"9 Probability & Simulation","heading":"9.3.1.2 Discrete","text":"sample(x, size, replace = FALSE, prob = NULL)Use sample() sample discrete distribution.can use sample() simulate events like rolling dice choosing deck cards. code simulates rolling 6-sided die 10000 times. set replace TRUE event independent. See happens set replace FALSE.\nFigure 9.1: Distribution dice rolls.\ncan also use sample sample list named outcomes.Ferrets much less common pet cats dogs, sample realistic. can set probabilities item list prob argument.","code":"\nrolls <- sample(1:6, 10000, replace = TRUE)\n\n# plot the results\nggplot() + \n  geom_histogram(aes(rolls), binwidth = 1, \n                 fill = \"white\", color = \"black\")\npet_types <- c(\"cat\", \"dog\", \"ferret\", \"bird\", \"fish\")\nsample(pet_types, 10, replace = TRUE)##  [1] \"cat\"    \"cat\"    \"cat\"    \"cat\"    \"ferret\" \"dog\"    \"bird\"   \"cat\"   \n##  [9] \"dog\"    \"fish\"\npet_types <- c(\"cat\", \"dog\", \"ferret\", \"bird\", \"fish\")\npet_prob <- c(0.3, 0.4, 0.1, 0.1, 0.1)\nsample(pet_types, 10, replace = TRUE, prob = pet_prob)##  [1] \"fish\" \"dog\"  \"cat\"  \"dog\"  \"cat\"  \"dog\"  \"fish\" \"dog\"  \"cat\"  \"fish\""},{"path":"sim.html","id":"binomial","chapter":"9 Probability & Simulation","heading":"9.3.2 Binomial Distribution","text":"binomial distribution useful modelling binary data, observation can one two outcomes, like success/failure, yes/head/tails.rbinom(n, size, prob)rbinom function generate random binomial distribution.n = number observationssize = number trialsprob = probability success trialCoin flips typical example binomial distribution, can assign heads 1 tails 0.can generate total number heads 1 set 20 coin flips setting size 20 n 1.can generate sets 20 coin flips increasing n.always check randomly generated data check makes sense. large samples, easiest graphically. histogram usually best choice plotting binomial data.Run simulation several times, noting histogram changes. Try changing values n, size, prob.","code":"\n# 20 individual coin flips of a fair coin\nrbinom(20, 1, 0.5)##  [1] 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 0 0\n# 20 individual coin flips of a baised (0.75) coin\nrbinom(20, 1, 0.75)##  [1] 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1\nrbinom(1, 20, 0.75)## [1] 13\nrbinom(10, 20, 0.5)##  [1] 10 14 11  7 11 13  6 10  9  9\nflips <- rbinom(1000, 20, 0.5)\n\nggplot() +\n  geom_histogram(\n    aes(flips), \n    binwidth = 1, \n    fill = \"white\", \n    color = \"black\"\n  )"},{"path":"sim.html","id":"normal","chapter":"9 Probability & Simulation","heading":"9.3.3 Normal Distribution","text":"rnorm(n, mean, sd)can simulate normal distribution size n know mean standard deviation (sd). density plot usually best way visualise type data n large.Run simulation several times, noting density plot changes. vertical lines represent? Try changing values n, mean, sd.","code":"\ndv <- rnorm(1e5, 10, 2)\n\n# proportions of normally-distributed data \n# within 1, 2, or 3 SD of the mean\nsd1 <- .6827 \nsd2 <- .9545\nsd3 <- .9973\n\nggplot() +\n  geom_density(aes(dv), fill = \"white\") +\n  geom_vline(xintercept = mean(dv), color = \"red\") +\n  geom_vline(xintercept = quantile(dv, .5 - sd1/2), color = \"darkgreen\") +\n  geom_vline(xintercept = quantile(dv, .5 + sd1/2), color = \"darkgreen\") +\n  geom_vline(xintercept = quantile(dv, .5 - sd2/2), color = \"blue\") +\n  geom_vline(xintercept = quantile(dv, .5 + sd2/2), color = \"blue\") +\n  geom_vline(xintercept = quantile(dv, .5 - sd3/2), color = \"purple\") +\n  geom_vline(xintercept = quantile(dv, .5 + sd3/2), color = \"purple\") +\n  scale_x_continuous(\n    limits = c(0,20), \n    breaks = seq(0,20)\n  )"},{"path":"sim.html","id":"poisson","chapter":"9 Probability & Simulation","heading":"9.3.4 Poisson Distribution","text":"Poisson distribution useful modelling events, like many times something happens unit time, long events independent (e.g., event happened one time period make less likely happen next).rpois(n, lambda)rpois function generate random Poisson distribution.n = number observationslambda = mean number events per observationLet's say want model many texts get day whole. know get average 20 texts per day. set n = 365 lambda = 20. Lambda parameter describes Poisson distribution, just like mean standard deviation parameters describe normal distribution.can see year, unlikely get fewer 5 texts day, 35 (although impossible).","code":"\ntexts <- rpois(n = 365, lambda = 20)\n\nggplot() +\n  geom_histogram(\n    aes(texts), \n    binwidth = 1, \n    fill = \"white\", \n    color = \"black\"\n  )"},{"path":"sim.html","id":"mvdist","chapter":"9 Probability & Simulation","heading":"9.4 Multivariate Distributions","text":"","code":""},{"path":"sim.html","id":"bvn","chapter":"9 Probability & Simulation","heading":"9.4.1 Bivariate Normal","text":"bivariate normal distribution two normally distributed vectors specified relationship, correlation .want sample population specific relationships variables? can sample bivariate normal distribution using mvrnorm() MASS package.load MASS library() function create conflict select() function dplyr always need preface dplyr::. Just use MASS::mvrnorm().need know many observations want simulate (n) means two variables (mu) need calculate covariance matrix (sigma) correlation variables (rho) standard deviations (sd).Plot sampled variables check everything worked like expect. easiest convert output mvnorm tibble order use ggplot.","code":"\nn   <- 1000 # number of random samples\n# name the mu values to give the resulting columns names\nmu     <- c(x = 10, y = 20) # the means of the samples\nsd <- c(5, 6)   # the SDs of the samples\n\nrho <- 0.5  # population correlation between the two variables\n\n# correlation matrix\ncor_mat <- matrix(c(  1, rho, \n                    rho,   1), 2) \n\n# create the covariance matrix\nsigma <- (sd %*% t(sd)) * cor_mat\n\n# sample from bivariate normal distribution\nbvn <- MASS::mvrnorm(n, mu, sigma) \nbvn |>\n  as_tibble() |>\n  ggplot(aes(x, y)) +\n    geom_point(alpha = 0.5) + \n    geom_smooth(method = \"lm\") +\n    geom_density2d()## `geom_smooth()` using formula 'y ~ x'"},{"path":"sim.html","id":"mvnorm","chapter":"9 Probability & Simulation","heading":"9.4.2 Multivariate Normal","text":"can generate 2 correlated variables, gets little trickier create correlation matrix.can use plotly library make 3D graph.","code":"\nn      <- 200 # number of random samples\nmu     <- c(x = 10, y = 20, z = 30) # the means of the samples\nsd <- c(8, 9, 10)   # the SDs of the samples\n\nrho1_2 <- 0.5 # correlation between x and y\nrho1_3 <- 0   # correlation between x and z\nrho2_3 <- 0.7 # correlation between y and z\n\n# correlation matrix\ncor_mat <- matrix(c(     1, rho1_2, rho1_3, \n                    rho1_2,      1, rho2_3,\n                    rho1_3, rho2_3,      1), 3) \n\nsigma <- (sd %*% t(sd)) * cor_mat\nbvn3 <- MASS::mvrnorm(n, mu, sigma)\n\ncor(bvn3) # check correlation matrix##           x         y         z\n## x 1.0000000 0.5896674 0.1513108\n## y 0.5896674 1.0000000 0.7468737\n## z 0.1513108 0.7468737 1.0000000\n#set up the marker style\nmarker_style = list(\n    color = \"#ff0000\", \n    line = list(\n      color = \"#444\", \n      width = 1\n    ), \n    opacity = 0.5,\n    size = 5\n  )\n\n# convert bvn3 to a tibble, plot and add markers\nbvn3 |>\n  as_tibble() |>\n  plot_ly(x = ~x, y = ~y, z = ~z, marker = marker_style) |>\n  add_markers()"},{"path":"sim.html","id":"faux","chapter":"9 Probability & Simulation","heading":"9.4.3 Faux","text":"Alternatively, can use package faux generate number correlated variables. also function checking parameters new simulated data (check_sim_stats()).can also use faux simulate data factorial designs. Set -subject within-subject factors lists levels (named) vectors. Means standard deviations can included vectors data frames. function calculates sigma , structures dataset, outputs plot design.can use check_sim_stats() function, need set argument vector -subject factor columns.See faux website detailed tutorials.","code":"\nbvn3 <- rnorm_multi(\n  n = n, \n  vars = 3,\n  mu = mu, \n  sd = sd,\n  r = c(rho1_2, rho1_3, rho2_3),\n  varnames = c(\"x\", \"y\", \"z\")\n)\n\ncheck_sim_stats(bvn3)\nb <- list(pet = c(cat = \"Cat Owners\",\n                  dog = \"Dog Owners\"))\nw <- list(time = c(\"morning\",\n                   \"noon\",\n                   \"night\"))\nmu <- data.frame(\n  cat    = c(10, 12, 14),\n  dog    = c(10, 15, 20),\n  row.names = w$time\n)\nsd <- c(3, 3, 3, 5, 5, 5)\n\npet_data <- sim_design(\n  within = w, \n  between = b,\n  n = 100, \n  mu = mu,\n  sd = sd, \n  r = .5)\ncheck_sim_stats(pet_data, between = \"pet\")"},{"path":"sim.html","id":"stat-terms","chapter":"9 Probability & Simulation","heading":"9.5 Statistical terms","text":"review important statistical terms review tests distributions.","code":""},{"path":"sim.html","id":"effect","chapter":"9 Probability & Simulation","heading":"9.5.1 Effect","text":"effect measure data. depend type data type statistical test using. example, flipped coin 100 times landed heads 66 times, effect 66/100. can use exact binomial test compare effect null effect expect fair coin (50/100) effect choose. effect size refers difference effect data null effect (usually chance value).","code":""},{"path":"sim.html","id":"p-value","chapter":"9 Probability & Simulation","heading":"9.5.2 P-value","text":"p-value test probability seeing effect least extreme , real effect value testing (e.g., null effect). used binomial test test chance probability 1/6 (e.g., probability rolling 1 6-sided die), p-value 0.17 means expect see effects least extreme data 17% time just chance alone.","code":""},{"path":"sim.html","id":"alpha","chapter":"9 Probability & Simulation","heading":"9.5.3 Alpha","text":"using null hypothesis significance testing (NHST), need decide cutoff value (alpha) making decision reject null hypothesis. call p-values alpha cutoff significant. psychology, alpha traditionally set 0.05, good arguments setting different criterion circumstances.","code":""},{"path":"sim.html","id":"false-pos","chapter":"9 Probability & Simulation","heading":"9.5.4 False Positive/Negative","text":"probability test concludes effect really effect (e.g., concludes fair coin biased) called false positive rate (Type Error Rate). alpha false positive rate accept test. probability test concludes effect really one (e.g., concludes biased coin fair) called false negative rate (Type II Error Rate). beta false negative rate accept test.false positive rate overall probability getting false positive, probability false positive null hypothesis. Similarly, false negative rate probability false negative alternative hypothesis. Unless know probability testing null effect, say anything overall probability false positives negatives. 100% hypotheses test false, significant effects false positives, hypotheses test true, positives true positives overall false positive rate 0.","code":""},{"path":"sim.html","id":"power","chapter":"9 Probability & Simulation","heading":"9.5.5 Power and SESOI","text":"Power equal 1 minus beta (.e., true positive rate), depends effect size, many samples take (n), set alpha . test, specify one values, can calculate last. effect size use power calculations smallest effect size interest (SESOI). See Daniël Lakens et al. (2018) tutorial methods choosing SESOI.say want able detect least 15% difference chance (50%) coin's fairness, want test 5% chance false positives 10% chance false negatives. following values?alpha = beta = false positive rate = false negative rate = power = SESOI = ","code":""},{"path":"sim.html","id":"conf-int","chapter":"9 Probability & Simulation","heading":"9.5.6 Confidence Intervals","text":"confidence interval range around value (mean) probability containing parameter, repeated process many times. Traditionally psychology, use 95% confidence intervals, can calculate CIs percentage.95% CI mean 95% probability true mean lies within range, , repeated study many times calculated CI way every time, expect true mean inside CI 95% studies. seems like subtle distinction, can lead misunderstandings. See Morey et al. (2016) detailed discussion.","code":""},{"path":"sim.html","id":"tests","chapter":"9 Probability & Simulation","heading":"9.6 Tests","text":"","code":""},{"path":"sim.html","id":"exact-binom","chapter":"9 Probability & Simulation","heading":"9.6.1 Exact binomial test","text":"binom.test(x, n, p)can test binomial distribution specific probability using exact binomial test.x = number successesn = number trialsp = hypothesised probability successHere can test series 10 coin flips fair coin biased coin hypothesised probability 0.5 (even odds).Run code several times, noting p-values fair biased coins. Alternatively, can simulate coin flips online build graph results p-values.p-value vary fair biased coins?happens confidence intervals increase n 10 100?criterion use tell observed data indicate coin fair biased?often conclude fair coin biased (false positives)?often conclude biased coin fair (false negatives)?","code":"\nn <- 10\nfair_coin <- rbinom(1, n, 0.5)\nbiased_coin <- rbinom(1, n, 0.6)\n\nbinom.test(fair_coin, n, p = 0.5)\nbinom.test(biased_coin, n, p = 0.5)## \n##  Exact binomial test\n## \n## data:  fair_coin and n\n## number of successes = 6, number of trials = 10, p-value = 0.7539\n## alternative hypothesis: true probability of success is not equal to 0.5\n## 95 percent confidence interval:\n##  0.2623781 0.8784477\n## sample estimates:\n## probability of success \n##                    0.6 \n## \n## \n##  Exact binomial test\n## \n## data:  biased_coin and n\n## number of successes = 8, number of trials = 10, p-value = 0.1094\n## alternative hypothesis: true probability of success is not equal to 0.5\n## 95 percent confidence interval:\n##  0.4439045 0.9747893\n## sample estimates:\n## probability of success \n##                    0.8"},{"path":"sim.html","id":"sampling-binom","chapter":"9 Probability & Simulation","heading":"9.6.1.1 Sampling function","text":"estimate rates, need repeat sampling many times. function ideal repeating exact procedure . Set arguments function variables might want change. , want estimate power :different sample sizes (n)different effects (bias)different hypothesised probabilities (p, defaults 0.5)created function, test times, changing values.","code":"\nsim_binom_test <- function(n, bias, p = 0.5) {\n  # simulate 1 coin flip n times with the specified bias\n  coin <- rbinom(1, n, bias)\n  # run a binomial test on the simulated data for the specified p\n  btest <- binom.test(coin, n, p)\n  # return the p-value of this test\n  btest$p.value\n}\nsim_binom_test(100, 0.6)## [1] 0.1332106"},{"path":"sim.html","id":"calc-power-binom","chapter":"9 Probability & Simulation","heading":"9.6.1.2 Calculate power","text":"can use replicate() function run many times save output values. can calculate power analysis checking proportion simulated analyses p-value less alpha (probability rejecting null hypothesis null hypothesis true).1e4 just scientific notation 1 followed 4 zeros (10000). running simulations, usually want run lot . pain keep track whether typed 5 6 zeros (100000 vs 1000000) change running time order magnitude.can plot distribution p-values.","code":"\nmy_reps <- replicate(1e4, sim_binom_test(100, 0.6))\n\nalpha <- 0.05 # this does not always have to be 0.05\n\nmean(my_reps < alpha)## [1] 0.4561\nggplot() + \n  geom_histogram(\n    aes(my_reps), \n    binwidth = 0.05, \n    boundary = 0,\n    fill = \"white\", \n    color = \"black\"\n  )"},{"path":"sim.html","id":"t-test","chapter":"9 Probability & Simulation","heading":"9.6.2 T-test","text":"t.test(x, y, alternative, mu, paired)Use t-test compare mean one distribution null hypothesis (one-sample t-test), compare means two samples (independent-samples t-test), compare pairs values (paired-samples t-test).can run one-sample t-test comparing mean data mu. simulated distribution mean 0.5 SD 1, creating effect size 0.5 SD tested mu 0. Run simulation times see often t-test returns significant p-value (run shiny app).Run independent-samples t-test comparing two lists values.paired argument defaults FALSE, good practice always explicitly set never confused type test performing.","code":"\nsim_norm <- rnorm(100, 0.5, 1)\nt.test(sim_norm, mu = 0)## \n##  One Sample t-test\n## \n## data:  sim_norm\n## t = 6.2874, df = 99, p-value = 8.758e-09\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  0.4049912 0.7784761\n## sample estimates:\n## mean of x \n## 0.5917337\na <- rnorm(100, 0.5, 1)\nb <- rnorm(100, 0.7, 1)\nt_ind <- t.test(a, b, paired = FALSE)\nt_ind## \n##  Welch Two Sample t-test\n## \n## data:  a and b\n## t = -1.8061, df = 197.94, p-value = 0.07243\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -0.54825320  0.02408469\n## sample estimates:\n## mean of x mean of y \n## 0.4585985 0.7206828"},{"path":"sim.html","id":"sampling-t","chapter":"9 Probability & Simulation","heading":"9.6.2.1 Sampling function","text":"can use names() function find names t.test parameters use just get one type data, like test statistic (e.g., t-value).want run simulation many times record information time, first need turn simulation function.Run times check gives sensible values.","code":"\nnames(t_ind)\nt_ind$statistic##  [1] \"statistic\"   \"parameter\"   \"p.value\"     \"conf.int\"    \"estimate\"   \n##  [6] \"null.value\"  \"stderr\"      \"alternative\" \"method\"      \"data.name\"  \n##         t \n## -1.806051\nsim_t_ind <- function(n, m1, sd1, m2, sd2) {\n  # simulate v1\n  v1 <- rnorm(n, m1, sd1)\n  \n  #simulate v2\n  v2 <- rnorm(n, m2, sd2)\n    \n  # compare using an independent samples t-test\n  t_ind <- t.test(v1, v2, paired = FALSE)\n  \n  # return the p-value\n  return(t_ind$p.value)\n}\nsim_t_ind(100, 0.7, 1, 0.5, 1)## [1] 0.362521"},{"path":"sim.html","id":"calc-power-t","chapter":"9 Probability & Simulation","heading":"9.6.2.2 Calculate power","text":"Now replicate simulation 1000 times.Run code several times. much power value fluctuate? many replications need run get reliable estimate power?Compare power estimate simluation power calculation using power.t.test(). , delta difference m1 m2 .can plot distribution p-values.think distribution p-values \neffect (.e., means identical)? Check .Make sure boundary argument set 0 p-value histograms. See happens null effect boundary set.","code":"\nmy_reps <- replicate(1e4, sim_t_ind(100, 0.7, 1, 0.5, 1))\n\nalpha <- 0.05\npower <- mean(my_reps < alpha)\npower## [1] 0.2925\npower.t.test(n = 100, \n             delta = 0.2, \n             sd = 1, \n             sig.level = alpha, \n             type = \"two.sample\")## \n##      Two-sample t test power calculation \n## \n##               n = 100\n##           delta = 0.2\n##              sd = 1\n##       sig.level = 0.05\n##           power = 0.2902664\n##     alternative = two.sided\n## \n## NOTE: n is number in *each* group\nggplot() + \n  geom_histogram(\n    aes(my_reps), \n    binwidth = 0.05, \n    boundary = 0,\n    fill = \"white\", \n    color = \"black\"\n  )"},{"path":"sim.html","id":"correlation","chapter":"9 Probability & Simulation","heading":"9.6.3 Correlation","text":"can test continuous variables related using cor() function. use rnorm_multi() make quick table correlated values.Set n large number like 1e6 correlations less affected chance. Change value mean , x, y. change correlation x y? happens increase decrease sd? Can work rules ?cor() defaults Pearson's correlations. Set method argument use Kendall Spearman correlations.","code":"\ndat <- rnorm_multi(\n  n = 100, \n  vars = 2, \n  r = -0.5,\n  varnames = c(\"x\", \"y\")\n)\n\ncor(dat$x, dat$y)## [1] -0.4960331\ncor(dat$x, dat$y, method = \"spearman\")## [1] -0.4724992"},{"path":"sim.html","id":"sampling-cor","chapter":"9 Probability & Simulation","heading":"9.6.3.1 Sampling function","text":"Create function creates two variables n observations r correlation. Use function cor.test() give p-values correlation.created function, test times, changing values.","code":"\nsim_cor_test <- function(n = 100, r = 0) {\n  dat <- rnorm_multi(\n    n = n, \n    vars = 2, \n    r = r,\n    varnames = c(\"x\", \"y\")\n  )\n\n  ctest <- cor.test(dat$x, dat$y)\n  ctest$p.value\n}\nsim_cor_test(50, .5)## [1] 0.001354836"},{"path":"sim.html","id":"calc-power-cor","chapter":"9 Probability & Simulation","heading":"9.6.3.2 Calculate power","text":"Now replicate simulation 1000 times.Compare value calcuated pwr package.","code":"\nmy_reps <- replicate(1e4, sim_cor_test(50, 0.5))\n\nalpha <- 0.05\npower <- mean(my_reps < alpha)\npower## [1] 0.965\npwr::pwr.r.test(n = 50, r = 0.5)## \n##      approximate correlation power calculation (arctangh transformation) \n## \n##               n = 50\n##               r = 0.5\n##       sig.level = 0.05\n##           power = 0.9669813\n##     alternative = two.sided"},{"path":"sim.html","id":"example","chapter":"9 Probability & Simulation","heading":"9.7 Example","text":"example uses Growth Chart Data Tables US CDC. data consist height centimeters z-scores –2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2 sex (1=male; 2=female) half-month age (24.0 240.5 months).","code":""},{"path":"sim.html","id":"load-wrangle","chapter":"9 Probability & Simulation","heading":"9.7.1 Load & wrangle","text":"little data wrangling first. look data import relabel Sex male female instead 1 2. Also convert Agemos (age months) years. Relabel column 0 mean calculate new column named sd difference columns 1 0.","code":"\norig_height_age <- read_csv(\"https://www.cdc.gov/growthcharts/data/zscore/zstatage.csv\") ## Rows: 872 Columns: 11\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr (2): Sex, Agemos\n## dbl (9): -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nheight_age <- orig_height_age |>\n  filter(Sex %in% c(1,2)) |>\n  mutate(\n    sex = recode(Sex, \"1\" = \"male\", \"2\" = \"female\"),\n    age = as.numeric(Agemos)/12,\n    sd = `1` - `0`\n  ) |>\n  select(sex, age, mean = `0`, sd)"},{"path":"sim.html","id":"plot","chapter":"9 Probability & Simulation","heading":"9.7.2 Plot","text":"Plot new data frame see mean height changes age boys girls.","code":"\nggplot(height_age, aes(age, mean, color = sex)) +\n  geom_smooth(aes(ymin = mean - sd, \n                  ymax = mean + sd),\n              stat=\"identity\")"},{"path":"sim.html","id":"simulate-a-population","chapter":"9 Probability & Simulation","heading":"9.7.3 Simulate a population","text":"Simulate 50 random male heights 50 random female heights 20-year-olds using rnorm() function means SDs height_age table. Plot data.Run simulation several times, noting density plot changes. Try changing age simulating.","code":"\nage_filter <- 20\nm <- filter(height_age, age == age_filter, sex == \"male\")\nf <- filter(height_age, age == age_filter, sex == \"female\")\n\nsim_height <- tibble(\n  male = rnorm(50, m$mean, m$sd),\n  female = rnorm(50, f$mean, f$sd)\n) |>\n  gather(\"sex\", \"height\", male:female)\n\nggplot(sim_height) +\n  geom_density(aes(height, fill = sex), alpha = 0.5) +\n  xlim(125, 225)"},{"path":"sim.html","id":"analyse-simulated-data","chapter":"9 Probability & Simulation","heading":"9.7.4 Analyse simulated data","text":"Use sim_t_ind(n, m1, sd1, m2, sd2) function created generate one simulation sample size 50 group using means SDs male female 14-year-olds.","code":"\nage_filter <- 14\nm <- filter(height_age, age == age_filter, sex == \"male\")\nf <- filter(height_age, age == age_filter, sex == \"female\")\n\nsim_t_ind(50, m$mean, m$sd, f$mean, f$sd)## [1] 0.0005255744"},{"path":"sim.html","id":"replicate-simulation","chapter":"9 Probability & Simulation","heading":"9.7.5 Replicate simulation","text":"Now replicate 1e4 times using replicate() function. function save returned p-values list (my_reps). can check proportion p-values less alpha value. power test.","code":"\nmy_reps <- replicate(1e4, sim_t_ind(50, m$mean, m$sd, f$mean, f$sd))\n\nalpha <- 0.05\npower <- mean(my_reps < alpha)\npower## [1] 0.6403"},{"path":"sim.html","id":"one-tailed-prediction","chapter":"9 Probability & Simulation","heading":"9.7.6 One-tailed prediction","text":"design 65% power detect sex difference height (2-tailed test). Modify sim_t_ind function 1-tailed prediction.just set alternative equal \"greater\" function, might better add alt argument function (giving default value t.test) change value alternative function alt.","code":"\nsim_t_ind <- function(n, m1, sd1, m2, sd2, alt = \"two.sided\") {\n  v1 <- rnorm(n, m1, sd1)\n  v2 <- rnorm(n, m2, sd2)\n  t_ind <- t.test(v1, v2, paired = FALSE, alternative = alt)\n  \n  return(t_ind$p.value)\n}\n\nalpha <- 0.05\nmy_reps <- replicate(1e4, sim_t_ind(50, m$mean, m$sd, f$mean, f$sd, \"greater\"))\nmean(my_reps < alpha)## [1] 0.752"},{"path":"sim.html","id":"range-of-sample-sizes","chapter":"9 Probability & Simulation","heading":"9.7.7 Range of sample sizes","text":"want find sample size give us 80% power? can try trial error. know number slightly larger 50. can search systematically repeating power calculation range sample sizes.might seem like overkill t-test, can easily look sample size calculators online, valuable skill learn analyses become complicated.Start relatively low number replications /spread-samples estimate looking specifically. can repeat narrower/denser range sample sizes iterations.Now can narrow search values around 55 (plus minus 5) increase number replications 1e3 1e4.","code":"\n# make another custom function to return power\npwr_func <- function(n, reps = 100, alpha = 0.05) {\n  ps <- replicate(reps, sim_t_ind(n, m$mean, m$sd, f$mean, f$sd, \"greater\"))\n  mean(ps < alpha)\n}\n\n# make a table of the n values you want to check\npower_table <- tibble(\n  n = seq(20, 100, by = 5)\n) |>\n  # run the power function for each n\n  mutate(power = map_dbl(n, pwr_func))\n\n# plot the results\nggplot(power_table, aes(n, power)) +\n  geom_smooth() +\n  geom_point() +\n  geom_hline(yintercept = 0.8)## `geom_smooth()` using method = 'loess' and formula 'y ~ x'\npower_table <- tibble(\n  n = seq(50, 60)\n) |>\n  mutate(power = map_dbl(n, pwr_func, reps = 1e4))\n\nggplot(power_table, aes(n, power)) +\n geom_smooth() +\n geom_point() +\n geom_hline(yintercept = 0.8)## `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"sim.html","id":"glossary-sim","chapter":"9 Probability & Simulation","heading":"9.8 Glossary","text":"","code":""},{"path":"sim.html","id":"resources8","chapter":"9 Probability & Simulation","heading":"9.9 Further Resources","text":"Distribution Shiny App (run reprores::app(\"simulate\")Simulation tutorials Lisa DeBruineChapter 21: Iteration R Data ScienceImproving statistical inferences Coursera (week 1)Faux package data simulationSimulation-Based Power-Analysis Factorial ANOVA Designs (Daniel Lakens & Caldwell, 2019)Understanding mixed effects models data simulation (DeBruine & Barr, 2019)","code":""},{"path":"custom.html","id":"custom","chapter":"10 Customising Visualisations & Reports","heading":"10 Customising Visualisations & Reports","text":"","code":""},{"path":"custom.html","id":"ilo-custom","chapter":"10 Customising Visualisations & Reports","heading":"10.1 Learning Objectives","text":"Create customise advanced types plotsStructure data report, presentation, dashboard formatsInclude linked figures, tables, references","code":""},{"path":"custom.html","id":"custom-viz","chapter":"10 Customising Visualisations & Reports","heading":"10.2 Visualisation","text":"","code":""},{"path":"custom.html","id":"setup-custom-viz","chapter":"10 Customising Visualisations & Reports","heading":"10.2.1 Set-up","text":"Open reprores-class-notes projectCreate new R Markdown file called 10-viz.RmdUpdate YAML headerReplace setup chunk one belowCheck packages installedDownload ggplot2 cheat sheet.","code":"```{r setup, include = FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n\n# packages needed for this chapter section\nlibrary(tidyverse)   # for data wrangling\nlibrary(ggthemes)    # for themes\nlibrary(patchwork)   # for combining plots\nlibrary(plotly)      # for interactive plots\n# devtools::install_github(\"hrbrmstr/waffle\")\nlibrary(waffle)      # for waffle plots\nlibrary(ggbump)      # for bump plots\nlibrary(treemap)     # for treemap plots\nlibrary(ggwordcloud) # for word clouds\nlibrary(tidytext)    # for manipulating text for word clouds\nlibrary(gganimate)   # for animated plots\n\n#install.packages(\"rnaturalearthhires\", repos = \"http://packages.ropensci.org\", type = \"source\")\nlibrary(sf)          # for mapping geoms\nlibrary(rnaturalearth) # for map data\nlibrary(rnaturalearthdata) # extra mapping data\n\ntheme_set(theme_light())```"},{"path":"custom.html","id":"defaults-1","chapter":"10 Customising Visualisations & Reports","heading":"10.2.2 Defaults","text":"code creates two plots using default (light) theme palettes. First, load data set issue_category factor can control order categories.Next, create bar plot number calls issue category.create scatterplot wait time call time, distinguished issue category.Finally, combine two plots using + patchwork see default styles plots.\nFigure 10.1: Default plot styles.\nTry changing theme using built-themes customising colours linetypes scale_* functions. See Appendix G details.","code":"\n# update column specification\nct <- cols(issue_category = col_factor(\n        levels = c(\"tech\", \"returns\", \"sales\", \"other\")\n      ))\n\n# load data\nsurvey_data <- read_csv(file = \"data/survey_data.csv\",\n                        col_types = ct)\n# create bar plot\nbar <- ggplot(data = survey_data, \n              mapping = aes(x = issue_category,\n                            fill = issue_category)) +\n  geom_bar(show.legend = FALSE) +\n  labs(x = \"Issue Category\", \n       y = \"Count\",\n       title = \"Calls by Issue Category\")\n#create scatterplot\npoint <- ggplot(data = survey_data, \n                mapping = aes(x = wait_time, \n                              y = call_time,\n                              color = issue_category)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = lm, formula = y~x) +\n  labs(x = \"Wait Time\",\n       y = \"Call Time\",\n       color = \"Issue Category\",\n       title = \"Wait Time by Call Time\")\nbar + point"},{"path":"custom.html","id":"annotations","chapter":"10 Customising Visualisations & Reports","heading":"10.2.3 Annotations","text":"often useful add annotations plot, example, highlight important part plot add labels. annotate() function creates specific geom x- y-coordinates specify.","code":""},{"path":"custom.html","id":"text-annotations","chapter":"10 Customising Visualisations & Reports","heading":"10.2.3.1 Text annotations","text":"Add text annotation setting geom argument \"text\" \"label\" adding label. Labels padding background, text just text.Backslash-n \\n label text controls line breaks . Try removing changing position see happens.x y control coordinates label. likely play around values get right.argument hjust horizontal justification text, vjust vertical justification. default values 0.5, text centred x y coordinates. 0 justify left bottom, 1 justifies right top.can change angle text, labels.\nFigure 10.2: example annotation text label.\nSee can work make figure , starting following:Hint: need add 1 label annotation 8 separate text annotations.","code":"\nbar +\n  # add left-justified text to the second bar\n  annotate(geom = \"text\",\n           label = \"Our goal is to\\nreduce this\\ncategory\",\n           x = 1.65, y = 150,\n           hjust = 0, vjust = 1, \n           color = \"white\", fontface = \"bold\",\n           angle = 45) +\n  # add a centred label to the third bar\n  annotate(geom = \"label\",\n           label = \"Our goal is\\nto increase this\\ncategory\",\n           x = 3, y = 75,\n           hjust = 0.5, vjust = 1, \n           color = \" darkturquoise\", fontface = \"bold\")\ntibble(x = c(0, 0, 1, 1),\n       y = c(0, 1, 0, 1)) |>\n  ggplot(aes(x, y)) +\n  geom_point(alpha = 0.25, size = 4, color = \"red\")\ntibble(x = c(0, 0, 1, 1),\n       y = c(0, 1, 0, 1)) |>\n  ggplot(aes(x, y)) +\n  geom_point(alpha = 0.25, size = 4, color = \"red\") +\n  annotate(\"label\", label = \"In the\\nmiddle\",\n           x = 0.5, y = 0.5,\n           fill = \"dodgerblue\", color = \"white\",\n           label.padding = unit(1, \"lines\"),\n           label.r = unit(1.5, \"lines\")) +\n  annotate(\"text\", label = \"Bottom\\nLeft\",\n           x = 0, y = 0, hjust = 0, vjust = 0) +\n  annotate(\"text\", label = \"Top\\nLeft\", \n           x = 0, y = 1, hjust = 0, vjust = 1) +\n  annotate(\"text\", label = \"Bottom\\nRight\",\n           x = 1, y = 0, hjust = 1, vjust = 0) +\n  annotate(\"text\", label = \"Top\\nRight\",\n           x = 1, y = 1, hjust = 1, vjust = 1) +\n  annotate(\"text\", label = \"45 degrees\",\n           x = 0, y = 0.5, hjust = 0, angle = 45) +\n  annotate(\"text\", label = \"90 degrees\",\n           x = 0.25, y = 0.5, angle = 90) +\n  annotate(\"text\", label = \"270 degrees\",\n           x = 0.75, y = 0.5, angle = 270)+\n  annotate(\"text\", label = \"-45 degrees\",\n           x = 1, y = 0.5, hjust = 1, angle = -45)"},{"path":"custom.html","id":"other-annotations","chapter":"10 Customising Visualisations & Reports","heading":"10.2.3.2 Other annotations","text":"can add geoms highlight parts plot. example adds rectangle around group points, text label, straight arrow label rectangle, curved arrow label individual point.\nFigure 10.3: Example annotatins rect, text, segment, curve geoms.\nSee ggforce package sophisticated options, highlighting group points ellipse.","code":"\npoint +\n  # add a rectangle surrounding long call times\n  annotate(geom = \"rect\",\n           xmin = 100, xmax = 275,\n           ymin = 140, ymax = 180,\n           fill = \"transparent\", color = \"red\") +\n  # add a text label\n  annotate(\"text\",\n           x = 260, y = 120,\n           label = \"outliers\") +\n  # add an line with an arrow from the text to the box\n  annotate(geom = \"segment\", \n           x = 240, y = 120, \n           xend = 200, yend = 135,\n           arrow = arrow(length = unit(0.5, \"lines\"))) +\n  # add a curved line with an arrow \n  # from the text to a wait time outlier\n  annotate(geom = \"curve\", \n          x = 280, y = 120, \n          xend = 320, yend = 45,\n          curvature = -0.5,\n          arrow = arrow(length = unit(0.5, \"lines\")))"},{"path":"custom.html","id":"other-plots","chapter":"10 Customising Visualisations & Reports","heading":"10.2.4 Other Plots","text":"","code":""},{"path":"custom.html","id":"interactive-plots","chapter":"10 Customising Visualisations & Reports","heading":"10.2.4.1 Interactive Plots","text":"plotly package can used make interactive graphs. Assign ggplot variable use function ggplotly() plot object. Note interactive plots work HTML files, PDFs Word files.\nFigure 10.4: Interactive graph using plotly\nHover data points click legend items.","code":"\nggplotly(point)"},{"path":"custom.html","id":"waffle-plots","chapter":"10 Customising Visualisations & Reports","heading":"10.2.4.2 Waffle Plots","text":"Chapter 3, mentioned pie charts poor way visualise proportions refused even show make one. Waffle plots delicious alternative.Use waffle hrbrmstr GitHub using install_github() function , rather one CRAN get using install.packages().default, geom_waffle() represents observation tile splits across 10 rows. can play n_rows argument determine works best data.\nFigure 10.5: Waffle plot.\nwaffle plot can also used display counts proportions achieve , set n_rows = 10 make_proportional = TRUE. Now, rather tile representing one observation, tile represents 1% data.\nFigure 10.6: Proportional waffle plot.\n","code":"\ndevtools::install_github(\"hrbrmstr/waffle\")\nsurvey_data |> \n  count(issue_category) |>\n  ggplot(aes(fill = issue_category, values = n)) +\n  geom_waffle(\n    n_rows = 23, # try setting this to 10 (the default)\n    size = 0.33, # line size\n    make_proportional = FALSE, # use raw values\n    colour = \"white\", # line colour\n    flip = FALSE, # bottom-top or left-right\n    radius = grid::unit(0.1, \"npc\") # set to 0.5 for circles\n  ) +\n  theme_enhance_waffle() + # gets rid of axes\n  scale_fill_colorblind(name = \"Issue Category\")\nsurvey_data |> \n  count(issue_category) |>\n  ggplot(aes(fill = issue_category, values = n)) +\n  geom_waffle(\n    n_rows = 10, \n    size = 0.33, \n    make_proportional = TRUE, # compute proportions\n    colour = \"white\", \n    flip = FALSE, \n    radius = grid::unit(0.1, \"npc\") \n  ) +\n  theme_enhance_waffle() + \n  scale_fill_colorblind(name = \"Issue Category\")"},{"path":"custom.html","id":"treemap","chapter":"10 Customising Visualisations & Reports","heading":"10.2.4.3 Treemap","text":"Treemap plots another way visualise proportions. Like waffle plots, need count data category first. can use brewer palette fill.\nFigure 10.7: Treemap plot.\ncan also represent multiple categories treemaps\nFigure 10.8: Treemap two variables\n","code":"\nsurvey_data |> \n  count(issue_category) |>\n  treemap(\n    index = \"issue_category\", # column with number of rectangles\n    vSize = \"n\", # column with size of rectangle\n    title = \"\",\n    palette = \"BuPu\",\n    inflate.labels = TRUE # expand labels to size of rectangle\n  )\nsurvey_data |> \n  count(issue_category, employee_id) |>\n  arrange(employee_id) |>\n  treemap(\n    # use c() to specify two variables\n    index = c(\"employee_id\", \"issue_category\"), \n    vSize = \"n\", \n    title = \"\",\n    palette = \"Dark2\",\n    # set different label sizes for each type of label\n    fontsize.labels = c(30, 10), \n    # set different alignments for two label types\n    align.labels = list(c(\"left\", \"top\"), c(\"center\", \"center\")) \n  )"},{"path":"custom.html","id":"bump-plots","chapter":"10 Customising Visualisations & Reports","heading":"10.2.4.4 Bump Plots","text":"Bump plots useful visualising rankings change time. first, need get ranking data. start typical raw data table, containing identifying column person three columns scores weekNow make table long, group week, use rank() function find rank person's score week. Use n() - rank(score) + 1 reverse ranks highest score gets rank 1. also need make week variable number.typical mapping bump plot puts time variable x-axis, rank variable y-axis, sets colour identifying variable.\nFigure 10.9: Basic bump plot\ncan make attractive customising axes adding text labels. Try running line code see builds .Add label = person mapping can add text labels.Increase size lines size argument geom_bump()need labels weeks 1.5 2.5, change x-axis breaksThe expand argument two scale_ functions expands plot area can fit text labels right.makes sense first place top, reverse order y-axis scale_y_reverse() fix breaks expansion.Add text labels geom_text(), just week 3, set data =  filter(rank_data, week == 3) geom.Set x = 3.05 move text labels just right week 3, set hjust = 0 right-justify text labels (default hjust = 0.5, center 3.05).Remove legend grid lines. Increase x-axis text size.\nFigure 10.10: Bump plot added features.\n","code":"\n# make a small dataset of scores for 3 people over 3 weeks\nscore_data <- tribble(\n  ~person, ~week_1, ~week_2, ~week_3,\n  \"Abeni\",      80,     75,       90,\n  \"Beth\",       75,     85,       75,\n  \"Carmen\",     60,     70,       80\n)\n# calculate ranks\nrank_data <- score_data |>\n  pivot_longer(cols = -person,\n               names_to = \"week\",\n               values_to = \"score\") |>\n  group_by(week) |>\n  mutate(rank = n() - rank(score) + 1) |>\n  ungroup() |>\n  arrange(week, rank) |>\n  mutate(week = str_replace(week, \"week_\", \"\") |> as.integer())\n\nrank_data\nggplot(data = rank_data, \n       mapping = aes(x = week, \n                     y = rank, \n                     colour = person)) +\n  ggbump::geom_bump()\nggplot(data = rank_data, \n       mapping = aes(x = week, \n                     y = rank, \n                     colour = person,\n                     label = person)) +\n  ggbump::geom_bump(size = 10) +\n  scale_x_continuous(name = \"\",\n                     breaks = 1:3, \n                     labels = c(\"Week 1\", \"Week 2\", \"Week 3\"),\n                     expand = expansion(c(.05, .2))) +\n  scale_y_reverse(name = \"Ranking\",\n                  breaks = 1:3, \n                  expand = expansion(.2)) +\n  geom_text(data = filter(rank_data, week == 3),\n            color = \"black\", x = 3.05, hjust = 0) +\n  theme(legend.position = \"none\",\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        axis.text.x = element_text(size = 12))"},{"path":"custom.html","id":"word-clouds","chapter":"10 Customising Visualisations & Reports","heading":"10.2.4.5 Word Clouds","text":"Word clouds common way summarise text data. First, download amazon_alexa.csv data folder load object. dataset contains text reviews well 1-5 rating customers bought Alexa device Amazon.can use data look words used differ depending rating given. make text data easy work , function tidytext::unnest_tokens() splits words input column individual words new output column. unnnest_tokens() particularly helpful also things like removes punctuation transforms words lower case make easier work . Compare words alexa see map .can add another line code using pipe counts many instances word rating give us popular words.problem common words function words rather content words, makes sense words highest word frequency natural language.Helpfully, tidytext contains list common \"stop words\", .e., words want ignore, stored object named stop_words. also useful define list custom stop words based upon unique properties data (can sometimes take attempts identify appropriate dataset). dataset contains lot numbers informative, also contains \"https\" website links, get rid custom stop list.defined stop words, can use anti_join() remove word present stop word list.get top 25 words, group rating use dplyr::slice_max(), ordered column n.First, make word cloud customers gave 1-star rating:Filter retains data 1-star ratings.label comes word column data plot (.e., words).colour makes words red (also set word give word different colour n vary colour continuously frequency).size makes size word proportional n, number times word appeared.ggwordcloud::geom_text_wordcloud_area() word cloud geom.ggwordcloud::scale_size_area() controls big word cloud (usually takes trial--error).can now 5-star ratings paste plots together patchwork (word clouds play well facets).\nFigure 10.11: Word cloud.\nworth highlighting whilst word clouds common, really equivalent pie charts text data good making accurate comparisons based size. might able see popular word, can accurately determine 2nd, 3rd, 4th 5th popular word based clouds alone? also issue just text data make qualitative analysis just something said lot mean useful important. , argument outwith scope book, even recurring part Emily's life thanks qualitative wife.","code":"\n# https://www.kaggle.com/sid321axn/amazon-alexa-reviews\n# extracted from Amazon by Manu Siddhartha & Anurag Bhatt\nalexa <- rio::import(\"data/amazon_alexa.csv\")\nwords <- alexa |>\n  unnest_tokens(output = \"word\", input = \"verified_reviews\")\nwords <- alexa |>\n  unnest_tokens(output = \"word\", input = \"verified_reviews\") |>\n  count(word, rating, sort = TRUE) \ncustom_stop <- tibble(word = c(0:9, \"https\", 34))\n\nwords <- alexa |>\n  unnest_tokens(output = \"word\", input = \"verified_reviews\") |>\n  count(word, rating) |>\n  anti_join(stop_words, by = \"word\") |>\n  anti_join(custom_stop, by = \"word\") |>\n  group_by(rating) |>\n  slice_max(order_by = n, n = 25, with_ties = FALSE) |>\n  ungroup()\nrating1 <- filter(words, rating == 1) |>\n  ggplot(aes(label = word, colour = \"red\", size = n)) +\n  geom_text_wordcloud_area() +\n  scale_size_area(max_size = 10) +\n  ggtitle(\"Rating = 1\") +\n  theme_minimal(base_size = 14)\n\nrating1\nrating5 <- filter(words, rating == 5) |>\n  ggplot(aes(label = word, size = n)) +\n  geom_text_wordcloud_area(colour = \"darkolivegreen3\") +\n  scale_size_area(max_size = 12) +\n  ggtitle(\"Rating = 5\") +\n  theme_minimal(base_size = 14)\n\nrating1 + rating5"},{"path":"custom.html","id":"maps","chapter":"10 Customising Visualisations & Reports","heading":"10.2.4.6 Maps","text":"Working maps can tricky. sf package provides functions work ggplot2, geom_sf(). rnaturalearth package (associated data packages may prompted download) provide high-quality mapping coordinates.ne_countries() returns world country polygons (.e., world map). specify object returned \"simple feature\" class sf work geom_sf(). like deep dive simple feature objects, check vignette sf package.worth checking object ne_countries() returns see just much information available.Try changing values colours get sense code works.can combine multiple countries using bind_rows() visualise different colours country.\nFigure 10.12: Map coloured country.\ncan join Scottish population data map table visualise data map using colours labels.typo data rnaturalearth, need change \"North Ayshire\" \"North Ayrshire\" join population data.Setting fill population geom_sf() gives region colour based population.colours customised scale_fill_viridis_c(). breaks fill scale set increments 100K (1e5 scientific notation) scale set span 0 600K.paste0() creates labels taking numbers 0 6 adding \"00 k\" .Finally, position legend moved sea using legend.position().\nFigure 10.13: Map coloured population.\n","code":"\n# get the world map coordinates\nworld_sf <- ne_countries(returnclass = \"sf\", scale = \"medium\")\n\n# plot them on a light blue background\nggplot() + \n  geom_sf(data = world_sf, size = 0.3) +\n  theme(panel.background = element_rect(fill = \"lightskyblue2\"))\n# get and bind country data\nuk_sf <- ne_states(country = \"united kingdom\", returnclass = \"sf\")\nireland_sf <- ne_states(country = \"ireland\", returnclass = \"sf\")\nislands <- bind_rows(uk_sf, ireland_sf) |>\n  filter(!is.na(geonunit))\n\n# set colours\ncountry_colours <- c(\"Scotland\" = \"#0962BA\",\n                     \"Wales\" = \"#00AC48\",\n                     \"England\" = \"#FF0000\",\n                     \"Northern Ireland\" = \"#FFCD2C\",\n                     \"Ireland\" = \"#F77613\")\n\nggplot() + \n  geom_sf(data = islands,\n          mapping = aes(fill = geonunit),\n          colour = NA,\n          alpha = 0.75) +\n  coord_sf(crs = sf::st_crs(4326),\n           xlim = c(-10.7, 2.1), \n           ylim = c(49.7, 61)) +\n  scale_fill_manual(name = \"Country\", \n                    values = country_colours)\n# load map data\nscotland_sf <- ne_states(geounit = \"Scotland\", \n                         returnclass = \"sf\")\n\n# load population data from\n# https://www.indexmundi.com/facts/united-kingdom/quick-facts/scotland/population\nscotpop <- read_csv(\"data/scottish_population.csv\", \n                    show_col_types = FALSE)\n\n# join data and fix typo in the map\nscotmap_pop <- scotland_sf |>\n  mutate(name = ifelse(name == \"North Ayshire\", \n                       yes = \"North Ayrshire\", \n                       no = name)) |>\n  left_join(scotpop, by = \"name\") |>\n  select(name, population, geometry)\n# plot\nggplot() + \n  geom_sf(data = scotmap_pop,\n          mapping = aes(fill = population),\n          color = \"white\", \n          size = .1) +\n  coord_sf(xlim = c(-8, 0), ylim = c(54, 61)) +\n  scale_fill_viridis_c(name = \"Population\",\n                       breaks = seq(from = 0, to = 6e5, by = 1e5), \n                       limits = c(0, 6e5),\n                       labels = paste0(0:6, \"00 K\")) +\n  theme(legend.position = c(0.16, 0.84))"},{"path":"custom.html","id":"animated-plots","chapter":"10 Customising Visualisations & Reports","heading":"10.2.4.7 Animated Plots","text":"Animated plots great way add wow factor reports, can complex make, distracting, accessible, use sparingly data visualisation animation really adds something. package gganimate many functions animating ggplots., load population data United Nations. Download file data folder open Excel first see looks like. code gets data first tab, filters just 6 world regions, makes data long, makes sure year column numeric pop column shows population whole numbers (original data 1000s).make animated plot showing population region changes year. First, make static plot. Filter data recent year can see single frame animation look like.convert animated plot shows data multiple years:Remove filter add transition_time(year).Use {} syntax include frame_time title.Use anim_save() save animation GIF file set code chunk eval = FALSE creating animation takes long time want run every time knit report.can show animated gif html report (animations work Word PDF) using include_graphics(), include GIF dynamic document like PowerPoint.\nFigure 10.14: Animated gif.\nactually many plots really improved animating . plot gives information single glance.","code":"\n# load and process data\nworldpop <- readxl::read_excel(\"data/WPP2019_POP_F01_1_TOTAL_POPULATION_BOTH_SEXES.xlsx\", skip = 16) |>\n  filter(Type == \"Region\") |>\n  select(region = 3, `1950`:`1992`) |>\n  pivot_longer(cols = -region, \n               names_to = \"year\",\n               values_to = \"pop\") |>\n  mutate(year = as.integer(year),\n         pop = round(1000 * as.numeric(pop)))\nworldpop |>\n  filter(year == 1992) |>\n  ggplot(aes(x = region, y = pop, fill = region)) +\n  geom_col(show.legend = FALSE) +\n  scale_fill_viridis_d() +\n  scale_x_discrete(name = \"\", \n                   guide = guide_axis(n.dodge=2))+\n  scale_y_continuous(name = \"Population\",\n                     breaks = seq(0, 3e9, 1e9),\n                     labels = paste0(0:3, \"B\")) +\n  ggtitle('Year: 1992')\nanim <- worldpop |>\n  ggplot(aes(x = region, y = pop, fill = region)) +\n  geom_col(show.legend = FALSE) +\n  scale_fill_viridis_d() +\n  scale_x_discrete(name = \"\",\n                   guide = guide_axis(n.dodge=2))+\n  scale_y_continuous(name = \"Population\",\n                     breaks = seq(0, 3e9, 1e9),\n                     labels = paste0(0:3, \"B\")) +\n  ggtitle('Year: {frame_time}') +\n  transition_time(year)\n  \ndir.create(\"images\", FALSE) # creates an images directory if needed\n\nanim_save(filename = \"images/gganim-demo.gif\",\n          animation = anim,\n          width = 8, height = 5, units = \"in\", res = 150)\nknitr::include_graphics(\"images/gganim-demo.gif\")"},{"path":"custom.html","id":"resources-custom","chapter":"10 Customising Visualisations & Reports","heading":"10.2.5 Resources","text":"many options data visualisation R time cover . following resources get started journey informative, intuitive visualisations.R Graph Gallery (really useful)Look Data Data Vizualization Social ScienceGraphs Cookbook RTop 50 ggplot2 VisualizationsR Graphics Cookbook Winston Changggplot extensionsplotly creating interactive graphsDrawing Beautiful Maps Programmaticallygganimate","code":""},{"path":"custom.html","id":"custom-reports","chapter":"10 Customising Visualisations & Reports","heading":"10.3 Reports","text":"","code":""},{"path":"custom.html","id":"setup-custom-reports","chapter":"10 Customising Visualisations & Reports","heading":"10.3.1 Set-up","text":"Close file 10-viz.RmdCreate new R Markdown file called 10-reports.RmdUpdate YAML headerReplace setup chunk one ","code":"```{r setup, include = FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n\n# packages needed for this chapter section\nlibrary(tidyverse)     # data wrangling functions\nlibrary(bookdown)      # for chaptered reports\nlibrary(flexdashboard) # for dashboards\nlibrary(DT)            # for interactive tables```"},{"path":"custom.html","id":"linked-documents","chapter":"10 Customising Visualisations & Reports","heading":"10.3.2 Linked documents","text":"need create longer reports links sections, can edit YAML use bookdown format. bookdown::html_document2 useful one adds figure table numbers automatically figures tables caption allows link reference.create links tables figures, need name code chunk created figures tables, call names inline coding:code chunk names can contain letters, numbers dashes. contain characters like spaces underscores, referencing work.can also link different sections report naming headings {#}:code shows link text figures tables full report using built-diamonds dataset - use reports.Rmd create document now. can see HTML output .format defaults numbered sections, set number_sections: false YAML header want . remove numbered sections, links like \\@ref(conclusion) show \"??\", need use URL link syntax instead, like :","code":"```{r my-table}\n# table code here``````{r my-figure}\n# figure code here```See Table\\ \\@ref(tab:my-table) or Figure\\ \\@ref(fig:my-figure).# My first heading {#heading-1}\n\n## My second heading {#heading-2}\n\nSee Section\\ \\@ref(heading-1) and Section\\ \\@ref(heading-2)\n---\ntitle: \"Linked Document Demo\"\noutput: \n  bookdown::html_document2:\n    number_sections: true\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE,\n                      message = FALSE,\n                      warning = FALSE)\nlibrary(tidyverse)\nlibrary(kableExtra)\ntheme_set(theme_minimal())\n```\n\nDiamond price depends on many features, such as:\n\n- cut (See Table\\ \\@ref(tab:by-cut))\n- colour (See Table\\ \\@ref(tab:by-colour))\n- clarity (See Figure\\ \\@ref(fig:by-clarity))\n- carats (See Figure\\ \\@ref(fig:by-carat))\n- See section\\ \\@ref(conclusion) for concluding remarks\n\n## Tables\n\n### Cut\n\n```{r by-cut}\ndiamonds %>%\n  group_by(cut) %>%\n  summarise(avg = mean(price),\n            .groups = \"drop\") %>%\n  kable(digits = 0, \n        col.names = c(\"Cut\", \"Average Price\"),\n        caption = \"Mean diamond price by cut.\") %>%\n  kable_material()\n```\n\n### Colour\n\n```{r by-colour}\ndiamonds %>%\n  group_by(color) %>%\n  summarise(avg = mean(price),\n            .groups = \"drop\") %>%\n  kable(digits = 0, \n        col.names = c(\"Cut\", \"Average Price\"),\n        caption = \"Mean diamond price by colour.\") %>%\n  kable_material()\n```\n\n## Plots\n\n### Clarity\n\n```{r by-clarity, fig.cap = \"Diamond price by clarity\"}\nggplot(diamonds, aes(x = clarity, y = price)) +\n  geom_boxplot() \n```\n\n### Carats\n\n```{r by-carat, fig.cap = \"Diamond price by carat\"}\nggplot(diamonds, aes(x = carat, y = price)) +\n  stat_smooth()\n```\n\n### Concluding remarks {#conclusion}\n\nI am not rich enough to worry about any of this.See the [last section](#conclusion) for concluding remarks."},{"path":"custom.html","id":"interactive-tables","chapter":"10 Customising Visualisations & Reports","heading":"10.3.3 Interactive tables","text":"One way make reports exciting use interactive tables. DT::datatable() function displays table extra interactive elements allow readers search reorder data, well controlling number rows shown . can especially helpful. works HTML output types. DT website extensive tutorials, cover basics .can customise display, changing column names, adding caption, moving location filter boxes, removing row names, applying classes change table appearance, applying advanced options.Create interactive table like one diamonds dataset diamonds table value greater 65 (whole table much large display interactive table). Show 20 items default remove search box, leave filter default options.","code":"\nlibrary(DT)\n\nscotpop <- read_csv(\"data/scottish_population.csv\", \n                    show_col_types = FALSE)\n\ndatatable(data = scotpop)\n# https://datatables.net/reference/option/\nmy_options <- list(\n  pageLength = 5, # how many rows are displayed\n  lengthChange = FALSE, # whether pageLength can change\n  info = TRUE, # text with the total number of rows\n  paging = TRUE, # if FALSE, the whole table displays\n  ordering = FALSE, # whether you can reorder columns\n  searching = FALSE # whether you can search the table\n)\n\ndatatable(\n  data = scotpop,\n  colnames = c(\"County\", \"Population\"),\n  caption = \"The population of Scottish counties.\",\n  filter = \"none\", # \"none\", \"bottom\" or \"top\"\n  rownames = FALSE, # removes the number at the left\n  class = \"cell-border hover stripe\", # default is \"display\"\n  options = my_options\n)\nmy_options <- list(\n  pageLength = 20, # how many rows are displayed\n  searching = FALSE # whether you can search the table\n)\n\ndiamonds |> \n  filter(table > 65) |>\n  select(-table, -(x:z)) |>\n  DT::datatable(\n    caption = \"All diamonds with table > 65.\",\n    options = my_options\n  )"},{"path":"custom.html","id":"other-formats","chapter":"10 Customising Visualisations & Reports","heading":"10.3.4 Other formats","text":"can create just reports R Markdown. can also create presentations, interactive dashboards, books, websites, web applications.","code":""},{"path":"custom.html","id":"presentations","chapter":"10 Customising Visualisations & Reports","heading":"10.3.4.1 Presentations","text":"can choose presentation template create new R Markdown document. use ioslides example, formats work similarly.\nFigure 10.15: Ioslides RMarkdown template.\nmain differences Rmd files working now output type YAML header ioslides_presentation instead html_document format requires specific title structure. slide starts level-2 header.template provides examples text, bullet point, code, plot slides. can knit template create HTML document presentation. often looks odd RStudio built-browser, click button open web browser. can use space bar arrow keys advance slides.code shows load packages display text, table, plot. can see HTML output .","code":"---\ntitle: \"Presentation Demo\"\nauthor: \"Lisa DeBruine\"\noutput: ioslides_presentation\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\nlibrary(tidyverse)\nlibrary(kableExtra)\n```\n\n## Slide with Markdown\n\nThe following slides will present some data from the `diamonds` dataset from **ggplot2**.\n\nDiamond price depends on many features, such as:\n\n- cut\n- colour\n- clarity\n- carats\n\n## Slide with a Table\n\n```{r}\ndiamonds %>%\n  group_by(cut, color) %>%\n  summarise(avg_price = mean(price),\n            .groups = \"drop\") %>%\n  pivot_wider(names_from = cut, values_from = avg_price) %>%\n  kable(digits = 0, caption = \"Mean diamond price by cut and colour.\") %>%\n  kable_material()\n```\n\n## Slide with a Plot\n\n```{r pressure}\nggplot(diamonds, aes(x = cut, y = price, color = color)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(aes(x = as.integer(cut)), \n               fun = mean, geom = \"line\") +\n  scale_x_discrete(position = \"top\") +\n  scale_color_viridis_d(guide = guide_legend(reverse = TRUE)) +\n  theme_minimal() \n```"},{"path":"custom.html","id":"dashboards","chapter":"10 Customising Visualisations & Reports","heading":"10.3.4.2 Dashboards","text":"Dashboards way display text, tables, plots dynamic formatting. install flexdashboard, can choose flexdashboard template create new R Markdown document.\nFigure 10.16: Flexdashboard RMarkdown template.\ncode shows load packages, display two tables tabset, display two plots column. can see HTML output .Change size web browser see boxes, tables figures change.best way figure format dashboard trial error, can also look sample layouts.","code":"---\ntitle: \"Flexdashboard Demo\"\noutput: \n  flexdashboard::flex_dashboard:\n    social: [ \"twitter\", \"facebook\", \"linkedin\", \"pinterest\" ]\n    source_code: embed\n    orientation: columns\n    vertical_layout: fill\n---\n\n```{r setup, include=FALSE}\nlibrary(flexdashboard)\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(DT) # for interactive tables\ntheme_set(theme_minimal())\n```\n\nColumn {data-width=350, .tabset}\n--------------------------------\n\n### By Cut\n\nThis table uses `kableExtra` to render the table with a specific theme.\n\n```{r}\ndiamonds %>%\n  group_by(cut) %>%\n  summarise(avg = mean(price),\n            .groups = \"drop\") %>%\n  kable(digits = 0, \n        col.names = c(\"Cut\", \"Average Price\"),\n        caption = \"Mean diamond price by cut.\") %>%\n  kable_classic()\n```\n\n### By Colour\n\nThis table uses `DT::datatable()` to render the table with a searchable interface.\n\n```{r}\ndiamonds %>%\n  group_by(color) %>%\n  summarise(avg = mean(price),\n            .groups = \"drop\") %>%\n  DT::datatable(colnames = c(\"Colour\", \"Average Price\"), \n                caption = \"Mean diamond price by colour\",\n                options = list(pageLength = 5),\n                rownames = FALSE) %>%\n  DT::formatRound(columns=2, digits=0)\n```\n\nColumn {data-width=350}\n-----------------------\n\n### By Clarity\n\n```{r by-clarity, fig.cap = \"Diamond price by clarity\"}\nggplot(diamonds, aes(x = clarity, y = price)) +\n  geom_boxplot() \n```\n\n\n### By Carats\n\n```{r by-carat, fig.cap = \"Diamond price by carat\"}\nggplot(diamonds, aes(x = carat, y = price)) +\n  stat_smooth()\n```"},{"path":"custom.html","id":"books","chapter":"10 Customising Visualisations & Reports","heading":"10.3.4.3 Books","text":"can create online books bookdown. fact, book reading created using bookdown. download package, start new project choose \"Book project using bookdown\" list project templates.\nFigure 10.17: Bookdown project template.\nchapter written separate .Rmd file general book settings can changed _bookdown.yml _output.yml files.","code":""},{"path":"custom.html","id":"websites","chapter":"10 Customising Visualisations & Reports","heading":"10.3.4.4 Websites","text":"can create simple website way create R Markdown document. Choose \"Simple R Markdown Website\" project templates get started. See Appendix K step--step tutorial.complex, blog-style websites, can investigate blogdown. install package, also able create template blogdown projects get started.","code":""},{"path":"custom.html","id":"shiny","chapter":"10 Customising Visualisations & Reports","heading":"10.3.4.5 Shiny","text":"get truly interactive, can take R coding next level learn Shiny. Shiny apps let R code react user input. can things like make word cloud, search google spreadsheet, conduct survey.well outside scope class, skills learned provide good start. free book Building Web Apps R Shiny one authors book can get started creating shiny apps.","code":""},{"path":"custom.html","id":"resources-report","chapter":"10 Customising Visualisations & Reports","heading":"10.3.5 Resources","text":"RStudio FormatsR Markdown CookbookDTFlexdashboardBookdownBlogdownShinyBuilding Web Apps R Shiny","code":""},{"path":"acknowledgements.html","id":"acknowledgements","chapter":"Acknowledgements","heading":"Acknowledgements","text":"whole psyTeachR team University Glasgow School Psychology deserves enormous thanks making possible rewarding teach methods focus reproducibility open research. Particularly\nHeather Cleland Woods,\nPhil McAleer,\nHelena Paterson,\nEmily Nordmann,\nCarolina Keuper-Tetzel, \nNiamh Stack.greatly appreciate Iris Holzleitner's volunteer -class assistance first year course. ever lucky get Rebecca Lai teaching assistant second year; kind patient approach teaching technical skills inspiration. Benedict Jones made invaluable contributions ethos reproducible research Glasgow. Thanks Daniël Lakens many inspirational discussions resources.","code":"\ncitation(\"reprores\")## \n## To cite dataskills in publications use:\n## \n##   Lisa DeBruine and Dale Barr (2021, Septmeber 18). Data Skills for\n##   Reproducible Science. R package version 2.0. Zenodo.\n##   http://doi.org/10.5281/zenodo.6527194\n## \n## A BibTeX entry for LaTeX users is\n## \n##   @Manual{,\n##     title = {Data Skills for Reproducible Science},\n##     author = {Lisa DeBruine and Dale Barr},\n##     doi = {10.5281/zenodo.6527194},\n##     publisher = {Zenodo},\n##     year = {2021},\n##     month = {September},\n##     note = {R package version 2.0},\n##     url = {https://psyteachr.github.io/msc-data-skills/},\n##   }"},{"path":"acknowledgements.html","id":"contributors","chapter":"Acknowledgements","heading":"Contributors","text":"Several people contributed testing materials.Rebecca LaiRichard MoreyMossa Merhi Reimert","code":""},{"path":"installingr.html","id":"installingr","chapter":"A Installing and Updating","heading":"A Installing and Updating","text":"Installing R RStudio usually straightforward. sections explain helpful YouTube video .time--time, updated version R, RStudio, packages use (e.g., ggplot2) become available. Remember separate, different process come different considerations. recommend updating latest version three start academic year.","code":""},{"path":"installingr.html","id":"installing-base-r","chapter":"A Installing and Updating","heading":"A.1 Installing Base R","text":"Install base R. Choose download link operating system (Linux, Mac OS X, Windows).Mac, install latest release newest R-x.x.x.pkg link (legacy version older operating system). install R, also install XQuartz able use visualisation packages.installing Windows version, choose \"base\" subdirectory click download link top page. install R, also install RTools; use \"recommended\" version highlighted near top list.using Linux, choose specific operating system follow installation instructions.","code":""},{"path":"installingr.html","id":"rstudio-online","chapter":"A Installing and Updating","heading":"A.1.1 R Online","text":"may need access R RStudio online use tablet Chromebook install R.Students School Psychology Neuroscience University Glasgow can access Glasgow Psychology RStudio GUID password.RStudio Cloud free online service allows access R RStudio.","code":""},{"path":"installingr.html","id":"updating-r","chapter":"A Installing and Updating","heading":"A.1.2 Updating R","text":"key thing aware update R, just download latest version website, lose packages. easiest way update R cause huge headache use installr package. use updateR() function, series dialogue boxes appear. fairly self-explanatory full step--step guide use installr, important bit select \"Yes\" asked like copy packages older version R.","code":"\n# Install the installr package\ninstall.packages(\"installr\")\n\n# Load installr\nlibrary(installr)\n\n# Run the update function\nupdateR()"},{"path":"installingr.html","id":"installing-rstudio","chapter":"A Installing and Updating","heading":"A.2 Installing RStudio","text":"Go rstudio.com download RStudio Desktop (Open Source License) version operating system list titled Installers Supported Platforms.","code":""},{"path":"installingr.html","id":"updating-rstudio","chapter":"A Installing and Updating","heading":"A.2.1 Updating RStudio","text":"Typically, updates RStudio affect code, instead add new features, like spell-check upgrades RStudio can . usually little downside updating RStudio easy .Click Help > Check updates; update available, prompt download can install usual.","code":""},{"path":"installingr.html","id":"rstudio-settings","chapter":"A Installing and Updating","heading":"A.2.2 RStudio Settings","text":"settings fix immediately updating RStudio. Go Global Options... Tools menu (⌘,), General tab, uncheck box says Restore .RData workspace startup. keep things around workspace, things get messy, unexpected things happen. always start clear workspace. also means never want save workspace exit, set Never. thing want save scripts.may also want change appearance code. Different fonts themes can sometimes help visual difficulties dyslexia.\nFigure .1: RStudio General Appearance settings\nmay also want change settings Code tab. example, prefer two spaces instead tabs indenting like able see whitespace characters. matter personal preference.\nFigure .2: RStudio Code settings\n","code":""},{"path":"installingr.html","id":"installing-latex","chapter":"A Installing and Updating","heading":"A.3 Installing LaTeX","text":"can install LaTeX typesetting system produce PDF reports RStudio. Without additional installation, able produce reports HTML PDF. course require make PDFs. generate PDF reports, additionally need install tinytex (Xie, 2022) run following code:","code":"\ntinytex::install_tinytex()"},{"path":"installingr.html","id":"installing-packages","chapter":"A Installing and Updating","heading":"A.4 Installing Packages","text":"Add-packages distributed base R, downloaded installed archive, way , instance, download install PokemonGo smartphone.main repository packages reside called CRAN, Comprehensive R Archive Network. package pass strict tests devised R core team allowed part CRAN archive. can install CRAN archive install.packages() function.Never install package inside script. console pane.","code":"\ninstall.packages(\"tidyverse\")"},{"path":"installingr.html","id":"development-packages","chapter":"A Installing and Updating","heading":"A.4.1 Development Packages","text":"Many R packages yet CRAN still development. Increasingly, datasets code papers available packages can download github. need install devtools package able install packages github.use development package script, good practice include comment website downloaded package. people use script unlikely package know find .","code":"\n# install devtools if you get\n# Error in loadNamespace(name) : there is no package called ‘devtools’\n# install.packages(\"devtools\")\ndevtools::install_github(\"psyteachr/reprores-v3\")"},{"path":"installingr.html","id":"updating-packages","chapter":"A Installing and Updating","heading":"A.4.2 Updating Packages","text":"Package developers occasionally release updates packages. typically add new functions package, fix amend existing functions. aware package updates may cause previous code stop working. tend happen minor updates packages, occasionally major updates, can serious issues developer made fundamental changes code works. reason, recommend updating packages beginning academic year (semester) -- assessment deadline just case!update individual package, easiest way use install.packages() function, always installs recent version package.update multiple packages, indeed packages, RStudio provides helpful tools. Click Tools > Check Package Updates. dialogue box appear can select packages wish update. aware select packages, may take time unable use R whilst process completes.","code":""},{"path":"installingr.html","id":"troubleshooting-1","chapter":"A Installing and Updating","heading":"A.4.3 Troubleshooting","text":"Occasionally, might problem packages seemingly refuse update, , rlang vctrs cause end trouble. packages likely ever explicitly load, required beneath surface RStudio things like knit Markdown files.try update package get error message says something like Warning install.packages : installation package ‘vctrs’ non-zero exit status perhaps Error loadNamespace(, c(lib.loc, .libPaths()), versionCheck = vI[[]]) :  namespace 'rlang' 0.4.9 loaded, >= 0.4.10 required one solution found manually uninstall package, restart R, install package new, rather trying update existing version. rpkg(\"installr\") package useful function uninstalling packages.","code":"\n# Load installr\nlibrary(installr)\n\n# Uninstall the problem package\nuninstall.packages(\"package_name\")\n\n# Then restart R using session - restart R\n\n# Then install the package fresh\ninstall.packages(\"package\")"},{"path":"getting-help.html","id":"getting-help","chapter":"B Getting Help","heading":"B Getting Help","text":"need take screenshot, example, something goes wrong installation, please use screenshot functions built-computer rather taking photo screen using phone.","code":""},{"path":"getting-help.html","id":"what-is-the-best-way-to-share-r-code","chapter":"B Getting Help","heading":"B.1 What is the best way to share R code?","text":"run problem need get help forum like class MS Teams channel. right way share code?Please share screenshot unless asked, code giving problems, something weird happening RStudio IDE.code working, almost always better copy paste code, people trying help can copy paste code exactly try , rather re-type everything image. look example. screenshot RStudio IDE might look code throws error. code block labelled cars causing error.\nFigure B.1: screenshot RStudio IDE showing error red.\nparticular error code threw wasAnd code threw wasNote can select copy code wanted run , rely screenshot.Copying code /error RStudio easy; just highlight code using mouse press Ctrl-C.just paste code Teams channel, formatting nice; lose fixed-width formatting allows read code easily.two ways get code Teams, one quick easy flexible, another far flexible requires steps.","code":"Error in mtcars %>% filter(mpg > 20) : could not find function \"%>%\"\nmtcars %>%\n  filter(mpg > 20)"},{"path":"getting-help.html","id":"backticks","chapter":"B Getting Help","heading":"B.1.1 Backticks","text":"First, just short function call, single line, error, can signal text meant appear code surrounding single backticks---.e., putting backtick (`) right right text want formatted code. Teams automatically format .multi-line code, easiest fastest way just type three backticks inside message beginning line. subsequent text enter treated code. get beginning line without submitting post, press Ctrl-Enter typing message. type three backticks, paste code right grey box automatically appears. Press Enter twice row get back code entry box. message might look like .\nFigure B.2: animation instructions make code blocks Teams\n","code":""},{"path":"getting-help.html","id":"code-snippets","chapter":"B Getting Help","heading":"B.1.2 Code snippets","text":"pasting text, click icon looks like letter \"\" pencil. open options text formatting allow easily create multi-line post. options, select icon looks like <\/>, stands code.\nFigure B.3: screenshot Teams editing interface.\ncode icon open window can paste code. dropdown menu top right, select 'R' type code. give syntax highlighting.","code":""},{"path":"getting-help.html","id":"reprex","chapter":"B Getting Help","heading":"B.2 Reprex","text":"might see people coding forums like StackOverflow asking \"reprex\", reproducible example. smallest, completely self-contained example problem question.example, may question figure select rows contain value \"test\" certain column, working. clearer can provide concrete example, want type whole table using code got point script.can include small table just basics smaller version problem. Make comments step expect actually got.version easier figure solution?... ...One big benefits creating reprex often solve problem trying break explain someone else.really want go rabbit hole, can create reproducible example using reprex package tidyverse.","code":"\n# this doesn't work\nno_test_data <- data |>\n  filter(!str_detect(type, \"test\"))\nlibrary(tidyverse)\n\n# with a minimal example table\ndata <- tribble(\n  ~id, ~type, ~x,\n  1, \"test\", 12,\n  2, \"testosterone\", 15,\n  3, \"estrogen\", 10\n)\n\n# this should keep IDs 2 and 3, but removes ID 2\nno_test_data <- data |>\n  filter(!str_detect(type, \"test\"))\n\n# expected to be true\nall(no_test_data$type == c(\"testosterone\", \"estrogen\"))"},{"path":"getting-help.html","id":"screenshots","chapter":"B Getting Help","heading":"B.3 Screenshots","text":"","code":""},{"path":"getting-help.html","id":"taking-a-screenshot-on-windows","chapter":"B Getting Help","heading":"B.3.1 Taking a screenshot on Windows","text":"Use Windows search function search \"Snip & Sketch\"Click \"New\" \"Snip now\"Use tool select area screen want take screenshot . photo automatically copied clipboard, can paste e.g., Teams chat document using Ctrl + V can also click Save icon top right save screenshot image file.shortcut snipping tool Win + Shift + S.","code":""},{"path":"getting-help.html","id":"taking-a-screenshot-on-mac","chapter":"B Getting Help","heading":"B.3.2 Taking a screenshot on Mac","text":"Press Shift + Command (⌘) + 4 bring Screenshot app.Use tool select area screen want take screenshot .see thumbnail corner screen, click edit screenshot drag e.g., Teams chat.photo also automatically save desktop.","code":""}]
